{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3xyWm9uZyyx"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqPUoeQ50z4j"
      },
      "source": [
        "# Generates Figure 3 from Cosentino et al. Nature Genetics 2023\n",
        "\n",
        "This notebook builds the ML model performance comparison and survival analysis\n",
        "Kaplan-Meier curve subfigures for Figure 3 of the ML-based COPD manuscript\n",
        "(Cosentino et al. Nature Genetics 2023).\n",
        "\n",
        "It compares the following models:\n",
        "\n",
        "-   FEV1/FVC ratio-based risk\n",
        "-   FEV1 percent predicted-based risk\n",
        "-   ML-based COPD risk\n",
        "\n",
        "It evaluates COPD risk predictions against the following labels:\n",
        "\n",
        "-   `copd_all_srcs_subset`: A subset of `copd` labels where all EIDs have valid\n",
        "    values from self-report, HESIN, and GP sources.\n",
        "-   `copd_hesin_primary_after`: Binary label indicating a COPD-related\n",
        "    hospitalization event after spirometery data collection.\n",
        "-   `copd_death_primary`: Binary label indicating a COPD-related death.\n",
        "\n",
        "This notebook assumes that there exists a TSV file containing risk predictions\n",
        "and labels stored at `DATA_FILEPATH`. This TSV must contain the following\n",
        "columns:\n",
        "\n",
        "-   `eid`: A unique individual identifier.\n",
        "-   `copd_all_srcs_subset`: A subset of `copd` labels where all EIDs have valid\n",
        "    values from self-report, HESIN, and GP sources.\n",
        "-   `copd_hesin_primary_after`: Binary label indicating a COPD-related\n",
        "    hospitalization event after spirometery data collection.\n",
        "-   `copd_death_primary`: Binary label indicating a COPD-related death (i.e., 0\n",
        "    if no death or death due to non-COPD causes).\n",
        "-   `blow_ratio_risk`: A risk score based on FEV1/FVC ratio (i.e., `1 -\n",
        "    blow_ratio`).\n",
        "-   `blow_fev1_pct_pred_norm_risk`: A risk score based on FEV1 percent predicted\n",
        "    (i.e., `1 - normalized(blow_fev1_pct_pred)`).\n",
        "-   `ml_based_copd`: The ML-based COPD liability score.\n",
        "\n",
        "**Important: We assume that `DATA_FILEPATH` contains *only* individuals from the\n",
        "validation holdout set.**\n",
        "\n",
        "This notebook assumes that there exists a TSV file at `KM_ML_DATA_FILEPATH`\n",
        "containing raw Kaplan-Meier curve datapoints. This file can be generated by\n",
        "running the `survival_analysis.R` Rlang script."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEbnbAFryo6j"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import concurrent.futures\n",
        "import dataclasses\n",
        "import enum\n",
        "import pathlib\n",
        "import string\n",
        "from typing import AbstractSet, Callable, Dict, List, Mapping, NamedTuple, Optional, Set, Sequence, Tuple, Type, Union\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "from matplotlib import transforms\n",
        "import mpl_toolkits.axes_grid1.inset_locator as inset_locator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import sklearn.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc2EWNZ5qODE"
      },
      "outputs": [],
      "source": [
        "def set_matplotib_settings():\n",
        "  sns.set_palette('deep')\n",
        "  sns.set_style(\n",
        "      'ticks',\n",
        "      {\n",
        "          'axes.grid': True,\n",
        "          'font.family': ['Helvetica'],\n",
        "          'text.usetex': True,\n",
        "          'legend.frameon': False,\n",
        "      },\n",
        "  )\n",
        "  rcParams['savefig.dpi'] = 300\n",
        "  rcParams['savefig.transparent'] = False\n",
        "  rcParams['font.size'] = 7\n",
        "\n",
        "\n",
        "set_matplotib_settings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD7zXCslVbJ1"
      },
      "source": [
        "## Bootstrapping and plotting utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYjQASDVk9FC"
      },
      "outputs": [],
      "source": [
        "# Constants denoting the expected case and control values for binary encodings.\n",
        "BINARY_LABEL_CONTROL = 0\n",
        "BINARY_LABEL_CASE = 1\n",
        "\n",
        "# Represents a numpy array of indices for a single bootstrap sample.\n",
        "IndexSample = np.ndarray\n",
        "\n",
        "\n",
        "class CurveType(enum.Enum):\n",
        "  \"\"\"Denotes the type of a performance curve.\"\"\"\n",
        "\n",
        "  ROC = 'roc'\n",
        "  PR = 'precision_recall'\n",
        "\n",
        "\n",
        "class CurveFnResult(NamedTuple):\n",
        "  \"\"\"Represents a single performance curve sample.\n",
        "\n",
        "  Attributes:\n",
        "    curve_type: The curve's type.\n",
        "    value_array_x: The curve's x coordinates.\n",
        "    value_array_y: The curve's y coordinates.\n",
        "    threshold_array: The thresholds corresponding to each x-y coordinate.\n",
        "  \"\"\"\n",
        "\n",
        "  curve_type: CurveType\n",
        "  value_array_x: np.ndarray\n",
        "  value_array_y: np.ndarray\n",
        "  threshold_array: np.ndarray\n",
        "\n",
        "\n",
        "class CurveBootstrapResult(NamedTuple):\n",
        "  \"\"\"Represents a bootstrapped curve result.\n",
        "\n",
        "  Attributes:\n",
        "    curve_type: The curve's type.\n",
        "    mean: The mean of the curve's y-coordinate values.\n",
        "    stddev: The standard deviation of the curve's y coordinate values.\n",
        "    num_samples: The number of bootstrap curve samples.\n",
        "    ci_level: The confidence level at which the CI is calculated (e.g., 95).\n",
        "    ci_lower: The lower limit of the `level` confidence interval.\n",
        "    ci_upper: The upper limit of the `level` confidence interval.\n",
        "    interp: The interpolated x-coordinates.\n",
        "  \"\"\"\n",
        "\n",
        "  curve_type: CurveType\n",
        "  mean: np.ndarray\n",
        "  stddev: np.ndarray\n",
        "  num_samples: int\n",
        "  ci_level: float\n",
        "  ci_upper: np.ndarray\n",
        "  ci_lower: np.ndarray\n",
        "  interp: np.ndarray\n",
        "\n",
        "\n",
        "# Denotes a bootstrappable function used to compute performance curves. Returns\n",
        "# a tuple containing two coordinate arrays and one threshold array.\n",
        "CurveFn = Callable[[np.ndarray, np.ndarray], CurveFnResult]\n",
        "\n",
        "\n",
        "class RocCurve(NamedTuple):\n",
        "  \"\"\"Container for a ROC curve.\"\"\"\n",
        "\n",
        "  tpr: np.ndarray\n",
        "  fpr: np.ndarray\n",
        "  err_lower: Optional[np.ndarray] = None\n",
        "  err_upper: Optional[np.ndarray] = None\n",
        "\n",
        "\n",
        "class PrecisionRecallCurve(NamedTuple):\n",
        "  \"\"\"Container for a precision-recall curve.\"\"\"\n",
        "\n",
        "  precision: np.ndarray\n",
        "  recall: np.ndarray\n",
        "  err_lower: Optional[np.ndarray] = None\n",
        "  err_upper: Optional[np.ndarray] = None\n",
        "\n",
        "\n",
        "class KmCurve(NamedTuple):\n",
        "  \"\"\"Container for a Kaplan-meier curve.\"\"\"\n",
        "\n",
        "  time: np.ndarray\n",
        "  prob: np.ndarray\n",
        "  std_err: np.ndarray\n",
        "  err_lower: np.ndarray\n",
        "  err_upper: np.ndarray\n",
        "\n",
        "\n",
        "@dataclasses.dataclass(eq=False, order=False, frozen=True)\n",
        "class NamedArray:\n",
        "  \"\"\"Represents a named numpy array.\n",
        "\n",
        "  Attributes:\n",
        "    name: The array name.\n",
        "    values: A numpy array.\n",
        "  \"\"\"\n",
        "\n",
        "  name: str\n",
        "  values: np.ndarray\n",
        "\n",
        "  def __post_init__(self):\n",
        "    if not self.name:\n",
        "      raise ValueError('`name` must be specified.')\n",
        "\n",
        "  def __len__(self) -\u003e int:\n",
        "    return len(self.values)\n",
        "\n",
        "  def __str__(self) -\u003e str:\n",
        "    return f'{self.__class__.__name__}({self.name})'\n",
        "\n",
        "\n",
        "@dataclasses.dataclass(eq=False, order=False, frozen=True)\n",
        "class Label(NamedArray):\n",
        "  \"\"\"Represents a named numpy array of ground truth label targets.\n",
        "\n",
        "  Attributes:\n",
        "    name: The label name.\n",
        "    values: A numpy array containing ground truth label targets.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "@dataclasses.dataclass(eq=False, order=False, frozen=True)\n",
        "class Prediction(NamedArray):\n",
        "  \"\"\"Represents a named numpy array of target predictions.\n",
        "\n",
        "  Attributes:\n",
        "    model_name: The name of the model that generated the predictions.\n",
        "    name: The name of the predictions (e.g., the prediction column).\n",
        "    values: A numpy array containing model predictions.\n",
        "  \"\"\"\n",
        "\n",
        "  model_name: str\n",
        "\n",
        "  def __post_init__(self):\n",
        "    super().__post_init__()\n",
        "    if not self.model_name:\n",
        "      raise ValueError('`model_name` must be specified.')\n",
        "\n",
        "  def __str__(self) -\u003e str:\n",
        "    return f'{self.__class__.__name__}({self.model_name}.{self.name})'\n",
        "\n",
        "\n",
        "def bootstrap_result_to_roc(\n",
        "    result: CurveBootstrapResult,\n",
        ") -\u003e RocCurve:\n",
        "  \"\"\"Converts a bootstrapped curve result to a `RocCurve`.\"\"\"\n",
        "  roc_curve = RocCurve(\n",
        "      tpr=result.mean,\n",
        "      fpr=result.interp,\n",
        "      err_lower=result.ci_lower,\n",
        "      err_upper=result.ci_upper,\n",
        "  )\n",
        "  return roc_curve\n",
        "\n",
        "\n",
        "def bootstrap_result_to_pr(\n",
        "    result: CurveBootstrapResult,\n",
        ") -\u003e PrecisionRecallCurve:\n",
        "  \"\"\"Converts a bootstrapped curve result to a `PrecisionRecallCurve`.\"\"\"\n",
        "  pr_curve = PrecisionRecallCurve(\n",
        "      precision=result.mean,\n",
        "      recall=result.interp,\n",
        "      err_lower=result.ci_lower,\n",
        "      err_upper=result.ci_upper,\n",
        "  )\n",
        "  return pr_curve\n",
        "\n",
        "\n",
        "def df_to_km_curves(km_data_filepath: pathlib.Path) -\u003e Dict[str, KmCurve]:\n",
        "  \"\"\"Converts a Kaplan-meier TSV to a mapping of identifiers to `KmCurve`s.\"\"\"\n",
        "  with open(str(km_data_filepath), mode='r') as f:\n",
        "    km_df = pd.read_csv(f, sep='\\t')\n",
        "  km_df_cols = set(km_df.columns)\n",
        "  expected_cols = {'group', 'time', 'prob', 'se', 'lower', 'upper'}\n",
        "  col_diff = km_df_cols.symmetric_difference(expected_cols)\n",
        "  if col_diff:\n",
        "    raise ValueError(f'Unexpected KM data columns: {col_diff}')\n",
        "\n",
        "  km_curves = {}\n",
        "  groups = km_df['group'].unique()\n",
        "  for group in groups:\n",
        "    group_df = km_df[km_df['group'] == group].copy()\n",
        "    km_curves[group] = KmCurve(\n",
        "        time=group_df.time,\n",
        "        prob=group_df.prob,\n",
        "        std_err=group_df.se,\n",
        "        err_lower=group_df.lower,\n",
        "        err_upper=group_df.upper,\n",
        "    )\n",
        "\n",
        "  return km_curves\n",
        "\n",
        "\n",
        "def l2_distance(\n",
        "    point_a: Tuple[float, float],\n",
        "    point_b: Tuple[float, float],\n",
        ") -\u003e float:\n",
        "  \"\"\"Computes the L2 distance between two points.\"\"\"\n",
        "  return np.linalg.norm(np.array(point_a) - np.array(point_b))\n",
        "\n",
        "\n",
        "def plot_roc_curves(\n",
        "    curves: Mapping[str, RocCurve],\n",
        "    label_overrides: Optional[Mapping[str, str]] = None,\n",
        "    color_overrides: Optional[Mapping[str, str]] = None,\n",
        "    line_width: float = 2,\n",
        "    xlabel: str = 'False Positive Rate',\n",
        "    ylabel: str = 'True Positive Rate',\n",
        "    title: str = '',\n",
        "    plot_x_eq_y: bool = True,\n",
        "    plot_marker: bool = True,\n",
        "    plot_legend: bool = True,\n",
        "    inset_xlim: Optional[Tuple[int, int]] = None,\n",
        "    inset_ylim: Optional[Tuple[int, int]] = None,\n",
        "    inset_zoom: float = 2,\n",
        "    ax: Optional[plt.Axes] = None,\n",
        ") -\u003e plt.Axes:\n",
        "  \"\"\"Plots ROC curves on the given axis.\n",
        "\n",
        "  Args:\n",
        "    curves: A mapping of curve identifiers to `RocCurve` values.\n",
        "    label_overrides: An optional mapping of curve identifiers to label overrides\n",
        "      used when plotting the given curve. The curve identifier must match a\n",
        "      curve identifier in `curves`.\n",
        "    color_overrides: An optional mapping of curve identifiers to color overrides\n",
        "      used when plotting the given curve. The curve identifier must match a\n",
        "      curve identifier in `curves`.\n",
        "    line_width: A float denoting the line width of curves.\n",
        "    xlabel: The label for the x axis.\n",
        "    ylabel: The label for the y axis.\n",
        "    title: The subplot's title.\n",
        "    plot_x_eq_y: Whether to plot an x=y line.\n",
        "    plot_marker: Whether to plot a marker on the point closest to `[0, 1]` in\n",
        "      each curve.\n",
        "    plot_legend: Whether to plot a legend on the axis.\n",
        "    inset_xlim: An optional tuple denoting the inset's x limits; if not\n",
        "      specified, not insets are added to the axis.\n",
        "    inset_ylim: An optional tuple denoting the inset's y limits; if not\n",
        "      specified, not insets are added to the axis.\n",
        "    inset_zoom: The inset's zoom level.\n",
        "    ax: An optional axis on which to plot the curves. If not specified, a new\n",
        "      axis is created.\n",
        "\n",
        "  Returns:\n",
        "    The axis on which curves were plotted.\n",
        "  \"\"\"\n",
        "  if label_overrides is None:\n",
        "    label_overrides = {}\n",
        "  if color_overrides is None:\n",
        "    color_overrides = {}\n",
        "\n",
        "  if ax is None:\n",
        "    ax = plt.axes()\n",
        "\n",
        "  plot_inset = inset_zoom \u003e 0 and inset_xlim and inset_ylim\n",
        "  if plot_inset:\n",
        "    ax_inset = inset_locator.zoomed_inset_axes(\n",
        "        ax,\n",
        "        inset_zoom,\n",
        "        loc='lower right',\n",
        "    )\n",
        "    ax_inset.set_xlim(*inset_xlim)\n",
        "    ax_inset.set_ylim(*inset_ylim)\n",
        "    inset_locator.mark_inset(\n",
        "        ax,\n",
        "        ax_inset,\n",
        "        loc1=1,\n",
        "        loc2=3,\n",
        "        fc='none',\n",
        "        ec='0.5',\n",
        "        linestyle='--',\n",
        "    )\n",
        "  else:\n",
        "    ax_inset = None\n",
        "\n",
        "  for curve_name, curve in curves.items():\n",
        "    curve_label = label_overrides.get(curve_name, curve_name)\n",
        "    curve_color = color_overrides.get(curve_name, None)\n",
        "    curve_plot = ax.plot(\n",
        "        curve.fpr,\n",
        "        curve.tpr,\n",
        "        color=curve_color,\n",
        "        lw=line_width,\n",
        "        label=curve_label,\n",
        "    )\n",
        "\n",
        "    # If no curve color was specified, use the color set by matplotlib.\n",
        "    assert len(curve_plot) == 1\n",
        "    curve_color = curve_color if curve_color else curve_plot[0].get_color()\n",
        "\n",
        "    # If specified, replot on the inset.\n",
        "    if ax_inset:\n",
        "      ax_inset.plot(\n",
        "          curve.fpr,\n",
        "          curve.tpr,\n",
        "          color=curve_color,\n",
        "          lw=line_width,\n",
        "          label=curve_label,\n",
        "      )\n",
        "\n",
        "    if curve.err_lower is not None and curve.err_upper is not None:\n",
        "      ax.fill_between(\n",
        "          curve.fpr,\n",
        "          curve.err_lower,\n",
        "          curve.err_upper,\n",
        "          color=curve_color,\n",
        "          alpha=0.2,\n",
        "      )\n",
        "      if ax_inset:\n",
        "        ax_inset.fill_between(\n",
        "            curve.fpr,\n",
        "            curve.err_lower,\n",
        "            curve.err_upper,\n",
        "            color=curve_color,\n",
        "            alpha=0.2,\n",
        "        )\n",
        "\n",
        "    # If specified, plot a marker on the point closest to `[0, 1]`.\n",
        "    if plot_marker:\n",
        "      points = list(zip(curve.fpr, curve.tpr))\n",
        "      distances = [l2_distance((0, 1), p) for p in points]\n",
        "      closest_point = points[np.argmin(distances)]\n",
        "      ax.plot(\n",
        "          closest_point[0],\n",
        "          closest_point[1],\n",
        "          marker='o',\n",
        "          color=curve_color,\n",
        "          markersize=8,\n",
        "      )\n",
        "      if ax_inset:\n",
        "        ax_inset.plot(\n",
        "            closest_point[0],\n",
        "            closest_point[1],\n",
        "            marker='o',\n",
        "            color=curve_color,\n",
        "            markersize=8,\n",
        "        )\n",
        "\n",
        "  if plot_x_eq_y:\n",
        "    ax.plot([-0.05, 1.05], [-0.05, 1.05], color='gray', lw=1, linestyle='--')\n",
        "\n",
        "  ax.set_title(title)\n",
        "  ax.set_xlabel(xlabel)\n",
        "  ax.set_ylabel(ylabel)\n",
        "  ax.set_xlim([-0.05, 1.05])\n",
        "  ax.set_ylim([-0.05, 1.05])\n",
        "  if plot_legend:\n",
        "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "  if ax_inset:\n",
        "    ax_inset.set_xticklabels([])\n",
        "    ax_inset.set_yticklabels([])\n",
        "\n",
        "  return ax\n",
        "\n",
        "\n",
        "def plot_pr_curves(\n",
        "    curves: Mapping[str, PrecisionRecallCurve],\n",
        "    label_overrides: Optional[Mapping[str, str]] = None,\n",
        "    color_overrides: Optional[Mapping[str, str]] = None,\n",
        "    line_width: float = 2,\n",
        "    xlabel: str = 'Recall',\n",
        "    ylabel: str = 'Precision',\n",
        "    title: str = '',\n",
        "    plot_marker: bool = True,\n",
        "    plot_legend: bool = True,\n",
        "    inset_xlim: Optional[Tuple[int, int]] = None,\n",
        "    inset_ylim: Optional[Tuple[int, int]] = None,\n",
        "    inset_zoom: float = 2,\n",
        "    ax: Optional[plt.Axes] = None,\n",
        ") -\u003e plt.Axes:\n",
        "  \"\"\"Plots precision-recall curves on the given axis.\n",
        "\n",
        "  Args:\n",
        "    curves: A mapping of curve identifiers to `PrecisionRecallCurve` values.\n",
        "    label_overrides: An optional mapping of curve identifiers to label overrides\n",
        "      used when plotting the given curve. The curve identifier must match a\n",
        "      curve identifier in `curves`.\n",
        "    color_overrides: An optional mapping of curve identifiers to color overrides\n",
        "      used when plotting the given curve. The curve identifier must match a\n",
        "      curve identifier in `curves`.\n",
        "    line_width: A float denoting the line width of curves.\n",
        "    xlabel: The label for the x axis.\n",
        "    ylabel: The label for the y axis.\n",
        "    title: The subplot's title.\n",
        "    plot_marker: Whether to plot a marker on the point closest to `[0, 1]` in\n",
        "      each curve.\n",
        "    plot_legend: Whether to plot a legend on the axis.\n",
        "    inset_xlim: An optional tuple denoting the inset's x limits; if not\n",
        "      specified, not insets are added to the axis.\n",
        "    inset_ylim: An optional tuple denoting the inset's y limits; if not\n",
        "      specified, not insets are added to the axis.\n",
        "    inset_zoom: The inset's zoom level.\n",
        "    ax: An optional axis on which to plot the curves. If not specified, a new\n",
        "      axis is created.\n",
        "\n",
        "  Returns:\n",
        "    The axis on which curves were plotted.\n",
        "  \"\"\"\n",
        "  if label_overrides is None:\n",
        "    label_overrides = {}\n",
        "  if color_overrides is None:\n",
        "    color_overrides = {}\n",
        "\n",
        "  if ax is None:\n",
        "    ax = plt.axes()\n",
        "\n",
        "  plot_inset = inset_zoom \u003e 0 and inset_xlim and inset_ylim\n",
        "  if plot_inset:\n",
        "    ax_inset = inset_locator.zoomed_inset_axes(\n",
        "        ax,\n",
        "        inset_zoom,\n",
        "        loc='upper right',\n",
        "    )\n",
        "    ax_inset.set_xlim(*inset_xlim)\n",
        "    ax_inset.set_ylim(*inset_ylim)\n",
        "    inset_locator.mark_inset(\n",
        "        ax,\n",
        "        ax_inset,\n",
        "        loc1=2,\n",
        "        loc2=4,\n",
        "        fc='none',\n",
        "        ec='0.5',\n",
        "        linestyle='--',\n",
        "    )\n",
        "  else:\n",
        "    ax_inset = None\n",
        "\n",
        "  for curve_name, curve in curves.items():\n",
        "    curve_label = label_overrides.get(curve_name, curve_name)\n",
        "    curve_color = color_overrides.get(curve_name, None)\n",
        "    curve_plot = ax.plot(\n",
        "        curve.recall,\n",
        "        curve.precision,\n",
        "        color=curve_color,\n",
        "        lw=line_width,\n",
        "        label=curve_label,\n",
        "    )\n",
        "\n",
        "    # If no curve color was specified, use the color set by matplotlib.\n",
        "    assert len(curve_plot) == 1\n",
        "    curve_color = curve_color if curve_color else curve_plot[0].get_color()\n",
        "\n",
        "    # If specified, replot on the inset.\n",
        "    if ax_inset:\n",
        "      ax_inset.plot(\n",
        "          curve.recall,\n",
        "          curve.precision,\n",
        "          color=curve_color,\n",
        "          lw=line_width,\n",
        "          label=curve_label,\n",
        "      )\n",
        "\n",
        "    if curve.err_lower is not None and curve.err_upper is not None:\n",
        "      ax.fill_between(\n",
        "          curve.recall,\n",
        "          curve.err_lower,\n",
        "          curve.err_upper,\n",
        "          color=curve_color,\n",
        "          alpha=0.2,\n",
        "      )\n",
        "      if ax_inset:\n",
        "        ax_inset.fill_between(\n",
        "            curve.recall,\n",
        "            curve.err_lower,\n",
        "            curve.err_upper,\n",
        "            color=curve_color,\n",
        "            alpha=0.2,\n",
        "        )\n",
        "\n",
        "    # If specified, plot a marker on the point closest to `[0, 1]`.\n",
        "    if plot_marker:\n",
        "      points = list(zip(curve.recall, curve.precision))\n",
        "      distances = [l2_distance((1, 1), p) for p in points]\n",
        "      closest_point = points[np.argmin(distances)]\n",
        "      ax.plot(\n",
        "          closest_point[0],\n",
        "          closest_point[1],\n",
        "          marker='o',\n",
        "          color=curve_color,\n",
        "          markersize=8,\n",
        "      )\n",
        "      if ax_inset:\n",
        "        ax_inset.plot(\n",
        "            closest_point[0],\n",
        "            closest_point[1],\n",
        "            marker='o',\n",
        "            color=curve_color,\n",
        "            markersize=8,\n",
        "        )\n",
        "\n",
        "  ax.set_title(title)\n",
        "  ax.set_xlabel(xlabel)\n",
        "  ax.set_ylabel(ylabel)\n",
        "  ax.set_xlim([-0.05, 1.05])\n",
        "  ax.set_ylim([-0.05, 1.05])\n",
        "  if plot_legend:\n",
        "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "  if ax_inset:\n",
        "    ax_inset.set_xticklabels([])\n",
        "    ax_inset.set_yticklabels([])\n",
        "\n",
        "  return ax\n",
        "\n",
        "\n",
        "def plot_km_curves(\n",
        "    curves: Mapping[str, KmCurve],\n",
        "    label_overrides: Optional[Mapping[str, str]] = None,\n",
        "    color_overrides: Optional[Mapping[str, str]] = None,\n",
        "    line_width: float = 2,\n",
        "    xlabel: str = 'Time (days)',\n",
        "    ylabel: str = 'Survival probability',\n",
        "    title: str = '',\n",
        "    plot_legend: bool = True,\n",
        "    legend_title: Optional[str] = None,\n",
        "    ax: Optional[plt.Axes] = None,\n",
        "):\n",
        "  \"\"\"Plots Kaplan-meier curves on the given axis.\n",
        "\n",
        "  Args:\n",
        "    curves: A mapping of curve identifiers to `KmCurve` values.\n",
        "    label_overrides: An optional mapping of curve identifiers to label overrides\n",
        "      used when plotting the given curve. The curve identifier must match a\n",
        "      curve identifier in `curves`.\n",
        "    color_overrides: An optional mapping of curve identifiers to color overrides\n",
        "      used when plotting the given curve. The curve identifier must match a\n",
        "      curve identifier in `curves`.\n",
        "    line_width: A float denoting the line width of curves.\n",
        "    xlabel: The label for the x axis.\n",
        "    ylabel: The label for the y axis.\n",
        "    title: The subplot's title.\n",
        "    plot_legend: Whether to plot a legend on the axis.\n",
        "    legend_title: An optional title for the legend.\n",
        "    ax: An optional axis on which to plot the curves. If not specified, a new\n",
        "      axis is created.\n",
        "\n",
        "  Returns:\n",
        "    The axis on which curves were plotted.\n",
        "  \"\"\"\n",
        "  if label_overrides is None:\n",
        "    label_overrides = {}\n",
        "  if color_overrides is None:\n",
        "    color_overrides = {}\n",
        "\n",
        "  if ax is None:\n",
        "    ax = plt.axes()\n",
        "\n",
        "  for curve_name, curve in curves.items():\n",
        "    curve_label = label_overrides.get(curve_name, curve_name)\n",
        "    curve_color = color_overrides.get(curve_name, None)\n",
        "    curve_plot = ax.plot(\n",
        "        curve.time,\n",
        "        curve.prob,\n",
        "        color=curve_color,\n",
        "        lw=line_width,\n",
        "        label=curve_label,\n",
        "    )\n",
        "\n",
        "    # If no curve color was specified, use the color set by matplotlib.\n",
        "    assert len(curve_plot) == 1\n",
        "    curve_color = curve_color if curve_color else curve_plot[0].get_color()\n",
        "\n",
        "    if curve.err_lower is not None and curve.err_upper is not None:\n",
        "      ax.fill_between(\n",
        "          curve.time,\n",
        "          curve.err_lower,\n",
        "          curve.err_upper,\n",
        "          color=curve_color,\n",
        "          alpha=0.2,\n",
        "      )\n",
        "\n",
        "  ax.set_title(title)\n",
        "  ax.set_xlabel(xlabel)\n",
        "  ax.set_ylabel(ylabel)\n",
        "\n",
        "  if plot_legend:\n",
        "    if legend_title is None:\n",
        "      # If no legend title is given, just plot base labels.\n",
        "      ax.legend(\n",
        "          bbox_to_anchor=(0, 1.02, 1, 1),\n",
        "          mode='expand',\n",
        "          loc='lower center',\n",
        "          borderaxespad=0,\n",
        "          frameon=False,\n",
        "          ncol=len(curves),\n",
        "      )\n",
        "    else:\n",
        "      # matplotlib doesn't give us an easy way to include a legend title inline\n",
        "      # with markers, so we create an empty placeholder.\n",
        "      title_handle = plt.plot([], marker='', ls='')[0]\n",
        "      handles, labels = ax.get_legend_handles_labels()\n",
        "      ax.legend(\n",
        "          bbox_to_anchor=(-0.03, 1.03, 1, 1),\n",
        "          mode='expand',\n",
        "          loc='lower center',\n",
        "          borderaxespad=0,\n",
        "          frameon=False,\n",
        "          labels=[legend_title] + labels,\n",
        "          handles=[title_handle] + handles,\n",
        "          ncol=len(curves) + 1,\n",
        "      )\n",
        "\n",
        "  return ax\n",
        "\n",
        "\n",
        "def bs_curves_to_fig_curves(\n",
        "    label_to_type_to_id_to_bs: Mapping[\n",
        "        str,\n",
        "        Mapping[\n",
        "            CurveType,\n",
        "            Mapping[\n",
        "                str,\n",
        "                CurveBootstrapResult,\n",
        "            ],\n",
        "        ],\n",
        "    ],\n",
        ") -\u003e Mapping[\n",
        "    str,\n",
        "    Mapping[\n",
        "        Union[Type[RocCurve], Type[PrecisionRecallCurve]],\n",
        "        Mapping[\n",
        "            str,\n",
        "            Union[\n",
        "                RocCurve,\n",
        "                PrecisionRecallCurve,\n",
        "            ],\n",
        "        ],\n",
        "    ],\n",
        "]:\n",
        "  \"\"\"Converts a mapping of bootstrap curves to the figure curve equivalent.\"\"\"\n",
        "  label_to_type_to_id_to_curve = collections.defaultdict(\n",
        "      lambda: collections.defaultdict(dict)\n",
        "  )\n",
        "  for label_col, curve_type_to_bs_result in label_to_type_to_id_to_bs.items():\n",
        "    for curve_type, model_id_to_bs_result in curve_type_to_bs_result.items():\n",
        "      for model_id, bs_result in model_id_to_bs_result.items():\n",
        "        if curve_type == CurveType.ROC:\n",
        "          roc_curve = bootstrap_result_to_roc(bs_result)\n",
        "          label_to_type_to_id_to_curve[label_col][RocCurve][\n",
        "              model_id\n",
        "          ] = roc_curve\n",
        "        elif curve_type == CurveType.PR:\n",
        "          pr_curve = bootstrap_result_to_pr(bs_result)\n",
        "          label_to_type_to_id_to_curve[label_col][PrecisionRecallCurve][\n",
        "              model_id\n",
        "          ] = pr_curve\n",
        "        else:\n",
        "          raise NotImplementedError(curve_type)\n",
        "  return label_to_type_to_id_to_curve\n",
        "\n",
        "\n",
        "def is_valid_binary_label(array: np.ndarray) -\u003e bool:\n",
        "  \"\"\"Whether `array` is a \"valid\" binary label array for bootstrapping.\n",
        "\n",
        "  We define a valid binary label array as an array that contains only binary\n",
        "  values, i.e., `{BINARY_LABEL_CONTROL, BINARY_LABEL_CASE}`, and contains at\n",
        "  least one value from each class.\n",
        "\n",
        "  Args:\n",
        "    array: A numpy array.\n",
        "\n",
        "  Returns:\n",
        "    Whether `array` is a \"valid\" binary label array.\n",
        "  \"\"\"\n",
        "  is_case_mask = array == BINARY_LABEL_CASE\n",
        "  is_control_mask = array == BINARY_LABEL_CONTROL\n",
        "  return (\n",
        "      np.any(is_case_mask)\n",
        "      and np.any(is_control_mask)\n",
        "      and np.all(np.logical_or(is_case_mask, is_control_mask))\n",
        "  )\n",
        "\n",
        "\n",
        "def _roc_curve(\n",
        "    y_true: np.ndarray,\n",
        "    y_pred: np.ndarray,\n",
        ") -\u003e CurveFnResult:\n",
        "  \"\"\"Wrapper function for computing ROC curves.\"\"\"\n",
        "  fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_true, y_pred)\n",
        "  return CurveFnResult(CurveType.ROC, fpr, tpr, thresholds)\n",
        "\n",
        "\n",
        "def _precision_recall_curve(\n",
        "    y_true: np.ndarray,\n",
        "    y_pred: np.ndarray,\n",
        ") -\u003e CurveFnResult:\n",
        "  \"\"\"Wrapper function for computing precision-recall curves.\"\"\"\n",
        "  precision, recall, thresholds = sklearn.metrics.precision_recall_curve(\n",
        "      y_true,\n",
        "      y_pred,\n",
        "  )\n",
        "  return CurveFnResult(CurveType.PR, precision, recall, thresholds)\n",
        "\n",
        "\n",
        "def _bootstrap_curve(\n",
        "    curve_type: CurveType,\n",
        "    curve_fn: CurveFn,\n",
        "    label: Label,\n",
        "    predictions: Sequence[Prediction],\n",
        "    sample_indices: Sequence[np.ndarray],\n",
        "    ci_level: float,\n",
        "    n_interp: int,\n",
        ") -\u003e Dict[str, CurveBootstrapResult]:\n",
        "  \"\"\"Generates bootstrapped `Prediction` curves from `num_bootstrap` samples.\n",
        "\n",
        "  Args:\n",
        "    curve_type: The type of curve generated by `curve_fn`.\n",
        "    curve_fn: A bootstrappable function for generating `curve_type` curves.\n",
        "    label: The ground truth label targets.\n",
        "    predictions: A list of target predictions from a set of models.\n",
        "    sample_indices: An array of bootstrap sample indices. If empty, returns the\n",
        "      single value computed on the entire dataset for each prediction.\n",
        "    ci_level: The confidence level at which the CI is calculated (e.g., 95).\n",
        "    n_interp: The number of interpolation points for x-coordinates in [0, 1].\n",
        "\n",
        "  Returns:\n",
        "    A bootstrapped curve computed from labels and predictions.\n",
        "  \"\"\"\n",
        "  if not sample_indices:\n",
        "    curve_samples = {}\n",
        "    for prediction in predictions:\n",
        "      curve_result = curve_fn(label.values, prediction.values)\n",
        "      curve_samples[prediction.model_name] = [curve_result]\n",
        "  else:\n",
        "    curve_samples = {prediction.model_name: [] for prediction in predictions}\n",
        "    for index in sample_indices:\n",
        "      sample_true = label.values[index]\n",
        "      for prediction in predictions:\n",
        "        curve_result = curve_fn(sample_true, prediction.values[index])\n",
        "        curve_samples[prediction.model_name].append(curve_result)\n",
        "\n",
        "  interp_points = np.linspace(0, 1, n_interp)\n",
        "  bootstrapped_curves = {}\n",
        "  for model_name, samples in curve_samples.items():\n",
        "    interp_values = []\n",
        "    for sample in samples:\n",
        "      sample_interp = np.interp(\n",
        "          interp_points,\n",
        "          sample.value_array_x,\n",
        "          sample.value_array_y,\n",
        "      )\n",
        "      interp_values.append(sample_interp)\n",
        "    mean_interp = np.mean(interp_values, axis=0)\n",
        "    stddev_interp = np.std(interp_values, axis=0)\n",
        "    lower_percentile = (100 - ci_level) / 2\n",
        "    upper_percentile = 100 - lower_percentile\n",
        "    percentiles = [lower_percentile, upper_percentile]\n",
        "    ci_lower, ci_upper = np.percentile(a=interp_values, q=percentiles, axis=0)\n",
        "    ci_lower = np.maximum(ci_lower, 0)\n",
        "    ci_upper = np.minimum(ci_upper, 1)\n",
        "    bootstrapped_curves[model_name] = CurveBootstrapResult(\n",
        "        curve_type,\n",
        "        mean_interp,\n",
        "        stddev_interp,\n",
        "        len(sample_indices),\n",
        "        ci_level,\n",
        "        ci_upper,\n",
        "        ci_lower,\n",
        "        interp_points,\n",
        "    )\n",
        "\n",
        "  return bootstrapped_curves\n",
        "\n",
        "\n",
        "def _generate_sample_indices(\n",
        "    label: Label,\n",
        "    is_binary: bool,\n",
        "    num_bootstrap: int,\n",
        "    seed: int,\n",
        ") -\u003e List[IndexSample]:\n",
        "  \"\"\"Returns a list of `num_bootstrap` randomly sampled bootstrap indices.\n",
        "\n",
        "  Args:\n",
        "    label: The ground truth label targets.\n",
        "    is_binary: Whether to generate valid binary samples; i.e., each index sample\n",
        "      contains at least one index corresponding to a label from each class.\n",
        "    num_bootstrap: The number of bootstrap indices to generate.\n",
        "    seed: The random seed; set prior to generating bootstrap indices.\n",
        "\n",
        "  Returns:\n",
        "    A list of `num_bootstrap` bootstrap sample indices.\n",
        "  \"\"\"\n",
        "  rng = np.random.default_rng(seed)\n",
        "  num_observations = len(label)\n",
        "  sample_indices = []\n",
        "  while len(sample_indices) \u003c num_bootstrap:\n",
        "    index = rng.integers(0, high=num_observations, size=num_observations)\n",
        "    sample_true = label.values[index]\n",
        "    # If computing a binary metric, skip indices that result in invalid labels.\n",
        "    if is_binary and not is_valid_binary_label(sample_true):\n",
        "      continue\n",
        "    sample_indices.append(index)\n",
        "  return sample_indices\n",
        "\n",
        "\n",
        "def _validate_and_mask(\n",
        "    label: Label,\n",
        "    predictions: Sequence[Prediction],\n",
        "    mask: Optional[np.ndarray] = None,\n",
        ") -\u003e Tuple[Label, List[Prediction]]:\n",
        "  \"\"\"Validates bootstrap argument shape and applies the mask if needed.\"\"\"\n",
        "  for prediction in predictions:\n",
        "    if len(label) != len(prediction):\n",
        "      raise ValueError('Label and prediction dimensions do not match.')\n",
        "  if mask is not None and len(mask) != len(label):\n",
        "    raise ValueError('Label and prediction dimensions do not match mask.')\n",
        "  if mask is not None:\n",
        "    label = Label(label.name, label.values[mask])\n",
        "    predictions = [\n",
        "        Prediction(\n",
        "            name=label.name, values=p.values[mask], model_name=p.model_name\n",
        "        )\n",
        "        for p in predictions\n",
        "    ]\n",
        "  return label, predictions\n",
        "\n",
        "\n",
        "def bootstrap_curves(\n",
        "    label: Label,\n",
        "    predictions: Sequence[Prediction],\n",
        "    mask: Optional[np.ndarray] = None,\n",
        "    n_bootstrap: int = 0,\n",
        "    conf_interval: float = 95,\n",
        "    n_interp: int = 1000,\n",
        "    seed: int = 42,\n",
        ") -\u003e Dict[CurveType, Dict[str, CurveBootstrapResult]]:\n",
        "  \"\"\"Returns confidence intervals for ROC and precision-recall curves.\"\"\"\n",
        "  label, predictions = _validate_and_mask(label, predictions, mask)\n",
        "  sample_indices = _generate_sample_indices(  # pylint: disable=protected-access\n",
        "      label,\n",
        "      is_binary=True,\n",
        "      num_bootstrap=n_bootstrap,\n",
        "      seed=seed,\n",
        "  )\n",
        "  curve_samples_kwargs = []\n",
        "  curve_fns = {CurveType.ROC: _roc_curve, CurveType.PR: _precision_recall_curve}\n",
        "  for curve_type, curve_fn in curve_fns.items():\n",
        "    curve_samples_kwargs.append({\n",
        "        'curve_type': curve_type,\n",
        "        'curve_fn': curve_fn,\n",
        "        'label': label,\n",
        "        'predictions': predictions,\n",
        "        'sample_indices': sample_indices,\n",
        "        'ci_level': conf_interval,\n",
        "        'n_interp': n_interp,\n",
        "    })\n",
        "\n",
        "  with concurrent.futures.ThreadPoolExecutor(len(curve_fns)) as executor:\n",
        "    curve_samples = list(\n",
        "        executor.map(\n",
        "            lambda arg_map: _bootstrap_curve(**arg_map), curve_samples_kwargs\n",
        "        )\n",
        "    )\n",
        "  return {\n",
        "      curve_type: curve_sample\n",
        "      for curve_type, curve_sample in zip(curve_fns, curve_samples)\n",
        "  }\n",
        "\n",
        "\n",
        "def build_ordered_maps(\n",
        "    labels_df: pd.DataFrame,\n",
        "    label_cols: Sequence[str],\n",
        "    model_id_to_preds: Mapping[str, pd.DataFrame],\n",
        "    model_id_to_pred_col: Mapping[str, str],\n",
        "    target_eids: Optional[AbstractSet[int]],\n",
        ") -\u003e Tuple[Dict[str, np.ndarray], Dict[str, np.ndarray]]:\n",
        "  \"\"\"Returns maps of labels and model IDs to consistently ordered numpy arrays.\n",
        "\n",
        "  When computing performance metrics in bootstrapping or thresholding, the label\n",
        "  and predictions numpy arrays must be consistently ordered so that each index\n",
        "  corresponds to the same sample. This function joins and returns the target\n",
        "  labels and model predictions so that the ordering is consistent across arrays.\n",
        "\n",
        "  Args:\n",
        "    labels_df: The labels dataframe.\n",
        "    label_cols: A list of target label columns from `labels_df`.\n",
        "    model_id_to_preds: A mapping of model IDs to model predictions.\n",
        "    model_id_to_pred_col: A mapping of model IDs to the target prediction column\n",
        "      from the model's corresponding value in `model_id_to_preds`.\n",
        "    target_eids: A set of EIDs to which labels and predictions are restricted.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of dictionaries mapping labels and model IDs to consistently ordered\n",
        "    numpy arrays.\n",
        "  \"\"\"\n",
        "  tmp_label_cols = {label_col: f'{label_col}_label' for label_col in label_cols}\n",
        "  tmp_pred_cols = {\n",
        "      model_id: f'{model_id}:{pred_col}'\n",
        "      for model_id, pred_col in model_id_to_pred_col.items()\n",
        "  }\n",
        "  if not set(tmp_label_cols.values()).isdisjoint(set(tmp_pred_cols.values())):\n",
        "    raise ValueError(f'Column conflict: {tmp_label_cols} v.s. {tmp_pred_cols}')\n",
        "\n",
        "  # Build and merge eid-column dataframes for each label and model prediction.\n",
        "  merged_df = labels_df[['eid'] + list(label_cols)]\n",
        "  merged_df = merged_df.rename(columns=tmp_label_cols)\n",
        "  for model_id, model_preds in model_id_to_preds.items():\n",
        "    pred_col = model_id_to_pred_col[model_id]\n",
        "    pred_df = model_preds[['eid', pred_col]]\n",
        "    pred_df = pred_df.rename(columns={pred_col: tmp_pred_cols[model_id]})\n",
        "    merged_df = merged_df.merge(pred_df, on='eid', how='inner')\n",
        "\n",
        "  # Filter to target eids if specified and ensure we have no NaN values.\n",
        "  if target_eids:\n",
        "    merged_df = merged_df[merged_df.eid.isin(target_eids)]\n",
        "    assert len(merged_df) == len(target_eids)\n",
        "  for label_col in tmp_label_cols.values():\n",
        "    print(\n",
        "        f'Dropping {sum(~merged_df[label_col].notna())} NaNs from \"{label_col}\"'\n",
        "    )\n",
        "    merged_df = merged_df.dropna(subset=[label_col])\n",
        "  assert (merged_df[list(tmp_label_cols.values())].notna()).all(axis=None)\n",
        "  assert (merged_df[list(tmp_pred_cols.values())].notna()).all(axis=None)\n",
        "\n",
        "  label_to_np = {}\n",
        "  for label_col, tmp_label_col in tmp_label_cols.items():\n",
        "    label_to_np[label_col] = merged_df[tmp_label_col].to_numpy()\n",
        "  model_id_to_np = {}\n",
        "  for model_id, tmp_pred_col in tmp_pred_cols.items():\n",
        "    model_id_to_np[model_id] = merged_df[tmp_pred_col].to_numpy()\n",
        "  return label_to_np, model_id_to_np\n",
        "\n",
        "\n",
        "def _build_bootstrap_inputs(\n",
        "    labels_df: pd.DataFrame,\n",
        "    label_col: str,\n",
        "    model_id_to_preds: Mapping[str, pd.DataFrame],\n",
        "    model_id_to_pred_col: Mapping[str, str],\n",
        "    target_eids: Optional[AbstractSet[int]],\n",
        ") -\u003e Tuple[Label, List[Prediction]]:\n",
        "  \"\"\"Returns a bootstrap label and predictions with matching EID order.\"\"\"\n",
        "  label_to_np, model_id_to_np = build_ordered_maps(\n",
        "      labels_df,\n",
        "      [label_col],\n",
        "      model_id_to_preds,\n",
        "      model_id_to_pred_col,\n",
        "      target_eids,\n",
        "  )\n",
        "  label = Label(label_col, label_to_np[label_col])\n",
        "  preds = []\n",
        "  for model_id, pred_values in model_id_to_np.items():\n",
        "    pred_col = model_id_to_pred_col[model_id]\n",
        "    preds.append(Prediction(pred_col, pred_values, model_id))\n",
        "  return label, preds\n",
        "\n",
        "\n",
        "def _validate_bootstrap_model_pred_args(\n",
        "    labels_df: pd.DataFrame,\n",
        "    label_col: str,\n",
        "    model_id_to_preds: Mapping[str, pd.DataFrame],\n",
        "    model_id_to_pred_col: Mapping[str, str],\n",
        "    model_id_to_threshold: Optional[Mapping[str, float]],\n",
        "    target_eids: Optional[AbstractSet[int]],\n",
        ") -\u003e None:\n",
        "  \"\"\"Ensures `bootstrap_model_preds` args match expected structured.\"\"\"\n",
        "  # The label dataframe must contain the target column and EIDs.\n",
        "  labels_columns = set(labels_df.columns)\n",
        "  if label_col not in labels_columns:\n",
        "    raise ValueError(f'Unexpected label column: {label_col}')\n",
        "  if target_eids and not set(target_eids).issubset(set(labels_df.eid)):\n",
        "    raise ValueError('Labels dataframe missing target EIDs.')\n",
        "\n",
        "  # All model maps must contain the same set of model IDs.\n",
        "  model_ids = set(model_id_to_preds)\n",
        "  if model_ids != set(model_id_to_pred_col):\n",
        "    raise ValueError(\n",
        "        f'Mismatched model IDs in map: {model_id_to_preds} '\n",
        "        f'v.s. {set(model_id_to_pred_col)}'\n",
        "    )\n",
        "  if model_id_to_threshold and model_ids != set(model_id_to_threshold):\n",
        "    raise ValueError(\n",
        "        f'Mismatched model IDs in map: {model_id_to_preds} '\n",
        "        f'v.s. {set(model_id_to_threshold)}'\n",
        "    )\n",
        "\n",
        "  # All model dataframes must contain the prediction column and target EIDs.\n",
        "  for model_id, model_preds in model_id_to_preds.items():\n",
        "    model_eids = set(model_preds.eid)\n",
        "    pred_col = model_id_to_pred_col[model_id]\n",
        "    model_cols = model_preds.columns\n",
        "    if pred_col not in model_cols:\n",
        "      raise ValueError(\n",
        "          f'Unexpected \"{model_id}\" prediction column: '\n",
        "          f'\"{pred_col}\" not in {model_cols}'\n",
        "      )\n",
        "    if target_eids and not set(target_eids).issubset(model_eids):\n",
        "      raise ValueError(f'\"{model_id}\" dataframe missing target EIDs.')\n",
        "\n",
        "\n",
        "def bootstrap_curves_model_preds(\n",
        "    labels_df: pd.DataFrame,\n",
        "    label_col: str,\n",
        "    model_id_to_preds: Mapping[str, pd.DataFrame],\n",
        "    model_id_to_pred_col: Mapping[str, str],\n",
        "    target_eids: Optional[AbstractSet[int]] = None,\n",
        "    n_bootstrap: int = 100,\n",
        "    n_interp: int = 1000,\n",
        "    seed: int = 42,\n",
        ") -\u003e Dict[CurveType, Dict[str, CurveBootstrapResult]]:\n",
        "  \"\"\"Returns a bootstrap curve results dictionary for the label and predictions.\n",
        "\n",
        "  Args:\n",
        "    labels_df: The labels dataframe.\n",
        "    label_col: The target label column from `labels_df`.\n",
        "    model_id_to_preds: A mapping of model IDs to model predictions.\n",
        "    model_id_to_pred_col: A mapping of model IDs to the target prediction column\n",
        "      from the model's corresponding value in `model_id_to_preds`.\n",
        "    target_eids: A set of EIDs to which labels and predictions are restricted.\n",
        "    n_bootstrap: The number of bootstrapping iterations.\n",
        "    n_interp: The number of points to interpolate along curve samples.\n",
        "    seed: The random seed.\n",
        "\n",
        "  Returns:\n",
        "    A dictionary mapping curve types to the corresponding model-curve bootstrap\n",
        "    results mapping for the label and predictions.\n",
        "  \"\"\"\n",
        "  _validate_bootstrap_model_pred_args(\n",
        "      labels_df,\n",
        "      label_col,\n",
        "      model_id_to_preds,\n",
        "      model_id_to_pred_col,\n",
        "      None,\n",
        "      target_eids,\n",
        "  )\n",
        "  label, preds = _build_bootstrap_inputs(\n",
        "      labels_df,\n",
        "      label_col,\n",
        "      model_id_to_preds,\n",
        "      model_id_to_pred_col,\n",
        "      target_eids,\n",
        "  )\n",
        "  return bootstrap_curves(\n",
        "      label,\n",
        "      preds,\n",
        "      n_bootstrap=n_bootstrap,\n",
        "      n_interp=n_interp,\n",
        "      seed=seed,\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhWaf1lP52on"
      },
      "source": [
        "## Load labels and model predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fdgLwd0i9Gu"
      },
      "outputs": [],
      "source": [
        "DATA_FILEPATH = '/path/to/data.tsv'\n",
        "REQUIRED_COLUMNS = {\n",
        "    'eid',\n",
        "    'copd_all_srcs_subset',\n",
        "    'copd_hesin_primary_after',\n",
        "    'copd_death_primary',\n",
        "    'blow_ratio_risk',\n",
        "    'blow_fev1_pct_pred_norm_risk',\n",
        "    'ml_based_copd',\n",
        "}\n",
        "\n",
        "with open(DATA_FILEPATH, mode='r') as f:\n",
        "  g_data_df = pd.read_csv(f, sep='\\t', index_col=None)\n",
        "\n",
        "assert REQUIRED_COLUMNS.issubset(set(g_data_df.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GahU2RwTlzUU"
      },
      "outputs": [],
      "source": [
        "# Coerce the input dataframe into the format expected by utilities.\n",
        "LABELS = [\n",
        "    'copd_all_srcs_subset',\n",
        "    'copd_hesin_primary_after',\n",
        "    'copd_death_primary',\n",
        "]\n",
        "MODEL_IDS = [\n",
        "    'blow_ratio_risk',\n",
        "    'blow_fev1_pct_pred_norm_risk',\n",
        "    'ml_based_copd',\n",
        "]\n",
        "g_label_df = g_data_df[['eid', *LABELS]].copy()\n",
        "g_model_id_to_preds = {m: g_data_df[['eid', m]].copy() for m in MODEL_IDS}\n",
        "g_model_id_to_pred_col = {m: m for m in MODEL_IDS}\n",
        "g_validation_eids = set(g_data_df.eid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R41oOmEgeDOc"
      },
      "source": [
        "### Load and preprocess Kaplan-meier curves from survival analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgIRdXadeIdU"
      },
      "outputs": [],
      "source": [
        "KM_ML_DATA_FILEPATH = '/path/to/ml_based_copd_km_data.tsv'\n",
        "km_curves = df_to_km_curves(pathlib.Path(KM_ML_DATA_FILEPATH))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfAGSAvmVjQ3"
      },
      "source": [
        "## Build Figure 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBXJngD7wjot"
      },
      "source": [
        "### Bootstrap performance curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASBlAR0WWbq4"
      },
      "outputs": [],
      "source": [
        "# Bootstrap curve results for each model over all labels.\n",
        "g_label_to_type_to_result = {\n",
        "    label_col: bootstrap_curves_model_preds(\n",
        "        labels_df=g_label_df,\n",
        "        label_col=label_col,\n",
        "        model_id_to_preds=g_model_id_to_preds,\n",
        "        model_id_to_pred_col=g_model_id_to_pred_col,\n",
        "        target_eids=g_validation_eids,\n",
        "        n_bootstrap=100,\n",
        "    )\n",
        "    for label_col in LABELS\n",
        "}\n",
        "\n",
        "# Convert bootstrap result representations to ROC plotting representation.\n",
        "g_label_to_type_to_curves = bs_curves_to_fig_curves(g_label_to_type_to_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9p-1XunW_PU"
      },
      "source": [
        "### Plot subfigures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqRgpZkn3VGL"
      },
      "outputs": [],
      "source": [
        "g_legend_overrides = {\n",
        "    'blow_ratio_risk': 'FEV1/FVC Ratio',\n",
        "    'blow_fev1_pct_pred_norm_risk': 'FEV1 Percent Predicted',\n",
        "    'ml_based_copd': 'Flow-volume ResNet18',\n",
        "}\n",
        "\n",
        "fig, axes = plt.subplots(3, 3, figsize=(9, 9), dpi=300)\n",
        "\n",
        "# Plot COPD risk curves.\n",
        "plot_roc_curves(\n",
        "    g_label_to_type_to_curves[LABELS[0]][RocCurve],\n",
        "    g_legend_overrides,\n",
        "    inset_xlim=(0.1, 0.4),\n",
        "    inset_ylim=(0.6, 0.85),\n",
        "    ax=axes[0][0],\n",
        "    plot_legend=False,\n",
        "    title='COPD status ROC curves',\n",
        ")\n",
        "plot_pr_curves(\n",
        "    g_label_to_type_to_curves[LABELS[0]][PrecisionRecallCurve],\n",
        "    g_legend_overrides,\n",
        "    plot_marker=False,\n",
        "    ax=axes[1][0],\n",
        "    plot_legend=False,\n",
        "    title='COPD status PR curves',\n",
        ")\n",
        "\n",
        "# Plot COPD hospitalization curves.\n",
        "plot_roc_curves(\n",
        "    g_label_to_type_to_curves[LABELS[1]][RocCurve],\n",
        "    g_legend_overrides,\n",
        "    inset_xlim=(0.05, 0.35),\n",
        "    inset_ylim=(0.7, 0.95),\n",
        "    ax=axes[0][1],\n",
        "    plot_legend=False,\n",
        "    title='COPD hospitalization ROC curves',\n",
        ")\n",
        "plot_pr_curves(\n",
        "    g_label_to_type_to_curves[LABELS[1]][PrecisionRecallCurve],\n",
        "    g_legend_overrides,\n",
        "    plot_marker=False,\n",
        "    ax=axes[1][1],\n",
        "    plot_legend=False,\n",
        "    title='COPD hospitalization PR curves',\n",
        ")\n",
        "\n",
        "# Plot COPD death curves.\n",
        "plot_roc_curves(\n",
        "    g_label_to_type_to_curves[LABELS[2]][RocCurve],\n",
        "    g_legend_overrides,\n",
        "    inset_xlim=(0.00, 0.30),\n",
        "    inset_ylim=(0.70, 0.95),\n",
        "    ax=axes[0][2],\n",
        "    plot_legend=False,\n",
        "    title='COPD death ROC curves',\n",
        ")\n",
        "plot_pr_curves(\n",
        "    g_label_to_type_to_curves[LABELS[2]][PrecisionRecallCurve],\n",
        "    g_legend_overrides,\n",
        "    plot_marker=False,\n",
        "    ax=axes[1][2],\n",
        "    plot_legend=False,\n",
        "    title='COPD death PR curves',\n",
        ")\n",
        "\n",
        "# Plot KM curves along the entirety of the bottom row.\n",
        "grid_spec = axes[-1][0].get_gridspec()\n",
        "for ax in axes[-1, 0:]:\n",
        "  ax.remove()\n",
        "km_ax = fig.add_subplot(grid_spec[-1, 0:])\n",
        "plot_km_curves(km_curves, legend_title='Risk group', ax=km_ax)\n",
        "\n",
        "# Note: We add labels before `tight_layout` so that spacing is preserved.\n",
        "# Note: The definition of \"labeled_axes\" is a bit of hack so that we only\n",
        "# label \"major\" subplot axes (ie., insets should not be labeled.).\n",
        "labeled_axes = [ax for ax in fig.get_axes() if ax.get_ylabel()]\n",
        "for i, ax in enumerate(labeled_axes):\n",
        "  ax_label = string.ascii_lowercase[i]\n",
        "  # label physical distance to the left and up scaled by dpi:\n",
        "  trans = transforms.ScaledTranslation(-20 / 72, 7 / 72, fig.dpi_scale_trans)\n",
        "  ax.text(\n",
        "      0.0,\n",
        "      1.0,\n",
        "      ax_label,\n",
        "      transform=ax.transAxes + trans,\n",
        "      fontsize='8',\n",
        "      va='bottom',\n",
        "      fontfamily='Helvetica',\n",
        "      weight='bold',\n",
        "  )\n",
        "\n",
        "  # Per natgen formatting, remove the spines from named axes (i.e., keep the\n",
        "  # spine on insets).\n",
        "  ax.spines[['right', 'top']].set_visible(False)\n",
        "\n",
        "# Per natgen formatting, remove the grid from all axes.\n",
        "for ax in fig.get_axes():\n",
        "  ax.grid(False)\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "axes[0, 1].legend(\n",
        "    loc='lower center',\n",
        "    bbox_to_anchor=(-0.75, 1.1, 2.5, 1.02),\n",
        "    borderaxespad=0,\n",
        "    frameon=False,\n",
        "    mode='expand',\n",
        "    ncol=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bp3LNj1IbHPu"
      },
      "outputs": [],
      "source": [
        "fig.savefig('figure_3.pdf', dpi=300, format='pdf', bbox_inches='tight')\n",
        "%download_file figure_3.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvA9IisSddjk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//learning/genomics/internal:genomics_colab",
        "kind": "private"
      },
      "name": "figure_3.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/experimental/genomics/spirometry/manuscript/notebooks/scratch.ipynb?workspaceId=jtcosentino:spiro_analysis_data_02::citc",
          "timestamp": 1638904376825
        },
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/phenotyping/spirometry/notebooks/spiro_to_covars_model_performance.ipynb?workspaceId=jtcosentino:spiro_analysis_data_02::citc",
          "timestamp": 1638316292908
        },
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/phenotyping/spirometry/notebooks/ratio_model_performance.ipynb?workspaceId=jtcosentino:spiro_analysis_data_03::citc",
          "timestamp": 1636154704898
        },
        {
          "file_id": "1CzTGP1PbyxGJiixCOyXWMzxze2weDSc8",
          "timestamp": 1636055746256
        },
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/analysis/bootstrap_df_ensemble.ipynb?workspaceId=jtcosentino:bootstrap02_external_api::citc",
          "timestamp": 1634667228095
        },
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/analysis/bootstrap_df.ipynb?workspaceId=jtcosentino:spiro000_analysis4::citc",
          "timestamp": 1632785622101
        },
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/analysis/bootstrap_df.ipynb?workspaceId=jtcosentino:bootstrap02_external_api::citc",
          "timestamp": 1632785479574
        },
        {
          "file_id": "12P51rZaYf8XCb1ZaPzt9agbqTHLz_PVi",
          "timestamp": 1632337104372
        }
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
