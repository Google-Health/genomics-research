{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZS2ejZGBZt1D"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# Copyright 2022 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wuQMVINbR4t"
      },
      "source": [
        "# Generates Figure 4 from Cosentino et al. Nature Genetics 2023\n",
        "\n",
        "This notebook builds the GWAS comparison subfigures for Figure 4 of the ML-based\n",
        "COPD manuscript (Cosentino et al. Nature Genetics 2023).\n",
        "\n",
        "This notebook also generates the following Extended Data and Supplementary GWAS\n",
        "comparison Figures:\n",
        "\n",
        "-   Extended Data Figure 5: Statistical power comparison of ML-based COPD with\n",
        "    Hobbs et al. Nature Genetics 2017 COPD GWAS.\n",
        "-   Extended Data Figure 6: Statistical power comparison of ML-based COPD\n",
        "    without MRB COPD cases with Hobbs et al. Nature Genetics 2017 COPD GWAS.\n",
        "-   Extended Data Figure 7: Statistical power comparison of binarized ML-based\n",
        "    COPD with Sakornsakolpat et al. Nature Genetics 2019.\n",
        "-   Extended Data Figure 8: Statistical power comparison of binarized ML-based\n",
        "    COPD matching GOLD prevalence with Sakornsakolpat et al. Nature\n",
        "    Genetics 2019.\n",
        "-   Supplementary Figure 12: Statistical power comparison of ML-based COPD with\n",
        "    GBMI COPD excluding UKB.\n",
        "-   Supplementary Figure 14: Statistical power comparison of binarized ML-based\n",
        "    COPD with medical-record-based COPD labels.\n",
        "-   Supplementary Figure 15: Statistical power comparison of proxy-GOLD with\n",
        "    Sakornsakolpat et al Nature Genetics 2019.\n",
        "-   Supplementary Figure 17: Statistical power comparison of proxy-GOLD label\n",
        "    using BOLT-LMM vs Regenie.\n",
        "\n",
        "**Important: Generating all figures requires populating the\n",
        "`ASSOC_RESULTS_BASE_DIR` directory with expected data files.** Each GWAS\n",
        "requires a hits, loci, and filtered GWAS results file\n",
        "(`{}.association_results.annotated_hits.tsv`, `{}.association_results.loci.tsv`,\n",
        "and `{}.association_results.filtered.tsv`, respectively). The notebook expects\n",
        "following filename prefixes for each GWAS:\n",
        "\n",
        "-   `ml_based_copd`: Our ML-based COPD liability score.\n",
        "-   `ml_based_copd_no_mrb_cases`: Our ML-based COPD liability score with\n",
        "    medical-record-based COPD cases removed.\n",
        "-   `hobbs_natgen_2017`: Hobbs et al. Nature Genetics 2017.\n",
        "-   `ml_based_copd_binarized_gold_prev`: ML-based COPD binarized to match proxy\n",
        "    GOLD prevalence.\n",
        "-   `sakornsakolpat_natgen_2019`: Sakornsakolpat et al. Nature Genetics 2019.\n",
        "-   `ml_based_copd_binarized`: ML-based COPD binarized to a 50-50 case-control\n",
        "    split.\n",
        "-   `mrb_labels_copd`: Medical-record-based COPD.\n",
        "-   `spiro_gold_copd`: Proxy GOLD COPD.\n",
        "-   `gbmi_excluding_ukb_copd`: Global Biobank Meta-analysis Initiative.\n",
        "-   `spiro_gold_copd_regenie`: Proxy GOLD COPD run with Regenie.\n",
        "-   `spiro_gold_copd_bolt`: Proxy GOLD COPD run with BOLT-LMM.\n",
        "\n",
        "We provide these files in our\n",
        "[GitHub repository](https://github.com/Google-Health/genomics-research/tree/main/ml-based-copd)\n",
        "for all GWAS *except* those from external data sources: `hobbs_natgen_2017`,\n",
        "`sakornsakolpat_natgen_2019`, and `gbmi_excluding_ukb_copd`. See the\n",
        "corresponding manuscripts for details on how to access each data source. Once\n",
        "downloaded, simply convert the summary statistics to match the schema outlined\n",
        "in the provided files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfLSjmO1MI2I"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import copy\n",
        "import csv\n",
        "import dataclasses\n",
        "import decimal\n",
        "import io\n",
        "import tempfile\n",
        "import os\n",
        "import typing\n",
        "from typing import Any, Dict, Generator, List, Sequence, Union, NamedTuple, Optional, Tuple\n",
        "\n",
        "from absl import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "from matplotlib import rcParams\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RB8wl4TMlUj"
      },
      "outputs": [],
      "source": [
        "def set_matplotib_settings():\n",
        "  rcParams['text.usetex'] = 'False'\n",
        "  rcParams['font.family'] = 'Helvetica'\n",
        "  rcParams['savefig.dpi'] = 300\n",
        "  rcParams['savefig.transparent'] = True\n",
        "  rcParams['font.size'] = 7\n",
        "\n",
        "  # Note: font types are needed to edit in Adobe Illustrator.\n",
        "  rcParams['pdf.fonttype'] = 42\n",
        "  rcParams['ps.fonttype'] = 42\n",
        "\n",
        "\n",
        "set_matplotib_settings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o04eJJewQORW"
      },
      "outputs": [],
      "source": [
        "# Directory containing all GWAS annotated hits, loci, and filtered result files.\n",
        "ASSOC_RESULTS_BASE_DIR = '/path/to/association_results'\n",
        "\n",
        "# Expected suffixes for each type of GWAS results files.\n",
        "ASSOC_RESULTS_HITS_SUFFIX = '.association_results.annotated_hits.tsv'\n",
        "ASSOC_RESULTS_LOCI_SUFFIX = '.association_results.loci.tsv'\n",
        "ASSOC_RESULTS_FILTERED_SUFFIX = '.association_results.filtered.tsv'\n",
        "\n",
        "\n",
        "# Denotes the chromosome offsets needed for a Manhattan plot. Chromosome sizes\n",
        "# can be obtained from UCSC. For example, for the Genome Reference Consortium\n",
        "# Human Reference 37, it can be downloaded from:\n",
        "# https://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/hg19.chrom.sizes\n",
        "CHROM_OFFSETS = collections.OrderedDict([\n",
        "    ('1', 0),\n",
        "    ('2', 249250621),\n",
        "    ('3', 492449994),\n",
        "    ('4', 690472424),\n",
        "    ('5', 881626700),\n",
        "    ('6', 1062541960),\n",
        "    ('7', 1233657027),\n",
        "    ('8', 1392795690),\n",
        "    ('9', 1539159712),\n",
        "    ('10', 1680373143),\n",
        "    ('11', 1815907890),\n",
        "    ('12', 1950914406),\n",
        "    ('13', 2084766301),\n",
        "    ('14', 2199936179),\n",
        "    ('15', 2307285719),\n",
        "    ('16', 2409817111),\n",
        "    ('17', 2500171864),\n",
        "    ('18', 2581367074),\n",
        "    ('19', 2659444322),\n",
        "    ('20', 2718573305),\n",
        "    ('21', 2781598825),\n",
        "    ('22', 2829728720),\n",
        "    ('$', 2881033286),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RenRI6evZH5e"
      },
      "source": [
        "## Utilities for parsing annotated hits, loci, and filtered GWAS results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGX4KvdVQPuw"
      },
      "outputs": [],
      "source": [
        "ArbitraryPrecisionReal = Union[float, decimal.Decimal]\n",
        "\n",
        "\n",
        "def pvalue_str_to_numeric(pvalue_str: str) -\u003e ArbitraryPrecisionReal:\n",
        "  \"\"\"Returns p-value as a float if possible, otherwise as Decimal.\"\"\"\n",
        "  float_value = float(pvalue_str)\n",
        "  if float_value != 0:\n",
        "    return float_value\n",
        "\n",
        "  # Analytically computed p-values from GWAS software can write out p-values\n",
        "  # that are too small to be represented by a float value, e.g. '1e-500'. In\n",
        "  # these cases we represent the result using an arbitrary-precision Decimal\n",
        "  # instead. But if the value written is truly 0, then we just use the float.\n",
        "  decimal_value = decimal.Decimal(pvalue_str)\n",
        "  if decimal_value == 0:\n",
        "    return 0.0\n",
        "  return decimal_value\n",
        "\n",
        "\n",
        "def _validate_assoc_result(\n",
        "    vid: str,\n",
        "    chrom: str,\n",
        "    bp: int,\n",
        "    ref: str,\n",
        "    alt: str,\n",
        "    rsid: str,\n",
        "    affx: str,\n",
        "    eff: str,\n",
        "    alt_freq: float,\n",
        "    num_indv: int,\n",
        "    src: str,\n",
        "    info_score: float,\n",
        "    p_hwe_pop: ArbitraryPrecisionReal,\n",
        "    p: ArbitraryPrecisionReal,\n",
        "    beta: float,\n",
        "    se: float,\n",
        "    ctrl_cnt: Optional[int],\n",
        "    case_cnt: Optional[int],\n",
        ") -\u003e None:\n",
        "  \"\"\"Raises ValueError if inputs are not a valid AssocResult.\"\"\"\n",
        "  # 20 is derived from l.g.medgen.util.variant_tools._MAX_VARIANT_ID_LENGTH\n",
        "  # We avoid its dependency since it brings in Nucleus as well.\n",
        "  if len(vid) \u003e 20:\n",
        "    raise ValueError(f'Unexpected variant id: {vid}')\n",
        "  if bp \u003c= 0:\n",
        "    raise ValueError(f'Invalid non-positive bp: {bp}')\n",
        "  if ref == alt:\n",
        "    raise ValueError(f'Ref and alt must be distinct: {ref} vs {alt}')\n",
        "  if eff not in [ref, alt]:\n",
        "    raise ValueError(\n",
        "        f'Effect allele must be one of ref or alt: {eff}, [{ref}, {alt}]'\n",
        "    )\n",
        "  if not 0 \u003c= alt_freq \u003c= 1:\n",
        "    raise ValueError(f'Alt allele frequency must be in [0, 1]: {alt_freq}')\n",
        "  if num_indv \u003c 1:\n",
        "    raise ValueError(f'Number of individuals must be positive: {num_indv}')\n",
        "  if src not in ['Genotyped', 'Imputed']:\n",
        "    raise ValueError(f'Unexpected source: {src}')\n",
        "  if not 0 \u003c= info_score \u003c= 1:\n",
        "    raise ValueError(f'INFO score must be in [0, 1]: {info_score}')\n",
        "  if src == 'Genotyped' and info_score != 1:\n",
        "    raise ValueError(\n",
        "        f'INFO score for genotyped variants must be 1: {info_score}'\n",
        "    )\n",
        "  if not 0 \u003c= p_hwe_pop \u003c= 1:\n",
        "    raise ValueError(f'HWE p-value must be in [0, 1]: {p_hwe_pop}')\n",
        "  if not 0 \u003c= p \u003c= 1:\n",
        "    raise ValueError(f'Association p-value must be in [0, 1]: {p}')\n",
        "  if se \u003c 0:\n",
        "    raise ValueError(f'Standard error must be positive: {se}')\n",
        "  if (ctrl_cnt is None) != (case_cnt is None):\n",
        "    raise ValueError(\n",
        "        'ctrl_cnt and case_cnt must either both be None or neither'\n",
        "        f' be None: {ctrl_cnt} vs {case_cnt}'\n",
        "    )\n",
        "  if ctrl_cnt is not None and ctrl_cnt \u003c 0:\n",
        "    raise ValueError(f'Non-None ctrl_cnt must be non-negative: {ctrl_cnt}')\n",
        "  if case_cnt is not None and case_cnt \u003c 0:\n",
        "    raise ValueError(f'Non-None case_cnt must be non-negative: {case_cnt}')\n",
        "\n",
        "\n",
        "class AssocResult(\n",
        "    typing.NamedTuple(\n",
        "        'AssocResult',\n",
        "        [\n",
        "            ('vid', str),\n",
        "            ('chrom', str),\n",
        "            ('bp', int),\n",
        "            ('ref', str),\n",
        "            ('alt', str),\n",
        "            ('rsid', str),\n",
        "            ('affx', str),\n",
        "            ('eff', str),\n",
        "            ('alt_freq', float),\n",
        "            ('num_indv', int),\n",
        "            ('src', str),\n",
        "            ('info_score', float),\n",
        "            ('p_hwe_pop', ArbitraryPrecisionReal),\n",
        "            ('p', ArbitraryPrecisionReal),\n",
        "            ('beta', float),\n",
        "            ('se', float),\n",
        "            ('ctrl_cnt', Optional[int]),\n",
        "            ('case_cnt', Optional[int]),\n",
        "        ],\n",
        "    )\n",
        "):\n",
        "  \"\"\"Container class for GWAS pipeline association results.\n",
        "\n",
        "  This is suitable for representing individual lines from both\n",
        "  \"association_results.raw.tsv\" and \"association_results.filtered.tsv\" output\n",
        "  files generated by the GWAS pipeline.\n",
        "\n",
        "  Attributes:\n",
        "    vid: The variant ID.\n",
        "    chrom: The string representation of the chromosome.\n",
        "    bp: The 1-based base pair position of the variant.\n",
        "    ref: The reference allele of the variant. In [ACGT]+.\n",
        "    alt: The alternate allele of the variant. In [ACGT]+.\n",
        "    rsid: The rsid of the variant. If it does not exist, uses\n",
        "      normalization.EMPTY_FIELD_PLACEHOLDER instead.\n",
        "    affx: The Affymetrix ID of the variant. If it does not exist, uses\n",
        "      normalization.EMPTY_FIELD_PLACEHOLDER.\n",
        "    eff: The effect allele used for estimating `beta`. Must be one of the `ref`\n",
        "      or `alt` alleles.\n",
        "    alt_freq: The frequency of the `alt` allele.\n",
        "    num_indv: The number of individuals used to compute the association result.\n",
        "    src: The source of the variant (genotyped directly or imputed).\n",
        "    info_score: The INFO score of the variant. For genotyped variants, is 1.0.\n",
        "    p_hwe_pop: The population Hardy-Weinberg p-value of the variant.\n",
        "    p: The p-value of association.\n",
        "    beta: The effect size of the association.\n",
        "    se: The standard error of the effect size estimate.\n",
        "    ctrl_cnt: The number of controls present in the association result. This\n",
        "      field is only applicable for PLINK association runs of case/control\n",
        "      phenotypes; when it is not applicable this field is set to None.\n",
        "    case_cnt: The number of cases present in the association result. This field\n",
        "      is only applicable for PLINK association runs of case/control phenotypes;\n",
        "      when it is not applicable this field is set to None.\n",
        "  \"\"\"\n",
        "\n",
        "  __slots__ = ()\n",
        "\n",
        "  def __new__(\n",
        "      cls,\n",
        "      vid: str,\n",
        "      chrom: str,\n",
        "      bp: int,\n",
        "      ref: str,\n",
        "      alt: str,\n",
        "      rsid: str,\n",
        "      affx: str,\n",
        "      eff: str,\n",
        "      alt_freq: float,\n",
        "      num_indv: int,\n",
        "      src: str,\n",
        "      info_score: float,\n",
        "      p_hwe_pop: ArbitraryPrecisionReal,\n",
        "      p: ArbitraryPrecisionReal,\n",
        "      beta: float,\n",
        "      se: float,\n",
        "      ctrl_cnt: Optional[int],\n",
        "      case_cnt: Optional[int],\n",
        "  ) -\u003e 'AssocResult':\n",
        "    _validate_assoc_result(\n",
        "        vid=vid,\n",
        "        chrom=chrom,\n",
        "        bp=bp,\n",
        "        ref=ref,\n",
        "        alt=alt,\n",
        "        rsid=rsid,\n",
        "        affx=affx,\n",
        "        eff=eff,\n",
        "        alt_freq=alt_freq,\n",
        "        num_indv=num_indv,\n",
        "        src=src,\n",
        "        info_score=info_score,\n",
        "        p_hwe_pop=p_hwe_pop,\n",
        "        p=p,\n",
        "        beta=beta,\n",
        "        se=se,\n",
        "        ctrl_cnt=ctrl_cnt,\n",
        "        case_cnt=case_cnt,\n",
        "    )\n",
        "    return super().__new__(\n",
        "        cls,\n",
        "        vid=vid,\n",
        "        chrom=chrom,\n",
        "        bp=bp,\n",
        "        ref=ref,\n",
        "        alt=alt,\n",
        "        rsid=rsid,\n",
        "        affx=affx,\n",
        "        eff=eff,\n",
        "        alt_freq=alt_freq,\n",
        "        num_indv=num_indv,\n",
        "        src=src,\n",
        "        info_score=info_score,\n",
        "        p_hwe_pop=p_hwe_pop,\n",
        "        p=p,\n",
        "        beta=beta,\n",
        "        se=se,\n",
        "        ctrl_cnt=ctrl_cnt,\n",
        "        case_cnt=case_cnt,\n",
        "    )\n",
        "\n",
        "  @classmethod\n",
        "  def from_line(cls, line) -\u003e 'AssocResult':\n",
        "    \"\"\"Returns an AssocResult from its string representation.\"\"\"\n",
        "    tokens = line.strip().split('\\t')\n",
        "    if len(tokens) not in [17, 19]:\n",
        "      raise ValueError(\n",
        "          f'Expected 17 or 19 tokens in AssocResult, got {len(tokens)}: {line}'\n",
        "      )\n",
        "    if len(tokens) == 19:\n",
        "      ctrl_cnt, case_cnt = [int(x) for x in tokens[17:]]\n",
        "    else:\n",
        "      ctrl_cnt, case_cnt = None, None\n",
        "\n",
        "    return cls(\n",
        "        vid=tokens[0],\n",
        "        chrom=tokens[1],\n",
        "        bp=int(tokens[2]),\n",
        "        ref=tokens[3],\n",
        "        alt=tokens[4],\n",
        "        rsid=tokens[5],\n",
        "        affx=tokens[6],\n",
        "        eff=tokens[7],\n",
        "        alt_freq=float(tokens[8]),\n",
        "        num_indv=int(tokens[9]),\n",
        "        src=tokens[10],\n",
        "        info_score=float(tokens[11]),\n",
        "        # Note: We skip tokens[12] as that is the deprecated p_hwe_coh.\n",
        "        p_hwe_pop=pvalue_str_to_numeric(tokens[13]),\n",
        "        p=pvalue_str_to_numeric(tokens[14]),\n",
        "        beta=float(tokens[15]),\n",
        "        se=float(tokens[16]),\n",
        "        ctrl_cnt=ctrl_cnt,\n",
        "        case_cnt=case_cnt,\n",
        "    )\n",
        "\n",
        "  def __str__(self) -\u003e str:\n",
        "    \"\"\"Returns a string representation of self.\n",
        "\n",
        "    Note: Round tripping `__str__` and `from_line` are not guaranteed to be the\n",
        "    same due to float numerical issues.\n",
        "    \"\"\"\n",
        "    tokens = [\n",
        "        self.vid,\n",
        "        self.chrom,\n",
        "        str(self.bp),\n",
        "        self.ref,\n",
        "        self.alt,\n",
        "        self.rsid,\n",
        "        self.affx,\n",
        "        self.eff,\n",
        "        str(self.alt_freq),\n",
        "        str(self.num_indv),\n",
        "        self.src,\n",
        "        str(self.info_score),\n",
        "        # Supporting the old P_HWE_COH which is unused.\n",
        "        '.',\n",
        "        # Transform the p-values to .lower() so that scientific notation uses\n",
        "        # lowercase 'e' which is what our pipelines write out.\n",
        "        str(self.p_hwe_pop).lower(),\n",
        "        str(self.p).lower(),\n",
        "        str(self.beta),\n",
        "        str(self.se),\n",
        "    ]\n",
        "    if self.ctrl_cnt is not None:\n",
        "      # Add case and control counts if they are applicable.\n",
        "      tokens += [str(self.ctrl_cnt), str(self.case_cnt)]\n",
        "    return '\\t'.join(tokens)\n",
        "\n",
        "  def columns(self) -\u003e List[str]:\n",
        "    \"\"\"Returns the header column names corresponding to this.\"\"\"\n",
        "    cols = [\n",
        "        'VID',\n",
        "        'CHR',\n",
        "        'BP',\n",
        "        'REF',\n",
        "        'ALT',\n",
        "        'RS',\n",
        "        'AFFX',\n",
        "        'EFF',\n",
        "        'AAF',\n",
        "        'NUM_INDV',\n",
        "        'SRC',\n",
        "        'INFO_SCORE',\n",
        "        'P_HWE_COH',\n",
        "        'P_HWE_POP',\n",
        "        'P',\n",
        "        'BETA',\n",
        "        'SE',\n",
        "    ]\n",
        "    if self.ctrl_cnt is not None:\n",
        "      cols += ['CTRL_CNT', 'CASE_CNT']\n",
        "    return cols\n",
        "\n",
        "  @property\n",
        "  def maf(self) -\u003e float:\n",
        "    \"\"\"Returns the minor allele frequency.\"\"\"\n",
        "    return min(self.alt_freq, 1 - self.alt_freq)\n",
        "\n",
        "  @property\n",
        "  def name(self) -\u003e str:\n",
        "    \"\"\"Returns a human-readable name for the variant.\"\"\"\n",
        "    if self.rsid and self.rsid != '.':\n",
        "      return self.rsid\n",
        "    return f'{self.chrom}:{self.bp}_{self.ref}_{self.alt}'\n",
        "\n",
        "\n",
        "def _validate_annotated_locus(\n",
        "    assoc_result: AssocResult,\n",
        "    cluster_left_bp: int,\n",
        "    cluster_right_bp: int,\n",
        "    num_variants: int,\n",
        "    num_hits: int,\n",
        "    cytoband: str,\n",
        "    gene_context: str,\n",
        "    closest_genes: str,\n",
        "    replication_variants: 'collections.OrderedDict[str, str]',\n",
        ") -\u003e None:\n",
        "  \"\"\"Raises ValueError if inputs are not a valid AnnotatedLocus.\"\"\"\n",
        "  if cluster_left_bp \u003e assoc_result.bp:\n",
        "    raise ValueError(\n",
        "        'Cluster left bp must not be after locus index bp: '\n",
        "        f'{cluster_left_bp} vs {assoc_result.bp}'\n",
        "    )\n",
        "  if cluster_right_bp \u003c assoc_result.bp:\n",
        "    raise ValueError(\n",
        "        'Cluster right bp must not be before locus index bp: '\n",
        "        f'{cluster_right_bp} vs {assoc_result.bp}'\n",
        "    )\n",
        "  if num_hits \u003c 1:\n",
        "    raise ValueError(f'Num hits in locus must be at least 1: {num_hits}')\n",
        "  if num_variants \u003c num_hits:\n",
        "    raise ValueError(\n",
        "        'Num variants in locus must be \u003e= num hits: '\n",
        "        f'{num_variants} vs {num_hits}'\n",
        "    )\n",
        "\n",
        "\n",
        "def _load_replication_variants(\n",
        "    column_names: List[str], values: List[str]\n",
        ") -\u003e collections.OrderedDict:\n",
        "  if len(column_names) != len(values):\n",
        "    raise ValueError(\n",
        "        f'Non-matching number of columns and values: {column_names}, {values}'\n",
        "    )\n",
        "  return collections.OrderedDict(zip(column_names, values))\n",
        "\n",
        "\n",
        "class AnnotatedLocus(\n",
        "    typing.NamedTuple(\n",
        "        'AnnotatedLocus',\n",
        "        [\n",
        "            ('assoc_result', AssocResult),\n",
        "            ('cluster_left_bp', int),\n",
        "            ('cluster_right_bp', int),\n",
        "            ('num_variants', int),\n",
        "            ('num_hits', int),\n",
        "            ('cytoband', str),\n",
        "            ('gene_context', str),\n",
        "            ('closest_genes', str),\n",
        "            ('replication_variants', 'collections.OrderedDict[str, str]'),\n",
        "        ],\n",
        "    )\n",
        "):\n",
        "  \"\"\"Container class for GWAS pipeline annotated hit results.\n",
        "\n",
        "  Attributes:\n",
        "    assoc_result: A constituent AssocResult for the index variant. Its\n",
        "      attributes are available to simplify access.\n",
        "    cluster_left_bp: The position of the leftmost significant variant within the\n",
        "      locus cluster.\n",
        "    cluster_right_bp: The position of the rightmost significant variant within\n",
        "      the locus cluster.\n",
        "    num_variants: The number of significant variants contained in the cluster(s)\n",
        "      represented by this AnnotatedLocus.\n",
        "    num_hits: The number of independent GWAS signals (clusters) present in this\n",
        "      AnnotatedLocus.\n",
        "    cytoband: The cytoband location of the index variant.\n",
        "    gene_context: The context of the index variant relative to nearby genes.\n",
        "    closest_genes: The closest gene(s) (if located within one or more gene\n",
        "      bodies), otherwise the closest leftmost and rightmost genes within 1 MB.\n",
        "    replication_variants: A collections.OrderedDict with keys being the\n",
        "      replication keyword column name in the\n",
        "      \"association_results.annotated_hits.tsv\" file and the value being a\n",
        "      colon-delimited string containing the IDs of the variants in the GWAS\n",
        "      catalog with this keyword that are replicated by this variant.\n",
        "  \"\"\"\n",
        "\n",
        "  __slots__ = ()\n",
        "\n",
        "  def __new__(\n",
        "      cls,\n",
        "      assoc_result: AssocResult,\n",
        "      cluster_left_bp: int,\n",
        "      cluster_right_bp: int,\n",
        "      num_variants: int,\n",
        "      num_hits: int,\n",
        "      cytoband: str,\n",
        "      gene_context: str,\n",
        "      closest_genes: str,\n",
        "      replication_variants: 'collections.OrderedDict[str, str]',\n",
        "  ) -\u003e 'AnnotatedLocus':\n",
        "    _validate_annotated_locus(\n",
        "        assoc_result=assoc_result,\n",
        "        cluster_left_bp=cluster_left_bp,\n",
        "        cluster_right_bp=cluster_right_bp,\n",
        "        num_variants=num_variants,\n",
        "        num_hits=num_hits,\n",
        "        cytoband=cytoband,\n",
        "        gene_context=gene_context,\n",
        "        closest_genes=closest_genes,\n",
        "        replication_variants=replication_variants,\n",
        "    )\n",
        "    return super().__new__(\n",
        "        cls,\n",
        "        assoc_result=assoc_result,\n",
        "        cluster_left_bp=cluster_left_bp,\n",
        "        cluster_right_bp=cluster_right_bp,\n",
        "        num_variants=num_variants,\n",
        "        num_hits=num_hits,\n",
        "        cytoband=cytoband,\n",
        "        gene_context=gene_context,\n",
        "        closest_genes=closest_genes,\n",
        "        replication_variants=replication_variants,\n",
        "    )\n",
        "\n",
        "  @classmethod\n",
        "  def from_line(cls, line, header_tokens: List[str]) -\u003e 'AnnotatedLocus':\n",
        "    \"\"\"Returns an instance of the class from its string representation.\n",
        "\n",
        "    Args:\n",
        "      line: The line to be converted into an AnnotatedLocus.\n",
        "      header_tokens: The ordered list of header fields for the record.\n",
        "\n",
        "    Returns:\n",
        "      An AnnotatedLocus representing the line.\n",
        "    \"\"\"\n",
        "    tokens = line.strip().split('\\t')\n",
        "    if len(tokens) != len(header_tokens):\n",
        "      raise ValueError(\n",
        "          'Number of tokens does not match header. '\n",
        "          f'Header ({len(header_tokens)}): {header_tokens}. '\n",
        "          f'Tokens ({len(tokens)}): {tokens}.'\n",
        "      )\n",
        "    if header_tokens[-1] != 'LOCUSZOOM_ID':\n",
        "      raise ValueError(\n",
        "          'Last header field expected to be deprecated '\n",
        "          f'\"LOCUSZOOM_ID\", found: {header_tokens[-1]}.'\n",
        "      )\n",
        "\n",
        "    # There are either 17 or 19 tokens in the AssocResult (19 iff it is a binary\n",
        "    # phenotype run using PLINK).\n",
        "    num_assoc_tokens = 19 if 'CTRL_CNT' in header_tokens else 17\n",
        "    assoc_tokens = tokens[:num_assoc_tokens]\n",
        "    assoc_result = AssocResult.from_line('\\t'.join(assoc_tokens))\n",
        "\n",
        "    # This relies on the convention that the replication names start immediately\n",
        "    # after the 'CLOSEST_GENES' column.\n",
        "    annot_start_ix = header_tokens.index('CLOSEST_GENES') + 1\n",
        "    # Slice off the final field since it is the deprecated LOCUSZOOM_ID field.\n",
        "    annot_names = header_tokens[annot_start_ix:-1]\n",
        "    if not all(name.endswith('_HITS') for name in annot_names):\n",
        "      raise ValueError(\n",
        "          'Expected all annotation names to end in \"_HITS\", found:'\n",
        "          f' {annot_names}.'\n",
        "      )\n",
        "    replication_variant_strs = tokens[annot_start_ix:-1]\n",
        "    replication_variants = _load_replication_variants(\n",
        "        annot_names, replication_variant_strs\n",
        "    )\n",
        "\n",
        "    field_lookup = dict(zip(header_tokens, tokens))\n",
        "    # Note: We drop the 'CLUSTER_ID' field that is only present in\n",
        "    # distance-based clustering as it was not being referenced elsewhere anyway.\n",
        "    return cls(\n",
        "        assoc_result=assoc_result,\n",
        "        cluster_left_bp=int(field_lookup['CLUSTER_LEFT']),\n",
        "        cluster_right_bp=int(field_lookup['CLUSTER_RIGHT']),\n",
        "        # This field is optionally generated depending on whether multiple\n",
        "        # independent hits were merged in the writing of the output. If not,\n",
        "        # this is presumed to be a single independent hit.\n",
        "        num_hits=int(field_lookup.get('NUM_CLUSTERS', 1)),\n",
        "        num_variants=int(field_lookup['CLUSTER_SIZE']),\n",
        "        cytoband=field_lookup['CYTOBAND'],\n",
        "        gene_context=field_lookup['GENE_CONTEXT'],\n",
        "        closest_genes=field_lookup['CLOSEST_GENES'],\n",
        "        replication_variants=replication_variants,\n",
        "    )\n",
        "\n",
        "  def __str__(self) -\u003e str:\n",
        "    \"\"\"Returns a string representation of self.\"\"\"\n",
        "    return '\\t'.join([\n",
        "        str(self.assoc_result),\n",
        "        str(self.num_hits),\n",
        "        str(self.cluster_left_bp),\n",
        "        str(self.cluster_right_bp),\n",
        "        str(self.num_variants),\n",
        "        self.cytoband,\n",
        "        self.gene_context,\n",
        "        self.closest_genes,\n",
        "        '\\t'.join(self.replication_variants.values()),\n",
        "        '.',  # Deprecated LocusZoom ID.\n",
        "    ])\n",
        "\n",
        "  def columns(self) -\u003e List[str]:\n",
        "    \"\"\"Returns the list of columns of a TSV file representing this.\"\"\"\n",
        "    return (\n",
        "        self.assoc_result.columns()\n",
        "        + [\n",
        "            'NUM_CLUSTERS',\n",
        "            'CLUSTER_LEFT',\n",
        "            'CLUSTER_RIGHT',\n",
        "            'CLUSTER_SIZE',\n",
        "            'CYTOBAND',\n",
        "            'GENE_CONTEXT',\n",
        "            'CLOSEST_GENES',\n",
        "        ]\n",
        "        + list(self.replication_variants.keys())\n",
        "        + ['LOCUSZOOM_ID']\n",
        "    )\n",
        "\n",
        "  def merge(\n",
        "      self, other: 'AnnotatedLocus', strict: bool = True\n",
        "  ) -\u003e 'AnnotatedLocus':\n",
        "    \"\"\"Returns an AnnotatedLocus consisting of the merger of the two.\n",
        "\n",
        "    The \"index\" position retained is based on the p-value of association -- the\n",
        "    more significant variant is kept. Assumptions of the merge are that the\n",
        "    independent \"hits\" associated with each of the inputs are disjoint, so that\n",
        "    total variants and total hits can just be summed together. This assumption\n",
        "    is true for both our LD-based and distance-based clustering implementations.\n",
        "\n",
        "    Args:\n",
        "      other: The other AnnotatedLocus to merge with.\n",
        "      strict: If True, raises an exception when replication keys don't match.\n",
        "        Otherwise we merge them.\n",
        "\n",
        "    Returns:\n",
        "      An AnnotatedLocus that is the merger of the two.\n",
        "\n",
        "    Raises:\n",
        "      ValueError: The hits cannot be safely merged.\n",
        "    \"\"\"\n",
        "    if self.chrom != other.chrom:\n",
        "      raise ValueError(\n",
        "          f'Cannot merge hits on separate chromosomes: {self} vs {other}'\n",
        "      )\n",
        "\n",
        "    self_replication_keys = list(self.replication_variants)\n",
        "    other_replication_keys = list(other.replication_variants)\n",
        "    chrom_pos = (\n",
        "        f'{self.assoc_result.chrom}:'\n",
        "        f'{self.cluster_left_bp}-{self.cluster_right_bp}'\n",
        "    )\n",
        "\n",
        "    if self_replication_keys == other_replication_keys:\n",
        "      merged_replication_keys = self_replication_keys\n",
        "    elif strict:\n",
        "      raise ValueError(\n",
        "          f'Cannot merge hits with different replications at {chrom_pos}: '\n",
        "          f'{self_replication_keys} vs {other_replication_keys}.'\n",
        "      )\n",
        "    else:\n",
        "      # Using print to minimize dependencies of the docker scripts.\n",
        "      print(\n",
        "          f'Merging distinct replication keys at {chrom_pos}: '\n",
        "          f'{self_replication_keys} and {other_replication_keys}'\n",
        "      )\n",
        "      # Concatenate \u0026 deduplicate while preserving the order.\n",
        "      merged_replication_keys = list(\n",
        "          dict.fromkeys(self_replication_keys + other_replication_keys)\n",
        "      )\n",
        "\n",
        "    replication_variants = collections.OrderedDict()\n",
        "    for key in merged_replication_keys:\n",
        "      replication_variants[key] = _merge_replication_variants(\n",
        "          self.replication_variants.get(key),\n",
        "          other.replication_variants.get(key),\n",
        "      )\n",
        "\n",
        "    index_hit = self if self.p \u003c= other.p else other\n",
        "    return AnnotatedLocus(\n",
        "        # Note: It's fine to use the underlying AssocResult object since it's\n",
        "        # immutable.\n",
        "        assoc_result=index_hit.assoc_result,\n",
        "        cluster_left_bp=min(self.cluster_left_bp, other.cluster_left_bp),\n",
        "        cluster_right_bp=max(self.cluster_right_bp, other.cluster_right_bp),\n",
        "        num_variants=self.num_variants + other.num_variants,\n",
        "        num_hits=self.num_hits + other.num_hits,\n",
        "        cytoband=index_hit.cytoband,\n",
        "        gene_context=index_hit.gene_context,\n",
        "        closest_genes=index_hit.closest_genes,\n",
        "        replication_variants=replication_variants,\n",
        "    )\n",
        "\n",
        "  def overlaps(self, other: 'AnnotatedLocus') -\u003e bool:\n",
        "    \"\"\"Returns True if and only if `self` overlaps `other`.\"\"\"\n",
        "    return self.chrom == other.chrom and min(\n",
        "        self.cluster_right_bp, other.cluster_right_bp\n",
        "    ) \u003e= max(self.cluster_left_bp, other.cluster_left_bp)\n",
        "\n",
        "  # Convenience methods for accessing the contained AssocResult.\n",
        "\n",
        "  @property\n",
        "  def vid(self) -\u003e str:\n",
        "    return self.assoc_result.vid\n",
        "\n",
        "  @property\n",
        "  def chrom(self) -\u003e str:\n",
        "    return self.assoc_result.chrom\n",
        "\n",
        "  @property\n",
        "  def bp(self) -\u003e int:\n",
        "    return self.assoc_result.bp\n",
        "\n",
        "  @property\n",
        "  def ref(self) -\u003e str:\n",
        "    return self.assoc_result.ref\n",
        "\n",
        "  @property\n",
        "  def alt(self) -\u003e str:\n",
        "    return self.assoc_result.alt\n",
        "\n",
        "  @property\n",
        "  def rsid(self) -\u003e str:\n",
        "    return self.assoc_result.rsid\n",
        "\n",
        "  @property\n",
        "  def affx(self) -\u003e str:\n",
        "    return self.assoc_result.affx\n",
        "\n",
        "  @property\n",
        "  def eff(self) -\u003e str:\n",
        "    return self.assoc_result.eff\n",
        "\n",
        "  @property\n",
        "  def alt_freq(self) -\u003e float:\n",
        "    return self.assoc_result.alt_freq\n",
        "\n",
        "  @property\n",
        "  def num_indv(self) -\u003e int:\n",
        "    return self.assoc_result.num_indv\n",
        "\n",
        "  @property\n",
        "  def src(self) -\u003e str:\n",
        "    return self.assoc_result.src\n",
        "\n",
        "  @property\n",
        "  def info_score(self) -\u003e float:\n",
        "    return self.assoc_result.info_score\n",
        "\n",
        "  @property\n",
        "  def p_hwe_pop(self) -\u003e ArbitraryPrecisionReal:\n",
        "    return self.assoc_result.p_hwe_pop\n",
        "\n",
        "  @property\n",
        "  def p(self) -\u003e ArbitraryPrecisionReal:\n",
        "    return self.assoc_result.p\n",
        "\n",
        "  @property\n",
        "  def beta(self) -\u003e float:\n",
        "    return self.assoc_result.beta\n",
        "\n",
        "  @property\n",
        "  def se(self) -\u003e float:\n",
        "    return self.assoc_result.se\n",
        "\n",
        "  @property\n",
        "  def maf(self) -\u003e float:\n",
        "    return self.assoc_result.maf\n",
        "\n",
        "  @property\n",
        "  def name(self) -\u003e str:\n",
        "    return self.assoc_result.name\n",
        "\n",
        "\n",
        "class AnnotatedLoci:\n",
        "  \"\"\"Class representing a file of AnnotatedLocus records.\n",
        "\n",
        "  This can be either the independent hits identified by LD-based clumping or\n",
        "  further reduced to distance-based loci.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, chrom_locus_map: Dict[str, List[AnnotatedLocus]]):\n",
        "    \"\"\"Constructor.\n",
        "\n",
        "    This is not usually instantiated directly, with preference for `from_file`.\n",
        "\n",
        "    Arguments:\n",
        "      chrom_locus_map: collections.OrderedDict mapping from chromosome name to a\n",
        "        list of AnnotatedLocus records on that chromosome sorted by position.\n",
        "    \"\"\"\n",
        "    self._chrom_locus_map = chrom_locus_map\n",
        "\n",
        "  @classmethod\n",
        "  def from_file(\n",
        "      cls, path_or_buffer: Union[str, os.PathLike, io.TextIOBase]\n",
        "  ) -\u003e 'AnnotatedLoci':\n",
        "    \"\"\"Returns an AnnotatedLoci object from the file.\"\"\"\n",
        "    if isinstance(path_or_buffer, (str, os.PathLike)):\n",
        "      handle = open(path_or_buffer, 'rt')\n",
        "    else:\n",
        "      handle = path_or_buffer\n",
        "\n",
        "    chrom_locus_map = collections.OrderedDict()\n",
        "    with handle:\n",
        "      try:\n",
        "        header = next(handle)\n",
        "      except StopIteration:\n",
        "        # Completely empty file, this should be treated the same as a header\n",
        "        # that is just blank (what the GWAS pipeline emits).\n",
        "        header = ''\n",
        "\n",
        "      if not header.strip():\n",
        "        # There are no hits at all. Just return an empty object.\n",
        "        return cls(chrom_locus_map=chrom_locus_map)\n",
        "\n",
        "      header_tokens = header.strip().split('\\t')\n",
        "      for line in handle:\n",
        "        locus = AnnotatedLocus.from_line(line, header_tokens)\n",
        "        if locus.chrom not in chrom_locus_map:\n",
        "          chrom_locus_map[locus.chrom] = []\n",
        "        chrom_locus_map[locus.chrom].append(locus)\n",
        "\n",
        "    # Order the results by position.\n",
        "    for chrom in chrom_locus_map.keys():\n",
        "      chrom_locus_map[chrom] = sorted(\n",
        "          chrom_locus_map[chrom], key=lambda locus: locus.bp\n",
        "      )\n",
        "    return cls(chrom_locus_map=chrom_locus_map)\n",
        "\n",
        "  def chroms(self) -\u003e List[str]:\n",
        "    return list(self._chrom_locus_map.keys())\n",
        "\n",
        "  def loci_counts_per_chrom(self) -\u003e Dict[str, int]:\n",
        "    \"\"\"Returns the number of loci in each chromosome.\"\"\"\n",
        "    return {c: len(self._chrom_locus_map[c]) for c in self._chrom_locus_map}\n",
        "\n",
        "  def get_loci_in_chrom(self, chrom: str) -\u003e List[AnnotatedLocus]:\n",
        "    \"\"\"Returns all loci in the given chromosome.\"\"\"\n",
        "    if chrom in self._chrom_locus_map:\n",
        "      return copy.deepcopy(self._chrom_locus_map[chrom])\n",
        "    else:\n",
        "      return []\n",
        "\n",
        "  def to_file(\n",
        "      self, path_or_buffer: Union[str, os.PathLike, io.TextIOBase]\n",
        "  ) -\u003e None:\n",
        "    \"\"\"Write to a file.\"\"\"\n",
        "    if isinstance(path_or_buffer, (str, os.PathLike)):\n",
        "      handle = open(path_or_buffer, 'wt')\n",
        "    else:\n",
        "      handle = path_or_buffer\n",
        "\n",
        "    if not self._chrom_locus_map:\n",
        "      # Since we have no loci, we don't know the proper set of columns. Just\n",
        "      # write an empty file instead (this is the current behavior of the GWAS\n",
        "      # pipeline anyway). Since above we have opened the handle, we can just\n",
        "      # return now to achieve this.\n",
        "      return\n",
        "\n",
        "    # By construction, all keys present in the map have non-empty values.\n",
        "    locus = next(iter(self._chrom_locus_map.values()))[0]\n",
        "    header_cols = locus.columns()\n",
        "\n",
        "    handle.write('\\t'.join(header_cols) + '\\n')\n",
        "    for chrom_loci in self._chrom_locus_map.values():\n",
        "      for locus in chrom_loci:\n",
        "        assert locus.columns() == header_cols\n",
        "        handle.write(str(locus) + '\\n')\n",
        "\n",
        "  def merge_by_distance(\n",
        "      self, max_cluster_separation: int, strict: bool = True\n",
        "  ) -\u003e 'AnnotatedLoci':\n",
        "    \"\"\"Returns an AnnotatedLoci object with variants merged by distance.\n",
        "\n",
        "    Args:\n",
        "      max_cluster_separation: The maximum distance in bp between clusters to\n",
        "        allow to be merged together.\n",
        "      strict: If True, raises an exception when replication keys don't match.\n",
        "        Otherwise we merge them.\n",
        "\n",
        "    Returns:\n",
        "      An AnnotatedLoci object with the hits merged by distance.\n",
        "    \"\"\"\n",
        "    merged_locus_map = collections.OrderedDict()\n",
        "    for chrom, unmerged_loci in self._chrom_locus_map.items():\n",
        "      merged_locus_map[chrom] = _merge_chrom_loci_by_distance(\n",
        "          unmerged_loci, max_cluster_separation, strict=strict\n",
        "      )\n",
        "    return AnnotatedLoci(chrom_locus_map=merged_locus_map)\n",
        "\n",
        "  def all_loci(self) -\u003e Generator[AnnotatedLocus, None, None]:\n",
        "    \"\"\"Yields all AnnotatedLocus records in order.\"\"\"\n",
        "    for chrom_loci in self._chrom_locus_map.values():\n",
        "      yield from chrom_loci\n",
        "\n",
        "  def items(self) -\u003e Generator[Tuple[str, List[AnnotatedLocus]], None, None]:\n",
        "    \"\"\"Yields (chrom, List[AnnotatedLocus]) elements.\"\"\"\n",
        "    yield from self._chrom_locus_map.items()\n",
        "\n",
        "  def __len__(self) -\u003e int:\n",
        "    \"\"\"Returns the total number of loci.\"\"\"\n",
        "    return sum(len(chrom_loci) for chrom_loci in self._chrom_locus_map.values())\n",
        "\n",
        "  def union(self, others: Sequence['AnnotatedLoci']) -\u003e 'AnnotatedLoci':\n",
        "    \"\"\"Returns all loci in this and other AnnotatedLoci.\"\"\"\n",
        "    if not others:\n",
        "      raise ValueError('`others` cannot be empty.')\n",
        "    merged_locus_map = collections.OrderedDict()\n",
        "    new_chroms_set = set(self.chroms())\n",
        "    for other in others:\n",
        "      new_chroms_set |= set(other.chroms())\n",
        "    new_chroms = sorted(new_chroms_set)\n",
        "\n",
        "    for chrom in new_chroms:\n",
        "      new_loci = self.get_loci_in_chrom(chrom)\n",
        "      for other in others:\n",
        "        new_loci += other.get_loci_in_chrom(chrom)\n",
        "      merged_locus_map[chrom] = new_loci\n",
        "    return AnnotatedLoci(chrom_locus_map=merged_locus_map)\n",
        "\n",
        "  def replication_results(\n",
        "      self, other: 'AnnotatedLoci'\n",
        "  ) -\u003e Tuple['AnnotatedLoci', 'AnnotatedLoci']:\n",
        "    \"\"\"Returns the loci that are shared with `other` and distinct from `other`.\n",
        "\n",
        "    This function is not symmetric, since a single locus in one `AnnotatedLoci`\n",
        "    object may replicate zero, one, or multiple loci in another.\n",
        "\n",
        "    Args:\n",
        "      other: The other AnnotatedLoci object used to determine replication\n",
        "        status.\n",
        "\n",
        "    Returns:\n",
        "      A tuple of (replicated, unique) loci from `self`. The two sets are\n",
        "      mutually exclusive and every locus in `self` is in one of the two outputs.\n",
        "    \"\"\"\n",
        "    replicated = collections.OrderedDict()\n",
        "    unique = collections.OrderedDict()\n",
        "    for chrom, chrom_loci in self.items():\n",
        "      # Loci on the chromosome of interest that are replicated in `other`.\n",
        "      chrom_replicated = []\n",
        "      # Loci on the chromosome of interest that are distinct/unique from the\n",
        "      # loci in `other`.\n",
        "      chrom_unique = []\n",
        "      # pylint: disable=protected-access\n",
        "      other_chrom_loci = other._chrom_locus_map.get(chrom, [])\n",
        "      # pylint: enable=protected-access\n",
        "      for locus in chrom_loci:\n",
        "        if any(locus.overlaps(other_locus) for other_locus in other_chrom_loci):\n",
        "          chrom_replicated.append(locus)\n",
        "        else:\n",
        "          chrom_unique.append(locus)\n",
        "\n",
        "      if chrom_replicated:\n",
        "        replicated[chrom] = copy.deepcopy(chrom_replicated)\n",
        "      if chrom_unique:\n",
        "        unique[chrom] = copy.deepcopy(chrom_unique)\n",
        "\n",
        "    return AnnotatedLoci(replicated), AnnotatedLoci(unique)\n",
        "\n",
        "\n",
        "def _merge_chrom_loci_by_distance(\n",
        "    loci: List[AnnotatedLocus], max_cluster_separation: int, strict: bool\n",
        ") -\u003e List[AnnotatedLocus]:\n",
        "  \"\"\"Returns a list of AnnotatedLocus objects merged by distance.\n",
        "\n",
        "  Args:\n",
        "    loci: The loci to merge.\n",
        "    max_cluster_separation: The maximum distance in bp between clusters to allow\n",
        "      to be merged.\n",
        "    strict: If True, raises an exception when replication keys don't match.\n",
        "      Otherwise we merge them.\n",
        "\n",
        "  Returns:\n",
        "    The merged loci, sorted by index variant position.\n",
        "  \"\"\"\n",
        "  if not loci:\n",
        "    return []\n",
        "\n",
        "  retval = []\n",
        "  # Ensure inputs are sorted by cluster left for merging. This is not\n",
        "  # necessarily the same as being sorted by index position, since clusters may\n",
        "  # be defined using LD.\n",
        "  left_sorted_loci = sorted(\n",
        "      loci, key=lambda locus: (locus.cluster_left_bp, locus.cluster_right_bp)\n",
        "  )\n",
        "  curr = left_sorted_loci[0]\n",
        "  for locus in left_sorted_loci[1:]:\n",
        "    sep = locus.cluster_left_bp - curr.cluster_right_bp\n",
        "    if sep \u003c= max_cluster_separation:\n",
        "      curr = curr.merge(locus, strict=strict)\n",
        "    else:\n",
        "      retval.append(curr)\n",
        "      curr = locus\n",
        "  # Fencepost.\n",
        "  retval.append(curr)\n",
        "\n",
        "  return sorted(retval, key=lambda locus: locus.bp)\n",
        "\n",
        "\n",
        "class GwasResults:\n",
        "  \"\"\"Class that contains results from a GWAS pipeline run.\n",
        "\n",
        "  It has both an AnnotatedLoci object and all underlying association results\n",
        "  that pass quality control. These underlying association results are guaranteed\n",
        "  to be a superset of the variants present in the `AnnotatedLoci` object.\n",
        "  \"\"\"\n",
        "\n",
        "  REQUIRED_ASSOC_COLS = frozenset(['VID', 'CHR', 'BP', 'P', 'BETA', 'SE'])\n",
        "\n",
        "  def __init__(\n",
        "      self, loci: AnnotatedLoci, chrom_assoc_df: Dict[str, pd.DataFrame]\n",
        "  ):\n",
        "    \"\"\"Constructor.\n",
        "\n",
        "    This is typically not called directly; prefer `GwasResults.from_files` or\n",
        "    `GwasResults.from_gwas_pipeline_dir` instead.\n",
        "\n",
        "    Args:\n",
        "      loci: `AnnotatedLoci` object. This is the set of \"GWAS hits\" for the GWAS;\n",
        "        see its class description for full details.\n",
        "      chrom_assoc_df: Mapping from chromosome name to DataFrame of all variants\n",
        "        that pass quality control for the GWAS (typically a chromosome-sharded\n",
        "        version of the \"association_results.filtered.tsv\" file).\n",
        "\n",
        "    Raises:\n",
        "      ValueError: DataFrames in `chrom_assoc_df` do not have identical columns.\n",
        "      ValueError: DataFrames in `chrom_assoc_df` do not contain all\n",
        "        `REQUIRED_ASSOC_COLS` columns.\n",
        "      ValueError: `loci` contains some variants not present in `chrom_assoc_df`.\n",
        "    \"\"\"\n",
        "    chrom_cols = list(\n",
        "        set([frozenset(df.columns) for df in chrom_assoc_df.values()])\n",
        "    )\n",
        "    if len(chrom_cols) != 1:\n",
        "      raise ValueError(\n",
        "          f'All assoc dataframes must have the same columns: {chrom_cols}'\n",
        "      )\n",
        "    if GwasResults.REQUIRED_ASSOC_COLS - chrom_cols[0]:\n",
        "      raise ValueError(\n",
        "          f'assoc_df missing some required columns: {sorted(chrom_cols[0])}'\n",
        "      )\n",
        "    loci_vids = set(locus.vid for locus in loci.all_loci())\n",
        "    assoc_vids = set()\n",
        "    for df in chrom_assoc_df.values():\n",
        "      assoc_vids.update(df['VID'])\n",
        "\n",
        "    if loci_vids - assoc_vids:\n",
        "      raise ValueError(\n",
        "          f'{len(loci_vids - assoc_vids)} VIDs from loci not in assoc_df.'\n",
        "      )\n",
        "\n",
        "    self._loci = loci\n",
        "    self._chrom_assoc_df = chrom_assoc_df\n",
        "\n",
        "  @classmethod\n",
        "  def from_files(\n",
        "      cls,\n",
        "      annotated_loci_path_or_buffer: Union[str, os.PathLike, io.TextIOBase],\n",
        "      filtered_results_path_or_buffer: Union[str, os.PathLike, io.TextIOBase],\n",
        "      columns: Optional[Sequence[str]] = None,\n",
        "  ) -\u003e 'GwasResults':\n",
        "    \"\"\"Returns a GwasResults object from the input filepaths.\n",
        "\n",
        "    Args:\n",
        "      annotated_loci_path_or_buffer: Path to the annotated hits (typically named\n",
        "        \"association_results.annotated_hits.tsv\" or\n",
        "        \"association_results.annotated_loci.tsv\").\n",
        "      filtered_results_path_or_buffer: Path to the filtered results (typically\n",
        "        named \"association_results.filtered.tsv\").\n",
        "      columns: List of columns of the filtered results to retain in the data. We\n",
        "        always keep required columns `REQUIRED_ASSOC_COLS`; this field can be\n",
        "        used to specify additional columns if they should be retained.\n",
        "\n",
        "    Returns:\n",
        "      GwasResults object representing the GWAS.\n",
        "    \"\"\"\n",
        "    loci = AnnotatedLoci.from_file(annotated_loci_path_or_buffer)\n",
        "\n",
        "    if isinstance(filtered_results_path_or_buffer, (str, os.PathLike)):\n",
        "      handle = open(filtered_results_path_or_buffer, mode='rt')\n",
        "    else:\n",
        "      handle = filtered_results_path_or_buffer\n",
        "\n",
        "    if columns:\n",
        "      cols = GwasResults.REQUIRED_ASSOC_COLS | set(columns)\n",
        "    else:\n",
        "      cols = GwasResults.REQUIRED_ASSOC_COLS\n",
        "\n",
        "    with handle:\n",
        "      assoc_df = pd.read_csv(handle, delimiter='\\t', usecols=cols)\n",
        "      assoc_df.CHR = assoc_df.CHR.astype(str)\n",
        "      chrom_assoc_df = {\n",
        "          chrom: assoc_df.loc[assoc_df.CHR == chrom].copy(deep=True)\n",
        "          for chrom in assoc_df.CHR.unique()\n",
        "      }\n",
        "    return cls(loci=loci, chrom_assoc_df=chrom_assoc_df)\n",
        "\n",
        "  @classmethod\n",
        "  def from_gwas_pipeline_dir(\n",
        "      cls, gwas_dir: str, columns: Optional[Sequence[str]] = None\n",
        "  ) -\u003e 'GwasResults':\n",
        "    \"\"\"Convenience method for loading from a GWAS pipeline output directory.\n",
        "\n",
        "    Args:\n",
        "      gwas_dir: The directory in which GWAS pipeline outputs are written.\n",
        "      columns: List of columns of the filtered results to retain in the data. We\n",
        "        always keep required columns `REQUIRED_ASSOC_COLS`; this field can be\n",
        "        used to specify additional columns if they should be retained.\n",
        "\n",
        "    Returns:\n",
        "      GwasResults object representing the GWAS.\n",
        "    \"\"\"\n",
        "    annotated_loci_file = os.path.join(\n",
        "        gwas_dir, 'analysis', 'association_results.annotated_hits.tsv'\n",
        "    )\n",
        "    filtered_results_file = os.path.join(\n",
        "        gwas_dir, 'analysis', 'association_results.filtered.tsv'\n",
        "    )\n",
        "    return cls.from_files(\n",
        "        annotated_loci_path_or_buffer=annotated_loci_file,\n",
        "        filtered_results_path_or_buffer=filtered_results_file,\n",
        "        columns=columns,\n",
        "    )\n",
        "\n",
        "  def merge_by_distance(self, max_cluster_separation: int) -\u003e 'GwasResults':\n",
        "    \"\"\"Returns a GwasResults object with variants merged by distance.\n",
        "\n",
        "    Args:\n",
        "      max_cluster_separation: The maximum distance in bp between clusters to\n",
        "        allow to be merged together.\n",
        "\n",
        "    Returns:\n",
        "      A GwasResults object with the hits merged by distance.\n",
        "    \"\"\"\n",
        "    return GwasResults(\n",
        "        loci=self._loci.merge_by_distance(\n",
        "            max_cluster_separation=max_cluster_separation\n",
        "        ),\n",
        "        chrom_assoc_df=copy.deepcopy(self._chrom_assoc_df),\n",
        "    )\n",
        "\n",
        "\n",
        "def join_two_gwases(\n",
        "    res1: GwasResults,\n",
        "    res2: GwasResults,\n",
        "    how: str,\n",
        "    columns: Optional[Sequence[str]] = None,\n",
        "    suffixes: Tuple[str, str] = ('_x', '_y'),\n",
        ") -\u003e pd.DataFrame:\n",
        "  \"\"\"Returns a DataFrame containing the results of joining two `GwasResult`s.\n",
        "\n",
        "  The goal of joining is to compare information about equivalent variants across\n",
        "  two `GwasResult`s. Typically this is performed to understand whether one GWAS\n",
        "  has better power than another (by comparing p-values) or to determine\n",
        "  consistency between estimated effect sizes (by comparing effect sizes). This\n",
        "  join can be performed at the raw association result level (i.e. by joining all\n",
        "  pairs of variants that have satisfied QC to produce valid results), but this\n",
        "  can be visually misleading when one or few clumps of variants in strong LD\n",
        "  dominate the results. Consequently, we also support joining of just a subset\n",
        "  of variants (the independent loci identified by one or both GWAS). This is\n",
        "  conceptually equivalent to joining results from all variants and then\n",
        "  filtering those results to just the subset of interest (but is implemented by\n",
        "  filtering and then joining for computational efficiency).\n",
        "\n",
        "  There are four supported methods for joining results:\n",
        "    * 'left_loci': All loci from the left (i.e. res1) result are included. This\n",
        "        is a typically useful incantation, and reflects direct comparison of\n",
        "        variants highlighted in a particular study.\n",
        "    * 'either_loci': Loci present in either of the results are included. This\n",
        "        is a fuller comparison of two GWASs than using 'left_loci', but can\n",
        "        cause the same locus to be represented multiple times (if in the same\n",
        "        region, one variant is designated the \"locus representative\" in one\n",
        "        GWAS but a different variant is the locus representative for the other).\n",
        "    * 'all_variants': Joins all variants that passed QC metrics in both GWASs.\n",
        "    * 'best_loci': Currently not implemented. Its goal is to have the benefit of\n",
        "        the 'either_loci' method but avoid double-counting.\n",
        "\n",
        "  Filtering by 'left_loci' or 'either_loci' means just keeping the specific\n",
        "  variants that correspond to the AnnotatedLocus objects within the desired\n",
        "  GWAS(s) for the join.\n",
        "\n",
        "  Note that the total number of variants in the result may be slightly smaller\n",
        "  than requested, as variants must have passed QC checks in both GWASs to be\n",
        "  included.\n",
        "\n",
        "  Args:\n",
        "    res1: One `GwasResults` object to compare (the \"left\" result).\n",
        "    res2: The other `GwasResults` object to compare.\n",
        "    how: How the join should be performed. Must be in [left_loci, either_loci,\n",
        "      all_variants, best_loci] (see above for details).\n",
        "    columns: Columns to keep in the output DataFrame.\n",
        "    suffixes: Suffixes to append to the left and right shared columns in the\n",
        "      output DataFrame (see pandas.merge documentation for details).\n",
        "\n",
        "  Returns:\n",
        "    A pd.DataFrame containing genome-wide joined variants.\n",
        "  \"\"\"\n",
        "  if columns is None:\n",
        "    columns = ['P', 'BETA', 'SE']\n",
        "  else:\n",
        "    columns = list(columns)  # Make a copy as we may need to modify it below.\n",
        "\n",
        "  # Validate input data.\n",
        "  if 'VID' in columns and how == 'best_loci':\n",
        "    raise ValueError(\n",
        "        '\"VID\" cannot be in columns when using '\n",
        "        f'\"best_loci\" join method: {columns}.'\n",
        "    )\n",
        "  if not set(columns) - {'VID'}:\n",
        "    raise ValueError(f'At least one non-VID column must be present: {columns}.')\n",
        "  if how not in ['left_loci', 'either_loci', 'best_loci', 'all_variants']:\n",
        "    raise ValueError(f'Unsupported GWAS join method: \"{how}\".')\n",
        "  if not any(suffixes):\n",
        "    raise ValueError(f'At least one suffix must be non-empty: {suffixes}')\n",
        "  if not len(suffixes) == len(set(suffixes)) == 2:\n",
        "    raise ValueError(f'Suffixes must be unique: {suffixes}')\n",
        "\n",
        "  if how == 'best_loci':\n",
        "    # This must be implemented independently, as it is a \"fuzzy\" join where the\n",
        "    # left and right variant values returned do not necessarily come from the\n",
        "    # same variants.\n",
        "    raise NotImplementedError('Join using \"best_loci\" is not yet implemented.')\n",
        "\n",
        "  # For all other join types, we select the same variants in each GwasResult.\n",
        "  # So, we can just find the set of VIDs per chromosome that need to be kept,\n",
        "  # and share the logic of actually performing the join that includes those\n",
        "  # VIDs.\n",
        "  # The following code blocks are logically distinct; the first identifies the\n",
        "  # particular VIDs to retain, and the next does the actual joining based on\n",
        "  # those VIDs. If these functionalities show independent utility we can factor\n",
        "  # them into separate functions.\n",
        "  chrom_vids = collections.defaultdict(set)\n",
        "  # pylint: disable=protected-access\n",
        "  if how == 'left_loci':\n",
        "    for chrom, loci in res1._loci.items():\n",
        "      chrom_vids[chrom].update({locus.vid for locus in loci})\n",
        "  elif how == 'either_loci':\n",
        "    for gwas_results in [res1, res2]:\n",
        "      for chrom, loci in gwas_results._loci.items():\n",
        "        chrom_vids[chrom].update({locus.vid for locus in loci})\n",
        "  elif how == 'all_variants':\n",
        "    for chrom in set(res1._chrom_assoc_df) \u0026 set(res2._chrom_assoc_df):\n",
        "      res1_vids = set(res1._chrom_assoc_df[chrom]['VID'])\n",
        "      res2_vids = set(res2._chrom_assoc_df[chrom]['VID'])\n",
        "      chrom_vids[chrom] = res1_vids \u0026 res2_vids\n",
        "  else:\n",
        "    assert False, 'Programming error -- should not reach this clause.'\n",
        "\n",
        "  # We do the actual join using VID as the key. If it is not requested as an\n",
        "  # output field, we need to add it and then remove at the end.\n",
        "  vid_requested = 'VID' in columns\n",
        "  if not vid_requested:\n",
        "    columns.append('VID')\n",
        "\n",
        "  chrom_results = []\n",
        "  for chrom, vids in chrom_vids.items():\n",
        "    if vids and chrom in res1._chrom_assoc_df and chrom in res2._chrom_assoc_df:\n",
        "      # Trim both dataframes to only the VIDs and columns to retain.\n",
        "      left_full_df = res1._chrom_assoc_df[chrom]\n",
        "      left_df = left_full_df.loc[left_full_df['VID'].isin(vids), columns]\n",
        "      right_full_df = res2._chrom_assoc_df[chrom]\n",
        "      right_df = right_full_df.loc[right_full_df['VID'].isin(vids), columns]\n",
        "      joined_chrom_df = pd.merge(\n",
        "          left_df,\n",
        "          right_df,\n",
        "          how='inner',\n",
        "          on='VID',\n",
        "          suffixes=suffixes,\n",
        "          validate='one_to_one',\n",
        "      )\n",
        "      if not vid_requested:\n",
        "        joined_chrom_df.drop('VID', axis='columns', inplace=True)\n",
        "      chrom_results.append(joined_chrom_df)\n",
        "  return pd.concat(chrom_results, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SMNkUk6ZSPq"
      },
      "source": [
        "## Utilities for loading annotated hits, loci, and filtered GWAS results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHLq_dgvOFWh"
      },
      "outputs": [],
      "source": [
        "@dataclasses.dataclass\n",
        "class Gwas:\n",
        "  \"\"\"Represents an individual GWAS.\n",
        "\n",
        "  Attributes:\n",
        "    gwas_id: A unique GWAS identifier.\n",
        "    gwas_label: A label used in figures when plotting GWAS results.\n",
        "    base_dir: A base directory containing annotated hits, loci, and results.\n",
        "    hits_suffix: The suffix of the hits file.\n",
        "    loci_suffix: The suffix of the loci file.\n",
        "    results_suffix: The suffix of the filtered results file.\n",
        "    hits: An `AnnotatedLoci` containing all hits.\n",
        "    loci: An `AnnotatedLoci` containing all loci.\n",
        "    gwas_results: An `GwasResults` containing filtered results.\n",
        "  \"\"\"\n",
        "\n",
        "  gwas_id: str\n",
        "  gwas_label: str\n",
        "  base_dir: str = ASSOC_RESULTS_BASE_DIR\n",
        "  hits_suffix: str = ASSOC_RESULTS_HITS_SUFFIX\n",
        "  loci_suffix: str = ASSOC_RESULTS_LOCI_SUFFIX\n",
        "  results_suffix: str = ASSOC_RESULTS_FILTERED_SUFFIX\n",
        "  hits: AnnotatedLoci = dataclasses.field(init=False)\n",
        "  loci: AnnotatedLoci = dataclasses.field(init=False)\n",
        "  gwas_results: GwasResults = dataclasses.field(init=False)\n",
        "\n",
        "  @property\n",
        "  def hits_path(self) -\u003e str:\n",
        "    \"\"\"A path to the GWAS's annotated hits.\"\"\"\n",
        "    return os.path.join(self.base_dir, f'{self.gwas_id}{self.hits_suffix}')\n",
        "\n",
        "  @property\n",
        "  def loci_path(self) -\u003e str:\n",
        "    \"\"\"A path to the GWAS's annotated loci.\"\"\"\n",
        "    return os.path.join(self.base_dir, f'{self.gwas_id}{self.loci_suffix}')\n",
        "\n",
        "  @property\n",
        "  def results_path(self) -\u003e str:\n",
        "    \"\"\"A path to the GWAS's filtered results.\"\"\"\n",
        "    return os.path.join(self.base_dir, f'{self.gwas_id}{self.results_suffix}')\n",
        "\n",
        "  def __post_init__(self):\n",
        "    if not os.path.exists(self.hits_path):\n",
        "      raise FileNotFoundError(self.hits_path)\n",
        "    if not os.path.exists(self.loci_path):\n",
        "      raise FileNotFoundError(self.loci_path)\n",
        "    self.hits = AnnotatedLoci.from_file(self.hits_path)\n",
        "    self.loci = AnnotatedLoci.from_file(self.loci_path)\n",
        "    self.gwas_results = GwasResults.from_files(\n",
        "        self.hits_path,\n",
        "        self.results_path,\n",
        "        columns=['VID', 'P', 'SE', 'BETA', 'EFF'],\n",
        "    )\n",
        "\n",
        "  def __str__(self) -\u003e str:\n",
        "    return f'{self.__class__.__name__}({self.gwas_id})'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m7H4ljHtwCY"
      },
      "source": [
        "## Utilities for generating plots and figures from GWAS results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts6YeY2XNZkX"
      },
      "outputs": [],
      "source": [
        "def gwas_comparison_pvalue_scatter_inset(\n",
        "    df,\n",
        "    x_col: str,\n",
        "    y_col: str,\n",
        "    xlabel: str = '',\n",
        "    ylabel: str = '',\n",
        "    p_thresh: float = 5e-8,\n",
        "    legend_x_desc: str = '',\n",
        "    legend_y_desc: str = '',\n",
        "    inset_axes: Optional[Tuple[float, float]] = None,\n",
        "    ax: matplotlib.axes.Axes = None,\n",
        ") -\u003e matplotlib.axes.Axes:\n",
        "  \"\"\"Plots a scatterplot of -log_10(P) from the two joined GWASes.\n",
        "\n",
        "  Args:\n",
        "    df: pd.DataFrame containing p-value columns for two GWASes.\n",
        "    x_col: The name of `df`s p-value column to plot on the x-axis.\n",
        "    y_col: The name of `df`s p-value column to plot on the y-axis.\n",
        "    xlabel: The label to give the x-axis.\n",
        "    ylabel: The label to give the y-axis.\n",
        "    p_thresh: The p-value threshold to annotate on the plot.\n",
        "    ax: matplotlib.Axes on which to plot. If unspecified, uses the current axes.\n",
        "\n",
        "  Returns:\n",
        "    The axes on which the plot is added.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: The columns to plot are not present in the dataframe.\n",
        "  \"\"\"\n",
        "  if any(col not in df.columns for col in [x_col, y_col]):\n",
        "    raise ValueError(f'{x_col} and {y_col} must be in {df.columns}')\n",
        "\n",
        "  if ax is None:\n",
        "    ax = plt.gca()\n",
        "\n",
        "  x = -np.log10(df[x_col])\n",
        "  y = -np.log10(df[y_col])\n",
        "  thresh = -np.log10(p_thresh)\n",
        "\n",
        "  only_y_sig_mask = (x \u003c thresh) \u0026 (y \u003e= thresh)\n",
        "  only_x_sig_mask = (x \u003e= thresh) \u0026 (y \u003c thresh)\n",
        "  both_sig_mask = (x \u003e= thresh) \u0026 (y \u003e= thresh)\n",
        "  neither_sig_mask = (x \u003c thresh) \u0026 (y \u003c thresh)\n",
        "\n",
        "  only_y_sig_color = '#2ca02c'\n",
        "  only_x_sig_color = '#ff7f0e'\n",
        "  both_sig_color = '#1f77b4'\n",
        "  neither_sig_color = '#84878a'\n",
        "\n",
        "  def scatter_onto_axis(mpl_axis):\n",
        "    handles = []\n",
        "    labels = []\n",
        "    for mask, color, label in [\n",
        "        (both_sig_mask, both_sig_color, 'Both significant'),\n",
        "        (\n",
        "            only_y_sig_mask,\n",
        "            only_y_sig_color,\n",
        "            legend_y_desc or 'Only y-axis significant',\n",
        "        ),\n",
        "        (\n",
        "            only_x_sig_mask,\n",
        "            only_x_sig_color,\n",
        "            legend_x_desc or 'Only x-axis significant',\n",
        "        ),\n",
        "        (neither_sig_mask, neither_sig_color, 'Neither significant'),\n",
        "    ]:\n",
        "      if mask.sum():\n",
        "        masked_x = x[mask]\n",
        "        masked_y = y[mask]\n",
        "        handles.append(mpl_axis.scatter(masked_x, masked_y, alpha=0.3, c=color))\n",
        "        labels.append(f'{label} (N={mask.sum()})')\n",
        "    return handles, labels\n",
        "\n",
        "  handles, labels = scatter_onto_axis(ax)\n",
        "\n",
        "  # Make figure square.\n",
        "  axlim = np.ceil(max(x.max(), y.max()))\n",
        "  ax.set_xlim([0, axlim])\n",
        "  ax.set_ylim([0, axlim])\n",
        "\n",
        "  ax.legend(handles=handles, labels=labels)\n",
        "\n",
        "  # Plot bounding box at significant p-value threshold and y=x line.\n",
        "  ax.hlines(y=thresh, xmin=0, xmax=thresh, linestyles='dashed', colors='r')\n",
        "  ax.vlines(x=thresh, ymin=0, ymax=thresh, linestyles='dashed', colors='r')\n",
        "  ax.plot([0, axlim], [0, axlim], 'r--', linewidth=1)\n",
        "\n",
        "  ax.set_xlabel(xlabel, fontsize=20)\n",
        "  ax.set_ylabel(ylabel, fontsize=20)\n",
        "  for xtick in ax.get_xticklabels():\n",
        "    xtick.update({'fontsize': 16})\n",
        "  for ytick in ax.get_yticklabels():\n",
        "    ytick.update({'fontsize': 16})\n",
        "\n",
        "  if inset_axes:\n",
        "    min_ax, max_ax = inset_axes\n",
        "    axins = ax.inset_axes([0.55, 0.07, 0.3, 0.3])\n",
        "    scatter_onto_axis(axins)\n",
        "    if min_ax \u003c thresh \u003c max_ax:\n",
        "      axins.hlines(\n",
        "          y=thresh, xmin=min_ax, xmax=thresh, linestyles='dashed', colors='r'\n",
        "      )\n",
        "      axins.vlines(\n",
        "          x=thresh, ymin=min_ax, ymax=thresh, linestyles='dashed', colors='r'\n",
        "      )\n",
        "    axins.plot([min_ax, max_ax], [min_ax, max_ax], 'r--', linewidth=1)\n",
        "\n",
        "    axins.set_xlim(*inset_axes)\n",
        "    axins.set_ylim(*inset_axes)\n",
        "    ax.indicate_inset_zoom(axins, edgecolor='black')\n",
        "\n",
        "  return ax\n",
        "\n",
        "\n",
        "def gwas_comparison_effect_size_scatter_inset(\n",
        "    df,\n",
        "    x_col: str,\n",
        "    y_col: str,\n",
        "    xlabel: str = '',\n",
        "    ylabel: str = '',\n",
        "    p_thresh: float = 5e-8,\n",
        "    inset_axes: Optional[Tuple[float, float]] = None,\n",
        "    ax: matplotlib.axes.Axes = None,\n",
        ") -\u003e matplotlib.axes.Axes:\n",
        "  if any(col not in df.columns for col in [x_col, y_col]):\n",
        "    raise ValueError(f'{x_col} and {y_col} must be in {df.columns}')\n",
        "\n",
        "  if ax is None:\n",
        "    ax = plt.gca()\n",
        "\n",
        "  ax.set_xlabel(xlabel, fontsize=20)\n",
        "  ax.set_ylabel(ylabel, fontsize=20)\n",
        "  for xtick in ax.get_xticklabels():\n",
        "    xtick.update({'fontsize': 16})\n",
        "  for ytick in ax.get_yticklabels():\n",
        "    ytick.update({'fontsize': 16})\n",
        "\n",
        "  corr = df[[x_col, y_col]].corr()\n",
        "  r2 = corr.iloc[0, 1] ** 2\n",
        "  r2 = '{:.2f}'.format(r2)\n",
        "  sns.regplot(\n",
        "      x=x_col,\n",
        "      y=y_col,\n",
        "      data=df,\n",
        "      line_kws={'color': 'red'},\n",
        "      scatter_kws={'color': 'black'},\n",
        "  )\n",
        "  ax.scatter(df[x_col], df[y_col], alpha=0.3, c='black')\n",
        "  plt.xlabel(xlabel)\n",
        "  plt.ylabel(ylabel)\n",
        "  plt.text(np.min(df[x_col]), np.max(df[y_col]), f'$R^2$={r2}', fontsize=20)\n",
        "  return ax\n",
        "\n",
        "\n",
        "def plot_scatter(\n",
        "    y_gwas: GwasResults,\n",
        "    x_gwas: GwasResults,\n",
        "    pheno: str,\n",
        "    x_axis_method: str,\n",
        "    y_axis_method: str,\n",
        "    ax,\n",
        "    pvalue: bool = True,\n",
        ") -\u003e None:\n",
        "  \"\"\"Plots a p-value or effect size comparison between two GWAS.\"\"\"\n",
        "\n",
        "  def update_effect_size(row):\n",
        "    if row['EFF_x'] == row['EFF_y']:\n",
        "      return row['BETA_y']\n",
        "    else:\n",
        "      return -row['BETA_y']\n",
        "\n",
        "  merged_df = join_two_gwases(\n",
        "      x_gwas,\n",
        "      y_gwas,\n",
        "      columns=['VID', 'P', 'SE', 'BETA', 'EFF'],\n",
        "      how='either_loci',\n",
        "  )\n",
        "  merged_df['BETA_y'] = merged_df.apply(update_effect_size, axis=1)\n",
        "  y_gwas_beta_larger_x_gwas = merged_df[\n",
        "      np.abs(merged_df['BETA_y']) \u003e np.abs(merged_df['BETA_x'])\n",
        "  ]\n",
        "  if pvalue:\n",
        "    ax = gwas_comparison_pvalue_scatter_inset(\n",
        "        merged_df,\n",
        "        'P_x',\n",
        "        'P_y',\n",
        "        xlabel=f'{pheno} -log(p_value) {x_axis_method}',\n",
        "        ylabel=f'{pheno} -log(p_value) {y_axis_method}',\n",
        "        legend_x_desc=f'Only {x_axis_method} significant',\n",
        "        legend_y_desc=f'Only {y_axis_method} significant',\n",
        "        inset_axes=(5, 10),\n",
        "        ax=ax,\n",
        "    )\n",
        "  else:\n",
        "    ax = gwas_comparison_effect_size_scatter_inset(\n",
        "        merged_df,\n",
        "        'BETA_x',\n",
        "        'BETA_y',\n",
        "        xlabel=f'{pheno} Effect size {x_axis_method}',\n",
        "        ylabel=f'{pheno} Effect size {y_axis_method}',\n",
        "        inset_axes=(5, 10),\n",
        "        ax=ax,\n",
        "    )\n",
        "\n",
        "\n",
        "def plot_manhattan(\n",
        "    ax,\n",
        "    main_gwas: Gwas,\n",
        "    overlap_gwas: Gwas,\n",
        "    chrom_offsets: collections.OrderedDict[str, int] = CHROM_OFFSETS,\n",
        "    p_cutoff: float = 0.001,\n",
        "    sig_cutoff: float = 5e-8,\n",
        "    max_y: float = 170,\n",
        "    min_y: float = -5,\n",
        "    min_x: float = -1.5e8,\n",
        "    max_x: float = 3.025e9,\n",
        "    seed: int = 23,\n",
        "):\n",
        "  \"\"\"Plots the Manhattan plot for GWAS.\"\"\"\n",
        "  prng = np.random.RandomState(seed)\n",
        "\n",
        "  # Compute replication across the two GWAS.\n",
        "  replicated_loci, unique_loci = main_gwas.loci.replication_results(\n",
        "      overlap_gwas.loci\n",
        "  )\n",
        "  replicated_vids = {l.vid for l in replicated_loci.all_loci()}\n",
        "  unique_vids = {l.vid for l in unique_loci.all_loci()}\n",
        "\n",
        "  # Plot SNPS above the P value cutoff, coloring hits if novel or shared.\n",
        "  chrom_colors = ['#c2a5cf', '#a6dba0']\n",
        "  xs, ys, cs = [], [], []\n",
        "  xhs, yhs, chs = [], [], []\n",
        "  for chrom_df in main_gwas.gwas_results._chrom_assoc_df.values():\n",
        "    chrom_df = chrom_df[chrom_df['P'] \u003c= p_cutoff]\n",
        "    chrom_df = chrom_df.assign(LOGP=-np.log10(chrom_df['P']))\n",
        "    chrom_df = chrom_df[['VID', 'CHR', 'BP', 'LOGP']]\n",
        "    for record in chrom_df.to_dict('records'):\n",
        "      x = chrom_offsets[str(record['CHR'])] + record['BP']\n",
        "      y = record['LOGP']\n",
        "      if record['VID'] in unique_vids:\n",
        "        xhs.append(x)\n",
        "        yhs.append(y)\n",
        "        chs.append('#d73027')\n",
        "      elif record['VID'] in replicated_vids:\n",
        "        xhs.append(x)\n",
        "        yhs.append(y)\n",
        "        chs.append('#4575b4')\n",
        "      else:\n",
        "        xs.append(x)\n",
        "        ys.append(y)\n",
        "        cs.append(chrom_colors[int(record['CHR']) % len(chrom_colors)])\n",
        "  ax.scatter(xs, ys, c=cs, s=1, rasterized=True)\n",
        "  ax.scatter(xhs, yhs, c=chs, s=10)\n",
        "\n",
        "  # Plot the significance cutoff line.\n",
        "  ax.axhline(y=-np.log10(sig_cutoff), linestyle='--', color='r', linewidth=0.5)\n",
        "\n",
        "  for hit in sorted(\n",
        "      main_gwas.hits.all_loci(),\n",
        "      key=lambda x: (int(x.assoc_result.chrom), int(x.assoc_result.bp)),\n",
        "  ):\n",
        "    x_hit = chrom_offsets[hit.assoc_result.chrom] + hit.assoc_result.bp\n",
        "    y_hit = -np.log10(hit.assoc_result.p)\n",
        "    is_common = hit.assoc_result.vid in replicated_vids\n",
        "    if y_hit \u003c 20 and not is_common:\n",
        "      continue\n",
        "    c_text = '#08306b' if is_common else 'k'\n",
        "    if y_hit \u003c 50:\n",
        "      ax.annotate(\n",
        "          hit.closest_genes,\n",
        "          xy=(x_hit, y_hit),\n",
        "          xytext=(x_hit, y_hit + 20),\n",
        "          style='oblique',\n",
        "          rotation=90,\n",
        "          color=c_text,\n",
        "          ha='center',\n",
        "          va='center',\n",
        "          arrowprops={\n",
        "              'facecolor': 'black',\n",
        "              'width': 0,\n",
        "              'headwidth': 0,\n",
        "              'shrink': 0.0,\n",
        "              'lw': 0.5,\n",
        "          },\n",
        "          bbox={'fc': 'none', 'ec': 'k', 'pad': 2, 'lw': 0},\n",
        "      )\n",
        "    else:\n",
        "      ax.annotate(\n",
        "          hit.closest_genes,\n",
        "          xy=(x_hit, y_hit),\n",
        "          xytext=(x_hit, y_hit + 2),\n",
        "          ha='center',\n",
        "          color=c_text,\n",
        "          style='oblique',\n",
        "      )\n",
        "\n",
        "  # Plot offsets, ticks, axis labels, etc.\n",
        "  offsets = np.asarray(list(chrom_offsets.values()))\n",
        "  xticks = (offsets[1:] + offsets[:-1]) / 2\n",
        "  ax.set_xticks(xticks)\n",
        "  ax.set_xticklabels([index for index in range(1, 23)], fontsize=16)\n",
        "  ax.set_yticks([0, 30, 60, 90, 120])\n",
        "  ax.set_yticklabels([0, 30, 60, 90, 120], fontsize=18)\n",
        "  ax.set_ylim([min_y, max_y])\n",
        "  ax.set_xlim([min_x, max_x])\n",
        "  ax.set_xlabel('Chromosomes', fontsize=20)\n",
        "  ax.set_ylabel(r'$-\\log_{10}(P)$', fontsize=20)\n",
        "\n",
        "\n",
        "def _build_gwas_comparison_figure(\n",
        "    gwas_x: Gwas,\n",
        "    gwas_y: Gwas,\n",
        "    pheno: str,\n",
        "    p_value_ax: plt.Axes,\n",
        "    effect_size_ax: plt.Axes,\n",
        ") -\u003e None:\n",
        "  plot_scatter(\n",
        "      x_gwas=gwas_x.gwas_results,\n",
        "      x_axis_method=gwas_x.gwas_label,\n",
        "      y_gwas=gwas_y.gwas_results,\n",
        "      y_axis_method=gwas_y.gwas_label,\n",
        "      ax=p_value_ax,\n",
        "      pheno=pheno,\n",
        "  )\n",
        "  p_value_ax.text(\n",
        "      0,\n",
        "      1.15,\n",
        "      'a',\n",
        "      transform=p_value_ax.transAxes,\n",
        "      fontsize=30,\n",
        "      va='top',\n",
        "      ha='right',\n",
        "  )\n",
        "  plot_scatter(\n",
        "      x_gwas=gwas_x.gwas_results,\n",
        "      x_axis_method=gwas_x.gwas_label,\n",
        "      y_gwas=gwas_y.gwas_results,\n",
        "      y_axis_method=gwas_y.gwas_label,\n",
        "      ax=effect_size_ax,\n",
        "      pheno=pheno,\n",
        "      pvalue=False,\n",
        "  )\n",
        "  effect_size_ax.text(\n",
        "      0,\n",
        "      1.15,\n",
        "      'b',\n",
        "      transform=effect_size_ax.transAxes,\n",
        "      fontsize=30,\n",
        "      va='top',\n",
        "      ha='right',\n",
        "  )\n",
        "\n",
        "  for ax in [p_value_ax, effect_size_ax]:\n",
        "    ax.spines[['right', 'top']].set_visible(False)\n",
        "    ax.grid(False)\n",
        "\n",
        "\n",
        "def build_gwas_comparison_figure(\n",
        "    gwas_x: Gwas,\n",
        "    gwas_y: Gwas,\n",
        "    pheno: str = 'COPD',\n",
        ") -\u003e plt.Figure:\n",
        "  \"\"\"Constructs a GWAS p-value and effect size comparison between two GWAS.\"\"\"\n",
        "  fig = plt.figure(figsize=(16, 8), constrained_layout=True)\n",
        "  spec = fig.add_gridspec(1, 2)\n",
        "\n",
        "  # Plot the scatter comparison of P values.\n",
        "  ax00 = fig.add_subplot(spec[0, 0])\n",
        "  ax01 = fig.add_subplot(spec[0, 1])\n",
        "  _build_gwas_comparison_figure(gwas_x, gwas_y, pheno, ax00, ax01)\n",
        "  return fig\n",
        "\n",
        "\n",
        "def build_figure_4(\n",
        "    main_gwas: Gwas,\n",
        "    overlap_gwas: Gwas,\n",
        "    pheno: str = 'COPD',\n",
        ") -\u003e plt.Figure:\n",
        "  \"\"\"Constructs Figure 4 from the manuscript.\"\"\"\n",
        "  fig = plt.figure(figsize=(16, 16), constrained_layout=True)\n",
        "  spec = fig.add_gridspec(2, 2)\n",
        "\n",
        "  # Plot the manhattan plot.\n",
        "  ax0 = fig.add_subplot(spec[0, :])\n",
        "  plot_manhattan(ax0, main_gwas, overlap_gwas)\n",
        "  ax0.text(\n",
        "      0,\n",
        "      1.15,\n",
        "      'a',\n",
        "      transform=ax0.transAxes,\n",
        "      fontsize=30,\n",
        "      va='top',\n",
        "      ha='right',\n",
        "  )\n",
        "  ax0.spines[['right', 'top']].set_visible(False)\n",
        "  ax0.grid(False)\n",
        "\n",
        "  # Plot the variant-in-hits comparison.\n",
        "  ax10 = fig.add_subplot(spec[1, 0])\n",
        "  ax11 = fig.add_subplot(spec[1, 1])\n",
        "  _build_gwas_comparison_figure(overlap_gwas, main_gwas, pheno, ax10, ax11)\n",
        "\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCTgpMatsJeX"
      },
      "outputs": [],
      "source": [
        "# The set of GWAS IDs used in the following analyses.\n",
        "GWAS_ML_BASED_COPD = 'ml_based_copd'\n",
        "GWAS_ML_BASED_COPD_NO_MRB_CASES = 'ml_based_copd_no_mrb_cases'\n",
        "GWAS_HOBBS_NATGEN_2017 = 'hobbs_natgen_2017'\n",
        "GWAS_ML_BASED_COPD_BINARIZED_GOLD_PREV = 'ml_based_copd_binarized_gold_prev'\n",
        "GWAS_SAKORNSAKOLPAT_NATGEN_2019 = 'sakornsakolpat_natgen_2019'\n",
        "GWAS_ML_BASED_COPD_BINARIZED = 'ml_based_copd_binarized'\n",
        "GWAS_MRB_LABELS_COPD = 'mrb_labels_copd'\n",
        "GWAS_SPIRO_GOLD_COPD = 'spiro_gold_copd'\n",
        "GWAS_GBMI_EXCLUDING_UKB_COPD = 'gbmi_excluding_ukb_copd'\n",
        "GWAS_SPIRO_GOLD_COPD_REGENIE = 'spiro_gold_copd_regenie'\n",
        "GWAS_SPIRO_GOLD_COPD_BOLT = 'spiro_gold_copd_bolt'\n",
        "GWAS_IDS = (\n",
        "    GWAS_ML_BASED_COPD,\n",
        "    GWAS_ML_BASED_COPD_NO_MRB_CASES,\n",
        "    GWAS_HOBBS_NATGEN_2017,\n",
        "    GWAS_ML_BASED_COPD_BINARIZED_GOLD_PREV,\n",
        "    GWAS_SAKORNSAKOLPAT_NATGEN_2019,\n",
        "    GWAS_ML_BASED_COPD_BINARIZED,\n",
        "    GWAS_MRB_LABELS_COPD,\n",
        "    GWAS_SPIRO_GOLD_COPD,\n",
        "    GWAS_GBMI_EXCLUDING_UKB_COPD,\n",
        "    GWAS_SPIRO_GOLD_COPD_REGENIE,\n",
        "    GWAS_SPIRO_GOLD_COPD_BOLT,\n",
        ")\n",
        "\n",
        "# A mapping of GWAS IDs to GWAS axis label.\n",
        "GWAS_ID_TO_GWAS_LABEL: dict[str, str] = {\n",
        "    GWAS_ML_BASED_COPD: 'ML-based',\n",
        "    GWAS_ML_BASED_COPD_NO_MRB_CASES: 'ML-based without MRB COPD',\n",
        "    GWAS_HOBBS_NATGEN_2017: 'Hobbs et al. 2017 NG',\n",
        "    GWAS_ML_BASED_COPD_BINARIZED_GOLD_PREV: (\n",
        "        'ML-based Binarized GOLD Prevalence'\n",
        "    ),\n",
        "    GWAS_SAKORNSAKOLPAT_NATGEN_2019: 'Sakornsakolpat et al. 2019 NG',\n",
        "    GWAS_ML_BASED_COPD_BINARIZED: 'ML-based Binarized',\n",
        "    GWAS_MRB_LABELS_COPD: 'MRB',\n",
        "    GWAS_SPIRO_GOLD_COPD: 'Proxy UKB GOLD',\n",
        "    GWAS_GBMI_EXCLUDING_UKB_COPD: 'GBMI Excluding UKB',\n",
        "    GWAS_SPIRO_GOLD_COPD_REGENIE: 'Proxy UKB GOLD (Regenie)',\n",
        "    GWAS_SPIRO_GOLD_COPD_BOLT: 'Proxy UKB GOLD (BOLT-LMM)',\n",
        "}\n",
        "\n",
        "# A mapping of GWAS IDs to GWAS results.\n",
        "g_gwas_id_to_gwas: dict[str, Gwas] = {\n",
        "    gwas_id: Gwas(gwas_id=gwas_id, gwas_label=GWAS_ID_TO_GWAS_LABEL[gwas_id])\n",
        "    for gwas_id in GWAS_IDS\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_N1xv0INps3"
      },
      "source": [
        "## Main Figures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u74GEB_4w7O"
      },
      "source": [
        "Figure 4: ML-based COPD discovers 67 novel association loci."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym2YoYAlKidm"
      },
      "outputs": [],
      "source": [
        "g_fig_4 = build_figure_4(\n",
        "    main_gwas=g_gwas_id_to_gwas[GWAS_ML_BASED_COPD],\n",
        "    overlap_gwas=g_gwas_id_to_gwas[GWAS_SAKORNSAKOLPAT_NATGEN_2019],\n",
        ")\n",
        "\n",
        "g_fig_4.savefig(\n",
        "    'figure_4.pdf',\n",
        "    dpi=300,\n",
        "    format='pdf',\n",
        "    bbox_inches='tight',\n",
        ")\n",
        "%download_file figure_4.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdNz_5F30Y4F"
      },
      "source": [
        "## Extended Data Figures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg0r8pes0cUF"
      },
      "source": [
        "Extended Data Figure 5: Statistical power comparison of ML-based COPD with Hobbs\n",
        "et al. Nature Genetics 2017 COPD GWAS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4dXk0dR0bul"
      },
      "outputs": [],
      "source": [
        "g_ext_data_fig_5 = build_gwas_comparison_figure(\n",
        "    gwas_x=g_gwas_id_to_gwas[GWAS_HOBBS_NATGEN_2017],\n",
        "    gwas_y=g_gwas_id_to_gwas[GWAS_ML_BASED_COPD],\n",
        ")\n",
        "\n",
        "g_ext_data_fig_5.savefig(\n",
        "    'extended_data_figure_5.pdf',\n",
        "    dpi=300,\n",
        "    format='pdf',\n",
        "    bbox_inches='tight',\n",
        ")\n",
        "%download_file extended_data_figure_5.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8R59WKy0bid"
      },
      "source": [
        "Extended Data Figure 6: Statistical power comparison of ML-based COPD without\n",
        "MRB COPD cases with Hobbs et al. Nature Genetics 2017 COPD GWAS."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIPUGZP908UW"
      },
      "outputs": [],
      "source": [
        "g_ext_data_fig_6 = build_gwas_comparison_figure(\n",
        "    gwas_x=g_gwas_id_to_gwas[GWAS_HOBBS_NATGEN_2017],\n",
        "    gwas_y=g_gwas_id_to_gwas[GWAS_ML_BASED_COPD_NO_MRB_CASES],\n",
        ")\n",
        "\n",
        "g_ext_data_fig_6.savefig(\n",
        "    'extended_data_figure_6.pdf',\n",
        "    dpi=300,\n",
        "    format='pdf',\n",
        "    bbox_inches='tight',\n",
        ")\n",
        "%download_file extended_data_figure_6.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_Z7447a1On1"
      },
      "source": [
        "Extended Data Figure 7: Statistical power comparison of binarized ML-based COPD\n",
        "with Sakornsakolpat et al. Nature Genetics 2019."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SO1Tsben1PEV"
      },
      "outputs": [],
      "source": [
        "g_ext_data_fig_7 = build_gwas_comparison_figure(\n",
        "    gwas_x=g_gwas_id_to_gwas[GWAS_SAKORNSAKOLPAT_NATGEN_2019],\n",
        "    gwas_y=g_gwas_id_to_gwas[GWAS_ML_BASED_COPD_BINARIZED],\n",
        ")\n",
        "\n",
        "g_ext_data_fig_7.savefig(\n",
        "    'extended_data_figure_7.pdf',\n",
        "    dpi=300,\n",
        "    format='pdf',\n",
        "    bbox_inches='tight',\n",
        ")\n",
        "%download_file extended_data_figure_7.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihnyVlWH1f1w"
      },
      "source": [
        "Extended Data Figure 8: Statistical power comparison of binarized ML-based COPD\n",
        "matching GOLD prevalence with Sakornsakolpat et al. Nature Genetics 2019."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faazPd1g1gGw"
      },
      "outputs": [],
      "source": [
        "g_ext_data_fig_8 = build_gwas_comparison_figure(\n",
        "    gwas_x=g_gwas_id_to_gwas[GWAS_SAKORNSAKOLPAT_NATGEN_2019],\n",
        "    gwas_y=g_gwas_id_to_gwas[GWAS_ML_BASED_COPD_BINARIZED_GOLD_PREV],\n",
        ")\n",
        "\n",
        "g_ext_data_fig_8.savefig(\n",
        "    'extended_data_figure_8.pdf',\n",
        "    dpi=300,\n",
        "    format='pdf',\n",
        "    bbox_inches='tight',\n",
        ")\n",
        "%download_file extended_data_figure_8.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDnPPtl9Nv70"
      },
      "source": [
        "## Supplementary Figures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsAoOCDH5AcH"
      },
      "source": [
        "Supplementary Figure 12: Statistical power comparison of ML-based COPD with GBMI\n",
        "COPD excluding UKB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4HNknWX5Apn"
      },
      "outputs": [],
      "source": [
        "g_suppl_fig_12 = build_gwas_comparison_figure(\n",
        "    gwas_x=g_gwas_id_to_gwas[GWAS_GBMI_EXCLUDING_UKB_COPD],\n",
        "    gwas_y=g_gwas_id_to_gwas[GWAS_ML_BASED_COPD],\n",
        ")\n",
        "\n",
        "g_suppl_fig_12.savefig(\n",
        "    'supplementary_figure_12.pdf',\n",
        "    dpi=300,\n",
        "    format='pdf',\n",
        "    bbox_inches='tight',\n",
        ")\n",
        "%download_file supplementary_figure_12.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3bWk5Xu6A18"
      },
      "source": [
        "Supplementary Figure 14: Statistical power comparison of binarized ML-based COPD\n",
        "with medical-record-based COPD labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCeeQP-l6Gnk"
      },
      "outputs": [],
      "source": [
        "g_suppl_fig_14 = build_gwas_comparison_figure(\n",
        "    gwas_x=g_gwas_id_to_gwas[GWAS_MRB_LABELS_COPD],\n",
        "    gwas_y=g_gwas_id_to_gwas[GWAS_ML_BASED_COPD_BINARIZED],\n",
        ")\n",
        "\n",
        "g_suppl_fig_14.savefig(\n",
        "    'supplementary_figure_14.pdf',\n",
        "    dpi=300,\n",
        "    format='pdf',\n",
        "    bbox_inches='tight',\n",
        "\n",
        ")\n",
        "%download_file supplementary_figure_14.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7R_5fAP6ROn"
      },
      "source": [
        "Supplementary Figure 15: Statistical power comparison of proxy-GOLD with\n",
        "Sakornsakolpat et al Nature Genetics 2019."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fECDade6RyR"
      },
      "outputs": [],
      "source": [
        "g_suppl_fig_15 = build_gwas_comparison_figure(\n",
        "    gwas_x=g_gwas_id_to_gwas[GWAS_SAKORNSAKOLPAT_NATGEN_2019],\n",
        "    gwas_y=g_gwas_id_to_gwas[GWAS_SPIRO_GOLD_COPD],\n",
        ")\n",
        "\n",
        "g_suppl_fig_15.savefig(\n",
        "    'supplementary_figure_15.pdf',\n",
        "    dpi=300,\n",
        "    format='pdf',\n",
        "    bbox_inches='tight',\n",
        ")\n",
        "%download_file supplementary_figure_15.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSBfuoNf6w1d"
      },
      "source": [
        "Supplementary Figure 17: Statistical power comparison of proxy-GOLD label using\n",
        "BOLT-LMM vs Regenie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T__UP2rv6v6L"
      },
      "outputs": [],
      "source": [
        "g_suppl_fig_17 = build_gwas_comparison_figure(\n",
        "    gwas_x=g_gwas_id_to_gwas[GWAS_SPIRO_GOLD_COPD_BOLT],\n",
        "    gwas_y=g_gwas_id_to_gwas[GWAS_SPIRO_GOLD_COPD_REGENIE],\n",
        ")\n",
        "\n",
        "g_suppl_fig_17.savefig(\n",
        "    'supplementary_figure_17.pdf',\n",
        "    dpi=300,\n",
        "    format='pdf',\n",
        "    bbox_inches='tight',\n",
        ")\n",
        "%download_file supplementary_figure_17.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNbjAW7_bz-H"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//learning/genomics/internal:genomics_colab",
        "kind": "private"
      },
      "name": "figure_4.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/phenotyping/spirometry/notebooks/plot_figure3.ipynb",
          "timestamp": 1677758642193
        },
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/phenotyping/spirometry/notebooks/plot_figure3.ipynb",
          "timestamp": 1667507357342
        },
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/phenotyping/spirometry/notebooks/plot_figure3.ipynb?cl=418101384",
          "timestamp": 1642543083643
        },
        {
          "file_id": "1htuYTVTPJEKlMfLjn_zk_FgUDCHqAUvc",
          "timestamp": 1640013481444
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
