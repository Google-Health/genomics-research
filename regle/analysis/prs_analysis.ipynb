{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMyYVUUHcnCAGY5yxymQ6+C"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VbyGa_IhXRgk"},"source":["# Preparation\n","\n","This section includes imports and functions."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"otMyZHIW0Fqs","executionInfo":{"status":"ok","timestamp":1717783770114,"user_tz":240,"elapsed":2320,"user":{"displayName":"Ted Yun","userId":"09506118669803633658"}}},"outputs":[],"source":["import dataclasses\n","from typing import Dict, List, Optional, Sequence, Union\n","\n","import abc\n","from typing import Callable\n","\n","import numpy as np\n","import pandas as pd\n","import scipy.stats\n","import sklearn\n","import sklearn.metrics\n","from sklearn import metrics"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"J8pr2zMLzmDH","executionInfo":{"status":"ok","timestamp":1717783770322,"user_tz":240,"elapsed":211,"user":{"displayName":"Ted Yun","userId":"09506118669803633658"}}},"outputs":[],"source":["# A function that computes a numeric outcome from label and prediction arrays.\n","BootstrappableFn = Callable[[np.ndarray, np.ndarray], float]\n","\n","# Constants denoting the expected case and control values for binary encodings.\n","BINARY_LABEL_CONTROL = 0\n","BINARY_LABEL_CASE = 1\n","\n","class Metric(abc.ABC):\n","  \"\"\"Represents a callable wrapper class for a named metric function.\n","\n","  Attributes:\n","    name: The metric's name.\n","  \"\"\"\n","\n","  def __init__(self, name: str, fn: BootstrappableFn) -> None:\n","    \"\"\"Initializes the metric.\n","\n","    Args:\n","      name: The metric's name.\n","      fn: A function that computes an outcome from label and prediction arrays.\n","        The function's signature should accept a `y_true` label array and a\n","        `y_pred` model prediction array. This function is invoked when the\n","        `Metric` instance is called.\n","    \"\"\"\n","    self._name: str = name\n","    self._fn: BootstrappableFn = fn\n","\n","  @property\n","  def name(self) -> str:\n","    \"\"\"The `Metric`'s name.\"\"\"\n","    return self._name\n","\n","  @abc.abstractmethod\n","  def _validate(self, y_true: np.ndarray, y_pred: np.ndarray) -> None:\n","    \"\"\"Validates the `y_true` labels and `y_pred` predictions.\n","\n","    Note: Each prediction subarray `y_pred[i, ...]` at index `i` should\n","    correspond to the `y_true[i]` label.\n","\n","    Args:\n","      y_true: The ground truth label targets.\n","      y_pred: The target predictions.\n","\n","    Raises:\n","      ValueError: If the first dimension of `y_true` and `y_pred` do not match.\n","    \"\"\"\n","    if y_true.shape[0] != y_pred.shape[0]:\n","      raise ValueError('`y_true` and `y_pred` first dimension mismatch: '\n","                       f'{y_true.shape[0]} != {y_pred.shape[0]}')\n","\n","  def __call__(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:\n","    \"\"\"Invokes the `Metric`'s function.\n","\n","    Args:\n","      y_true: The ground truth label values.\n","      y_pred: The target predictions.\n","\n","    Returns:\n","      The result of the `Metric.fn(y_true, y_pred)`.\n","    \"\"\"\n","    self._validate(y_true, y_pred)\n","    return self._fn(y_true, y_pred)\n","\n","  def __str__(self) -> str:\n","    return self.name\n","\n","\n","class ContinuousMetric(Metric):\n","  \"\"\"Represents a callable wrapper class for a named continuous label function.\n","\n","  Attributes:\n","    name: The metric's name.\n","  \"\"\"\n","\n","  # Note: This is a useful delegation since _validate is an @abc.abstractmethod.\n","  def _validate(  # pylint: disable=useless-super-delegation\n","      self,\n","      y_true: np.ndarray,\n","      y_pred: np.ndarray,\n","  ) -> None:\n","    \"\"\"Validates the `y_true` labels and `y_pred` predictions.\n","\n","    Args:\n","      y_true: The ground truth label values.\n","      y_pred: The target predictions.\n","\n","    Raises:\n","      ValueError: If the first dimension of `y_true` and `y_pred` do not match.\n","    \"\"\"\n","    super()._validate(y_true, y_pred)\n","\n","\n","class BinaryMetric(Metric):\n","  \"\"\"Represents a callable wrapper class for a named binary label function.\n","\n","  This class asserts that the provided `y_true` labels are binary targets in\n","  `{0, 1}` and that `y_true` contains at least one element in each class, i.e.,\n","  not all samples are from the same class.\n","\n","  Attributes:\n","    name: The metric's name.\n","  \"\"\"\n","\n","  def _validate(self, y_true: np.ndarray, y_pred: np.ndarray) -> None:\n","    \"\"\"Validates the `y_true` labels and `y_pred` predictions.\n","\n","    Args:\n","      y_true: The ground truth label values.\n","      y_pred: The target predictions.\n","\n","    Raises:\n","      ValueError: If the first dimension of `y_true` and `y_pred` do not match.\n","      ValueError: If `y_true` labels are nonbinary, i.e., not all values are in\n","        `{BINARY_LABEL_CONTROL, BINARY_LABEL_CASE}` or if `y_true` does not\n","        contain at least one element from each class.\n","    \"\"\"\n","    super()._validate(y_true, y_pred)\n","    if not is_valid_binary_label(y_true):\n","      raise ValueError('`y_true` labels must be in `{BINARY_LABEL_CONTROL, '\n","                       'BINARY_LABEL_CASE}` and have at least one element from '\n","                       f'each class; found: {y_true}')\n","\n","\n","def is_binary(metric: Metric) -> bool:\n","  \"\"\"Whether `metric` is a metric computed with binary `y_true` labels.\"\"\"\n","  return isinstance(metric, BinaryMetric)\n","\n","\n","def is_valid_binary_label(array: np.ndarray) -> bool:\n","  \"\"\"Whether `array` is a \"valid\" binary label array for bootstrapping.\n","\n","  We define a valid binary label array as an array that contains only binary\n","  values, i.e., `{BINARY_LABEL_CONTROL, BINARY_LABEL_CASE}`, and contains at\n","  least one value from each class.\n","\n","  Args:\n","    array: A numpy array.\n","\n","  Returns:\n","    Whether `array` is a \"valid\" binary label array.\n","  \"\"\"\n","  is_case_mask = array == BINARY_LABEL_CASE\n","  is_control_mask = array == BINARY_LABEL_CONTROL\n","  return (np.any(is_case_mask) and np.any(is_control_mask) and\n","          np.all(np.logical_or(is_case_mask, is_control_mask)))\n","\n","\n","def pearsonr(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n","  \"\"\"Returns the Pearson R correlation coefficient.\"\"\"\n","  # Note: We ignore the returned p value.\n","  r, _ = scipy.stats.pearsonr(y_true, y_pred)\n","  return r\n","\n","\n","def pearsonr_squared(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n","  \"\"\"Returns the square of the Pearson correlation coefficient.\"\"\"\n","  return pearsonr(y_true, y_pred)**2\n","\n","\n","def spearmanr(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n","  \"\"\"Returns the Spearman R correlation coefficient.\"\"\"\n","  # Note: We ignore the returned p value.\n","  r, _ = scipy.stats.spearmanr(y_true, y_pred)\n","  return r\n","\n","\n","def count(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n","  \"\"\"Returns the number of samples in `y_true`.\"\"\"\n","  if y_true.shape[0] != y_pred.shape[0]:\n","    raise ValueError('`y_true` and `y_pred` first dimension mismatch: '\n","                     f'{y_true.shape[0]} != {y_pred.shape[0]}')\n","  return len(y_true)\n","\n","\n","def frequency_between(y_true: np.ndarray, y_pred: np.ndarray,\n","                      percentile_lower: int, percentile_upper: int) -> float:\n","  \"\"\"Computes the positive class frequency within a percentile interval.\n","\n","  Args:\n","    y_true: Ground truth (correct) target values.\n","    y_pred: Estimated targets as returned by a classifier.\n","    percentile_lower: The lower bound (inclusive) of percentile. 0 to include\n","      all samples.\n","    percentile_upper: The upper bound (inclusive for 100, exclusive for all\n","      other values) of percentile. 100 to include all samples.\n","\n","  Returns:\n","    A [0.0, 1.0] float corresponding to the positive class frequency within\n","    the percentile interval.\n","\n","  Raises:\n","    ValueError: Invalid percentile range.\n","  \"\"\"\n","  if not 0 <= percentile_lower < 100:\n","    raise ValueError('`percentile_lower` must be in range `[0, 100)`: '\n","                     f'{percentile_lower}')\n","  if not 0 < percentile_upper <= 100:\n","    raise ValueError('`percentile_upper` must be in range `(0, 100]`: '\n","                     f'{percentile_upper}')\n","\n","  pred_lower_percentile, pred_upper_percentile = np.percentile(\n","      a=y_pred, q=[percentile_lower, percentile_upper])\n","  lower_mask = (y_pred >= pred_lower_percentile)\n","  if percentile_upper == 100:\n","    mask = lower_mask\n","  else:\n","    upper_mask = (y_pred < pred_upper_percentile)\n","    mask = lower_mask & upper_mask\n","  assert len(mask) == len(y_true)\n","  return np.mean(y_true[mask])\n","\n","\n","def frequency(y_true: np.ndarray,\n","              y_pred: np.ndarray,\n","              top_percentile: int = 100) -> float:\n","  \"\"\"Computes the positive class frequency within the top prediction percentile.\n","\n","  We select the subset of `y_true` labels corresponding to `y_pred`'s\n","  `top_percentile`-th prediction percetile and return the positive class\n","  frequency within this subset. `top_percentile=100` indicates the frequency for\n","  all samples.\n","\n","  Args:\n","    y_true: Ground truth (correct) target values.\n","    y_pred: Estimated targets as returned by a classifier.\n","    top_percentile: Determines the set of examples considered in the frequency\n","      calculation. The top percentile represents the top percentile by\n","      prediction risk. 100 indicates using all samples.\n","\n","  Returns:\n","    A [0.0, 1.0] float corresponding to the positive class frequency in the top\n","    percentile.\n","\n","  Raises:\n","    ValueError: `top_percentile` is not in range `(0, 100]`.\n","  \"\"\"\n","  if not 0 < top_percentile <= 100:\n","    raise ValueError('`top_percentile` must be in range `(0, 100]`: '\n","                     f'{top_percentile}')\n","\n","  return frequency_between(\n","      y_true,\n","      y_pred,\n","      percentile_lower=100 - top_percentile,\n","      percentile_upper=100)\n","\n","\n","def frequency_fn(top_percentile: int) -> BootstrappableFn:\n","  \"\"\"Returns a function that computes `frequency` at `top_percentile`.\"\"\"\n","\n","  def _frequency(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n","    return frequency(y_true, y_pred, top_percentile)\n","\n","  return _frequency\n","\n","\n","def frequency_between_fn(percentile_lower: int,\n","                         percentile_upper: int) -> BootstrappableFn:\n","  \"\"\"Returns a function that computes `frequency` in a percentile interval.\"\"\"\n","\n","  def _freq_between(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n","    return frequency_between(\n","        y_true,\n","        y_pred,\n","        percentile_lower=percentile_lower,\n","        percentile_upper=percentile_upper)\n","\n","  return _freq_between"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"M33VPEMF0sGd","executionInfo":{"status":"ok","timestamp":1717783770322,"user_tz":240,"elapsed":4,"user":{"displayName":"Ted Yun","userId":"09506118669803633658"}}},"outputs":[],"source":["# Represents a numpy array of indices for a single bootstrap sample.\n","IndexSample = np.ndarray\n","\n","\n","@dataclasses.dataclass(eq=False, order=False, frozen=True)\n","class NamedArray:\n","  \"\"\"Represents a named numpy array.\n","\n","  Attributes:\n","    name: The array name.\n","    values: A numpy array.\n","  \"\"\"\n","\n","  name: str\n","  values: np.ndarray\n","\n","  def __post_init__(self):\n","    if not self.name:\n","      raise ValueError('`name` must be specified.')\n","\n","  def __len__(self) -> int:\n","    return len(self.values)\n","\n","  def __str__(self) -> str:\n","    return f'{self.__class__.__name__}({self.name})'\n","\n","\n","@dataclasses.dataclass(eq=False, order=False, frozen=True)\n","class Label(NamedArray):\n","  \"\"\"Represents a named numpy array of ground truth label targets.\n","\n","  Attributes:\n","    name: The label name.\n","    values: A numpy array containing ground truth label targets.\n","  \"\"\"\n","\n","\n","@dataclasses.dataclass(eq=False, order=False, frozen=True)\n","class Prediction(NamedArray):\n","  \"\"\"Represents a named numpy array of target predictions.\n","\n","  Attributes:\n","    model_name: The name of the model that generated the predictions.\n","    name: The name of the predictions (e.g., the prediction column).\n","    values: A numpy array containing model predictions.\n","  \"\"\"\n","\n","  model_name: str\n","\n","  def __post_init__(self):\n","    super().__post_init__()\n","    if not self.model_name:\n","      raise ValueError('`model_name` must be specified.')\n","\n","  def __str__(self) -> str:\n","    return f'{self.__class__.__name__}({self.model_name}.{self.name})'\n","\n","\n","@dataclasses.dataclass(eq=False, order=False, frozen=True)\n","class SampleMean:\n","  \"\"\"Represents an estimate of the population mean for a given sample.\n","\n","  Attributes:\n","    mean: The mean of a given sample.\n","    stddev: The standard deviation of the sample mean.\n","    num_samples: The number of samples used to calculate `mean` and `stddev`.\n","\n","  Raises:\n","    ValueError: If `num_samples` is not >= `1`.\n","    ValueError: If `stddev` is not `0` when `num_samples` is `1`.\n","  \"\"\"\n","\n","  mean: float\n","  stddev: float\n","  num_samples: int\n","\n","  def __post_init__(self):\n","    # Ensure we have a valid number of samples.\n","    if self.num_samples < 1:\n","      raise ValueError(f'`num_samples` must be >= `1`: {self.num_samples}')\n","\n","    # Ensure the standard deviation is 0 given a single sample.\n","    if self.num_samples == 1 and self.stddev != 0.0:\n","      raise ValueError(\n","          f'`stddev` must be `0` if `num_samples` is `1`: {self.stddev:0.4f}'\n","      )\n","\n","  def __str__(self) -> str:\n","    return f'{self.mean:0.4f} (SD={self.stddev:0.4f}, n={self.num_samples})'\n","\n","\n","@dataclasses.dataclass(eq=False, order=False, frozen=True)\n","class ConfidenceInterval(SampleMean):\n","  \"\"\"Represents a confidence interval (CI) for a sample mean.\n","\n","  Attributes:\n","    mean: The mean of a given sample.\n","    stddev: The standard deviation of the sample mean.\n","    num_samples: The number of samples used to calculate `mean` and `stddev`.\n","    level: The confidence level at which the CI is calculated (e.g., 95).\n","    ci_lower: The lower limit of the `level` confidence interval.\n","    ci_upper: The upper limit of the `level` confidence interval.\n","\n","  Raises:\n","    ValueError: If `num_samples` is not >= `1`.\n","    ValueError: If `stddev` is not `0` when `num_samples` is `1`.\n","    ValueError: If `level` is not in range (0, 100].\n","    ValueError: If `ci_lower` or `ci_upper` does not match not `mean` when\n","      `num_samples` is `1`.\n","  \"\"\"\n","\n","  level: float\n","  ci_lower: float\n","  ci_upper: float\n","\n","  def __post_init__(self):\n","    super().__post_init__()\n","    # Ensure we have a valid confidence level.\n","    if not 0 < self.level <= 100:\n","      raise ValueError(f'`level` must be in range (0, 100]: {self.level:0.2f}')\n","\n","    # Ensure confidence intervals match the sample mean given a single sample.\n","    if self.num_samples == 1:\n","      if (self.ci_lower != self.mean) or (self.ci_upper != self.mean):\n","        raise ValueError(\n","            '`ci_lower` and `ci_upper` must match `mean` if `num_samples` is '\n","            f'1: mean={self.mean:0.4f}, ci_lower={self.ci_lower:0.4f}, '\n","            f'ci_upper={self.ci_upper:0.4f}'\n","        )\n","\n","  def __str__(self) -> str:\n","    return (\n","        f'{self.mean:0.4f} (SD={self.stddev:0.4f}, n={self.num_samples}, '\n","        f'{self.level:0>6.2f}% CI=[{self.ci_lower:0.4f}, '\n","        f'{self.ci_upper:0.4f}])'\n","    )\n","\n","\n","@dataclasses.dataclass(eq=False, order=False, frozen=True)\n","class Result:\n","  \"\"\"Represents a bootstrapped metric result for an individual model.\n","\n","  Attributes:\n","    model_name: The model's name.\n","    prediction_name: The model's prediction name (e.g., the model head's name or\n","      the label name used in training).\n","    metric_name: The metric's name.\n","    ci: A confidence interval describing the distribution of metric samples.\n","  \"\"\"\n","\n","  model_name: str\n","  prediction_name: str\n","  metric_name: str\n","  ci: ConfidenceInterval\n","\n","  def __post_init__(self):\n","    # Ensure model, prediction, and metric names are specified.\n","    if not self.model_name:\n","      raise ValueError('`model_name` must be specified.')\n","    if not self.prediction_name:\n","      raise ValueError('`prediction_name` must be specified.')\n","    if not self.metric_name:\n","      raise ValueError('`metric_name` must be specified.')\n","\n","  def __str__(self) -> str:\n","    return (\n","        f'{self.model_name}.{self.prediction_name}: '\n","        f'{self.metric_name}: {self.ci}'\n","    )\n","\n","\n","@dataclasses.dataclass(eq=False, order=False, frozen=True)\n","class PairedResult:\n","  \"\"\"Represents a paired bootstrapped metric result for two models.\n","\n","  Attributes:\n","    model_name_a: The first model's name.\n","    prediction_name_a: The first model's prediction name (e.g., the model head's\n","      name or the label name used in training).\n","    model_name_b: The second model's name.\n","    prediction_name_b: The second model's prediction name (e.g., the model\n","      head's name or the label name used in training).\n","    metric_name: The metric's name.\n","    ci: A confidence interval describing the distribution of differences between\n","      the first and second models' metric samples.\n","  \"\"\"\n","\n","  model_name_a: str\n","  prediction_name_a: str\n","  model_name_b: str\n","  prediction_name_b: str\n","  metric_name: str\n","  ci: ConfidenceInterval\n","\n","  def __post_init__(self):\n","    # Ensure model, prediction, and metric names are specified.\n","    if not self.model_name_a:\n","      raise ValueError('`model_name_a` must be specified.')\n","    if not self.prediction_name_a:\n","      raise ValueError('`prediction_name_a` must be specified.')\n","    if not self.model_name_b:\n","      raise ValueError('`model_name_b` must be specified.')\n","    if not self.prediction_name_b:\n","      raise ValueError('`prediction_name_b` must be specified.')\n","    if not self.metric_name:\n","      raise ValueError('`metric_name` must be specified.')\n","\n","  def __str__(self) -> str:\n","    return (\n","        f'({self.model_name_a}.{self.prediction_name_a} - '\n","        f'{self.model_name_b}.{self.prediction_name_b}): '\n","        f'{self.metric_name}: {self.ci}'\n","    )\n","\n","\n","def _reverse_paired_result(paired_result: PairedResult) -> PairedResult:\n","  \"\"\"Returns the \"(b - a)\" inverse of an \"(a - b)\" `PairedResult`.\"\"\"\n","  reversed_ci = ConfidenceInterval(\n","      mean=(paired_result.ci.mean * -1),\n","      stddev=paired_result.ci.stddev,\n","      num_samples=paired_result.ci.num_samples,\n","      level=paired_result.ci.level,\n","      ci_upper=(paired_result.ci.ci_lower * -1),\n","      ci_lower=(paired_result.ci.ci_upper * -1),\n","  )\n","  reversed_paired_result = PairedResult(\n","      model_name_a=paired_result.model_name_b,\n","      prediction_name_a=paired_result.prediction_name_b,\n","      model_name_b=paired_result.model_name_a,\n","      prediction_name_b=paired_result.prediction_name_a,\n","      metric_name=paired_result.metric_name,\n","      ci=reversed_ci,\n","  )\n","  return reversed_paired_result\n","\n","\n","def _compute_confidence_interval(\n","    samples: np.ndarray,\n","    ci_level: float,\n",") -> ConfidenceInterval:\n","  \"\"\"Computes the mean, standard deviation, and confidence interval for samples.\n","\n","  Args:\n","    samples: A boostrapped array of observed sample values.\n","    ci_level: The confidence level/width of the desired confidence interval.\n","\n","  Returns:\n","    A `Result` containing the mean, standard deviation, and the `ci_level`%\n","    confidence interval for the observed sample values.\n","  \"\"\"\n","  sample_mean = np.mean(samples, axis=0)\n","  sample_std = np.std(samples, axis=0)\n","\n","  lower_percentile = (100 - ci_level) / 2\n","  upper_percentile = 100 - lower_percentile\n","  percentiles = [lower_percentile, upper_percentile]\n","  ci_lower, ci_upper = np.percentile(a=samples, q=percentiles, axis=0)\n","\n","  ci = ConfidenceInterval(\n","      mean=sample_mean,\n","      stddev=sample_std,\n","      num_samples=len(samples),\n","      level=ci_level,\n","      ci_lower=ci_lower,\n","      ci_upper=ci_upper,\n","  )\n","\n","  return ci\n","\n","\n","def _generate_sample_indices(\n","    label: Label,\n","    is_binary: bool,\n","    num_bootstrap: int,\n","    seed: int,\n",") -> List[IndexSample]:\n","  \"\"\"Returns a list of `num_bootstrap` randomly sampled bootstrap indices.\n","\n","  Args:\n","    label: The ground truth label targets.\n","    is_binary: Whether to generate valid binary samples; i.e., each index sample\n","      contains at least one index corresponding to a label from each class.\n","    num_bootstrap: The number of bootstrap indices to generate.\n","    seed: The random seed; set prior to generating bootstrap indices.\n","\n","  Returns:\n","    A list of `num_bootstrap` bootstrap sample indices.\n","  \"\"\"\n","  rng = np.random.default_rng(seed)\n","  num_observations = len(label)\n","  sample_indices = []\n","  while len(sample_indices) < num_bootstrap:\n","    index = rng.integers(0, high=num_observations, size=num_observations)\n","    sample_true = label.values[index]\n","    # If computing a binary metric, skip indices that result in invalid labels.\n","    if is_binary and not is_valid_binary_label(sample_true):\n","      continue\n","    sample_indices.append(index)\n","  return sample_indices\n","\n","\n","def _compute_metric_samples(\n","    metric: Metric,\n","    label: Label,\n","    predictions: Sequence[Prediction],\n","    sample_indices: Sequence[np.ndarray],\n",") -> Dict[str, np.ndarray]:\n","  \"\"\"Generates `num_bootstrap` metric samples for each `Prediction`.\n","\n","  Note: This method assumes that label and prediction values are orded so that\n","  the value at index `i` in a given `Prediction` corresponds to the label value\n","  at index `i` in `label`. Both the `Label` and `Prediction` arrays are indexed\n","  using the given `sample_indices`.\n","\n","  Args:\n","    metric: An instance of a bootstrappable `Metric`; used to compute samples.\n","    label: The ground truth label targets.\n","    predictions: A list of target predictions from a set of models.\n","    sample_indices: An array of bootstrap sample indices. If empty, returns the\n","      single value computed on the entire dataset for each prediction.\n","\n","  Returns:\n","    A mapping of model names to the corresponding metric samples array.\n","  \"\"\"\n","  if not sample_indices:\n","    metric_samples = {}\n","    for prediction in predictions:\n","      value = metric(label.values, prediction.values)\n","      metric_samples[prediction.model_name] = np.asarray([value])\n","    return metric_samples\n","\n","  metric_samples = {prediction.model_name: [] for prediction in predictions}\n","  for index in sample_indices:\n","    sample_true = label.values[index]\n","    for prediction in predictions:\n","      sample_value = metric(sample_true, prediction.values[index])\n","      metric_samples[prediction.model_name].append(sample_value)\n","\n","  metric_samples = {\n","      name: np.asarray(samples) for name, samples in metric_samples.items()\n","  }\n","\n","  return metric_samples\n","\n","\n","def _compute_all_metric_samples(\n","    metrics: Sequence[Metric],\n","    contains_binary_metric: bool,\n","    label: Label,\n","    predictions: Sequence[Prediction],\n","    num_bootstrap: int,\n","    seed: int,\n",") -> Dict[str, Dict[str, np.ndarray]]:\n","  \"\"\"Generates `num_bootstrap` samples for each `Prediction` and `Metric`.\n","\n","  Args:\n","    metrics: A sequence of a bootstrappable `Metric` instances.\n","    contains_binary_metric: Whether the set of metrics contains a binary metric.\n","    label: The ground truth label targets.\n","    predictions: A list of target predictions from a set of models.\n","    num_bootstrap: The number of bootstrap iterations.\n","    seed: The random seed; set prior to generating bootstrap indices.\n","\n","  Returns:\n","    A mapping of metric names to model-sample dictionaries.\n","  \"\"\"\n","  sample_indices = _generate_sample_indices(\n","      label,\n","      contains_binary_metric,\n","      num_bootstrap,\n","      seed,\n","  )\n","  metric_samples = []\n","  for metric in metrics:\n","    metric_samples.append(\n","        _compute_metric_samples(\n","            metric=metric,\n","            label=label,\n","            predictions=predictions,\n","            sample_indices=sample_indices,\n","        )\n","    )\n","\n","  return {\n","      metric.name: metric_sample\n","      for metric, metric_sample in zip(metrics, metric_samples)\n","  }\n","\n","\n","def _process_metric_samples(\n","    metric: Metric,\n","    predictions: Sequence[Prediction],\n","    model_names_to_metric_samples: Dict[str, np.ndarray],\n","    ci_level: float,\n",") -> List[Result]:\n","  \"\"\"Compute `ConfidenceInterval`s for metric samples across predictions.\"\"\"\n","  results = []\n","  for prediction in predictions:\n","    metric_samples = model_names_to_metric_samples[prediction.model_name]\n","    ci = _compute_confidence_interval(metric_samples, ci_level)\n","    result = Result(prediction.model_name, prediction.name, metric.name, ci)\n","    results.append(result)\n","  return results\n","\n","\n","def _process_metric_samples_paired(\n","    metric: Metric,\n","    predictions: Sequence[Prediction],\n","    model_names_to_metric_samples: Dict[str, np.ndarray],\n","    ci_level: float,\n",") -> List[PairedResult]:\n","  \"\"\"Compute `ConfidenceInterval`s for paired samples across predictions.\"\"\"\n","  results = []\n","  for i, prediction_a in enumerate(predictions[:-1]):\n","    for prediction_b in predictions[i + 1 :]:\n","      # Compute the result of `prediction_a - prediction_b`.\n","      metric_samples_a = model_names_to_metric_samples[prediction_a.model_name]\n","      metric_samples_b = model_names_to_metric_samples[prediction_b.model_name]\n","      metric_samples_diff = metric_samples_a - metric_samples_b\n","      ci = _compute_confidence_interval(metric_samples_diff, ci_level)\n","      result = PairedResult(\n","          prediction_a.model_name,\n","          prediction_a.name,\n","          prediction_b.model_name,\n","          prediction_b.name,\n","          metric.name,\n","          ci,\n","      )\n","      results.append(result)\n","      # Derive and include the result of `prediction_b - prediction_a`.\n","      results.append(_reverse_paired_result(result))\n","  return results\n","\n","\n","def _bootstrap(\n","    metrics: Sequence[Metric],\n","    contains_binary_metric: bool,\n","    label: Label,\n","    predictions: Sequence[Prediction],\n","    num_bootstrap: int,\n","    ci_level: float,\n","    seed: int,\n",") -> Dict[str, List[Result]]:\n","  \"\"\"Performs bootstrapping for all models using the given metrics.\n","\n","  Args:\n","    metrics: A sequence of a bootstrappable `Metric` instances.\n","    contains_binary_metric: Whether the set of metrics contains a binary metric.\n","    label: The ground truth label targets.\n","    predictions: A list of target predictions from a set of models.\n","    num_bootstrap: The number of bootstrap iterations.\n","    ci_level: The confidence level/width of the desired confidence interval.\n","    seed: The random seed; set prior to generating bootstrap indices.\n","\n","  Returns:\n","    A dictionary mapping metric names to a list of `Result`s containing the mean\n","    metric values of each model over `num_bootstrap` bootstrapping iterations.\n","  \"\"\"\n","  metric_to_model_to_samples = _compute_all_metric_samples(\n","      metrics,\n","      contains_binary_metric,\n","      label,\n","      predictions,\n","      num_bootstrap,\n","      seed,\n","  )\n","  metric_samples = []\n","  for metric in metrics:\n","    metric_samples.append(\n","        _process_metric_samples(\n","            metric=metric,\n","            predictions=predictions,\n","            model_names_to_metric_samples=metric_to_model_to_samples[\n","                metric.name\n","            ],\n","            ci_level=ci_level,\n","        )\n","    )\n","\n","  return {\n","      metric.name: metric_sample\n","      for metric, metric_sample in zip(metrics, metric_samples)\n","  }\n","\n","\n","def _paired_bootstrap(\n","    metrics: Sequence[Metric],\n","    contains_binary_metric: bool,\n","    label: Label,\n","    predictions: Sequence[Prediction],\n","    num_bootstrap: int,\n","    ci_level: float,\n","    seed: int,\n",") -> Dict[str, List[PairedResult]]:\n","  \"\"\"Performs paired bootstrapping for all models using the given metrics.\n","\n","  Args:\n","    metrics: A sequence of a bootstrappable `Metric` instances.\n","    contains_binary_metric: Whether the set of metrics contains a binary metric.\n","    label: The ground truth label targets.\n","    predictions: A list of target predictions from a set of models.\n","    num_bootstrap: The number of bootstrap iterations.\n","    ci_level: The confidence level/width of the desired confidence interval.\n","    seed: The random seed; set prior to generating bootstrap indices.\n","\n","  Returns:\n","    A dictionary mapping metric names to `PairedResult`s containing the mean\n","    metric difference between models over `num_bootstrap` bootstrapping\n","    iterations.\n","  \"\"\"\n","  metric_to_model_to_samples = _compute_all_metric_samples(\n","      metrics,\n","      contains_binary_metric,\n","      label,\n","      predictions,\n","      num_bootstrap,\n","      seed,\n","  )\n","  metric_samples = []\n","  for metric in metrics:\n","    metric_samples.append(\n","        _process_metric_samples_paired(\n","            metric=metric,\n","            predictions=predictions,\n","            model_names_to_metric_samples=metric_to_model_to_samples[\n","                metric.name\n","            ],\n","            ci_level=ci_level,\n","        )\n","    )\n","\n","  return {\n","      metric.name: metric_sample\n","      for metric, metric_sample in zip(metrics, metric_samples)\n","  }\n","\n","\n","def _default_binary_metrics() -> List[BinaryMetric]:\n","  \"\"\"Returns `PerformanceMetrics`'s default metrics for binary target.\"\"\"\n","  metrics = [\n","      BinaryMetric('num', count),\n","      BinaryMetric('auc', sklearn.metrics.roc_auc_score),\n","      BinaryMetric('auprc', sklearn.metrics.average_precision_score),\n","  ]\n","  for percentile in [100, 10, 5, 1]:\n","    metrics.append(\n","        BinaryMetric(\n","            f'freq@{percentile:>03}%',\n","            frequency_fn(percentile),\n","        )\n","    )\n","  return metrics\n","\n","\n","def _default_continuous_metrics() -> List[ContinuousMetric]:\n","  \"\"\"Returns `PerformanceMetrics`'s default metrics for continuous target.\"\"\"\n","  metrics = [\n","      ContinuousMetric('num', count),\n","      ContinuousMetric('pearson', pearsonr),\n","      ContinuousMetric('pearsonr_squared', pearsonr_squared),\n","      ContinuousMetric('spearman', spearmanr),\n","      ContinuousMetric('mse', sklearn.metrics.mean_squared_error),\n","      ContinuousMetric('mae', sklearn.metrics.mean_absolute_error),\n","  ]\n","  return metrics\n","\n","\n","def _default_metrics(binary_targets: bool) -> List[Metric]:\n","  \"\"\"Returns `PerformanceMetrics`'s default set of metrics for the target type.\n","\n","  Args:\n","    binary_targets: Whether the target labels are binary. If false, the returned\n","      metrics assume continuous labels.\n","\n","  Returns:\n","    The default set of binary or continuous `bootstrap_metrics.Metric`s.\n","  \"\"\"\n","  if binary_targets:\n","    return _default_binary_metrics()\n","  return _default_continuous_metrics()\n","\n","\n","class PerformanceMetrics:\n","  \"\"\"A named collection of invocable, bootstrapable `Metric`s.\n","\n","  Initializes a class that applies the given `Metric` functions to new ground\n","  truth labels and predictions. `Metric`s can be evaluated with and without\n","  bootstrapping.\n","\n","  The default metrics are number of samples, auc, auprc, and frequency\n","  calculations for the top 100/10/5/1 top percentiles, if `default_metrics` is\n","  'binary'. If `default_metrics` is 'continuous', the default metrics are\n","  Pearson and Spearman correlations, the square of the Pearson correlation, mean\n","  squared error (MSE) and mean absolute error (MAE).\n","\n","  TODO(b/199452239): Refactor `PerformanceMetrics` so that the default metric\n","  set is not parameterized with a string.\n","\n","  Raises:\n","    ValueError: if an item in `metrics` is not of type `Metric`.\n","  \"\"\"\n","\n","  def __init__(\n","      self,\n","      name: str,\n","      default_metrics: Optional[str] = None,\n","      metrics: Optional[List[Metric]] = None,\n","  ) -> None:\n","\n","    if metrics is None:\n","      if default_metrics is None:\n","        raise ValueError('`default_metrics` is None and no metric is provided.')\n","      elif default_metrics == 'binary':\n","        metrics = _default_metrics(binary_targets=True)\n","      elif default_metrics == 'continuous':\n","        metrics = _default_metrics(binary_targets=False)\n","      else:\n","        raise ValueError(\n","            'unknown `default_metrics`: {}'.format(default_metrics)\n","        )\n","\n","    for metric in metrics:\n","      if not isinstance(metric, Metric):\n","        raise ValueError('Invalid metric value: must be of class `Metric`.')\n","\n","    if len(metrics) != len({metric.name for metric in metrics}):\n","      raise ValueError(f'Metric names must be unique: {metrics}')\n","\n","    self.name = name\n","    self.metrics = metrics\n","    self.contains_binary = any(is_binary(m) for m in metrics)\n","\n","  def compute(\n","      self,\n","      y_true: np.ndarray,\n","      y_pred: np.ndarray,\n","      mask: Optional[np.ndarray] = None,\n","      n_bootstrap: int = 0,\n","      conf_interval: float = 95,\n","      seed: int = 42,\n","  ) -> Dict[str, Result]:\n","    \"\"\"Evaluates all metrics using the given labels and predictions.\n","\n","    Args:\n","      y_true: Ground truth (correct) target values.\n","      y_pred: Estimated targets as returned by a classifier.\n","      mask: A boolean mask; applied to `y_true` and `y_pred`.\n","      n_bootstrap: An integer denoting the number of bootstrap iterations for\n","        each evaluation metric.\n","      conf_interval: A float denoting the width of confidence interval.\n","      seed: An int denoting the seed for the PRNG.\n","\n","    Returns:\n","      A dictionary of bootstrapped metrics keyed on metric name with\n","      `Result` values.\n","\n","    Raises:\n","      ValueError: If the dimensions of `y_true`, `y_pred`, or `mask` do not\n","      match, or labels are not in {0 , 1}.\n","    \"\"\"\n","    if len(y_true) != len(y_pred):\n","      raise ValueError('Label and prediction dimensions do not match.')\n","\n","    if mask is not None and len(mask) != len(y_pred):\n","      raise ValueError('Label and prediction dimensions do not match mask.')\n","\n","    if mask is not None:\n","      y_true = y_true[mask]\n","      y_pred = y_pred[mask]\n","\n","    # TODO(b/197539434): Pipe through non-empty names after public api refactor.\n","    label_name = 'label'\n","    label = Label(label_name, y_true)\n","    predictions = [Prediction(label_name, y_pred, 'model')]\n","\n","    metric_results = _bootstrap(\n","        self.metrics,\n","        contains_binary_metric=self.contains_binary,\n","        label=label,\n","        predictions=predictions,\n","        num_bootstrap=n_bootstrap,\n","        ci_level=conf_interval,\n","        seed=seed,\n","    )\n","\n","    # TODO(b/197539434): Remove temporary asserts after public api refactor.\n","    final_results = {}\n","    for metric_name, results in metric_results.items():\n","      assert len(results) == 1\n","      final_results[metric_name] = results[0]\n","\n","    return final_results\n","\n","  def compute_paired(\n","      self,\n","      y_true: np.ndarray,\n","      y_pred_a: np.ndarray,\n","      y_pred_b: np.ndarray,\n","      mask: Optional[np.ndarray] = None,\n","      n_bootstrap: int = 0,\n","      conf_interval: float = 95,\n","      seed: int = 42,\n","  ) -> Dict[str, PairedResult]:\n","    \"\"\"Computes a paired bootstrap value for each metric.\n","\n","    Args:\n","      y_true: Ground truth (correct) target values.\n","      y_pred_a: Target predictions from model A; compared to `y_pred_b`.\n","      y_pred_b: Target predictions from model B; compared to `y_pred_a`.\n","      mask: A boolean mask; applied to `y_true`, `y_pred_a`, and `y_pred_b`.\n","      n_bootstrap: An integer denoting the number of bootstrap iterations for\n","        each evaluation metric.\n","      conf_interval: A float denoting the width of confidence interval.\n","      seed: An int denoting the seed for the PRNG.\n","\n","    Returns:\n","      A dictionary of paired bootstrapped metrics keyed on metric name with\n","      `PairedResult` values.\n","\n","    Raises:\n","      ValueError: If the dimensions of `y_true`, `y_pred_a`, `y_pred_b` or\n","      `mask` do not match, or labels are not in {0 , 1}.\n","    \"\"\"\n","    if (len(y_true) != len(y_pred_a)) or (len(y_true) != len(y_pred_b)):\n","      raise ValueError('Label and prediction dimensions do not match.')\n","\n","    if mask is not None and len(mask) != len(y_pred_a):\n","      raise ValueError('Label and prediction dimensions do not match mask.')\n","\n","    if mask is not None:\n","      y_true = y_true[mask]\n","      y_pred_a = y_pred_a[mask]\n","      y_pred_b = y_pred_b[mask]\n","\n","    # TODO(b/197539434): Pipe through non-empty names after public api refactor.\n","    label_name = 'label'\n","    label = Label(label_name, y_true)\n","    first_model_name = 'model_a'\n","    predictions = [\n","        Prediction(label_name, y_pred_a, first_model_name),\n","        Prediction(label_name, y_pred_b, 'model_b'),\n","    ]\n","\n","    metric_results = _paired_bootstrap(\n","        self.metrics,\n","        contains_binary_metric=self.contains_binary,\n","        label=label,\n","        predictions=predictions,\n","        num_bootstrap=n_bootstrap,\n","        ci_level=conf_interval,\n","        seed=seed,\n","    )\n","\n","    # TODO(b/197539434): Remove temporary asserts after public api refactor.\n","    final_results = {}\n","    for metric_name, results in metric_results.items():\n","      assert len(results) == 2\n","      assert results[0].model_name_a == first_model_name\n","      final_results[metric_name] = results[0]\n","\n","    return final_results\n","\n","  def _print_results(\n","      self,\n","      title: str,\n","      results: Dict[str, Union[Result, PairedResult]],\n","  ) -> None:\n","    \"\"\"Prints each result object under the current name and given title.\"\"\"\n","    print(f'{self.name}: {title}')\n","    for _, result in sorted(results.items()):\n","      print(f'\\t{result}')\n","\n","  def compute_and_print(\n","      self,\n","      y_true: np.ndarray,\n","      y_pred: np.ndarray,\n","      mask: Optional[np.ndarray] = None,\n","      n_bootstrap: int = 0,\n","      conf_interval: float = 95,\n","      seed: int = 42,\n","      title: str = '',\n","  ) -> None:\n","    \"\"\"Evaluates and pretty-prints metrics using given labels and predictions.\n","\n","    Args:\n","      y_true: Ground truth (correct) target values.\n","      y_pred: Estimated targets as returned by a classifier.\n","      mask: A boolean mask; applied to `y_true` and `y_pred`.\n","      n_bootstrap: An integer denoting the number of bootstrap iterations for\n","        each evaluation metric.\n","      conf_interval: A float denoting the width of confidence interval.\n","      seed: An int denoting the seed for the PRNG.\n","      title: A title appended to the printed evaluation metrics.\n","\n","    Raises:\n","      ValueError: If any of `y_true`, `y_pred`, or `mask` are not of type\n","          numpy.array of if their dimensions do not match.\n","    \"\"\"\n","    results = self.compute(\n","        y_true,\n","        y_pred,\n","        mask=mask,\n","        n_bootstrap=n_bootstrap,\n","        conf_interval=conf_interval,\n","        seed=seed,\n","    )\n","    self._print_results(title, results)\n","\n","  def compute_paired_and_print(\n","      self,\n","      y_true: np.ndarray,\n","      y_pred_a: np.ndarray,\n","      y_pred_b: np.ndarray,\n","      mask: Optional[np.ndarray] = None,\n","      n_bootstrap: int = 0,\n","      conf_interval: float = 95,\n","      seed: int = 42,\n","      title: str = '',\n","      **kwargs,\n","  ) -> None:\n","    \"\"\"Evaluates and pretty-prints paired metrics.\n","\n","    Args:\n","      y_true: Ground truth (correct) target values.\n","      y_pred_a: Target predictions from model A; compared to `y_pred_b`.\n","      y_pred_b: Target predictions from model B; compared to `y_pred_a`.\n","      mask: A boolean mask; applied to `y_true`, `y_pred_a`, and `y_pred_b`.\n","      n_bootstrap: An integer denoting the number of bootstrap iterations for\n","        each evaluation metric.\n","      conf_interval: A float denoting the width of confidence interval.\n","      seed: An int denoting the seed for the PRNG.\n","      title: A title appended to the printed evaluation metrics.\n","      **kwargs: Additional keyword arguments passed to each Metric's `func`.\n","    \"\"\"\n","    results = self.compute_paired(\n","        y_true,\n","        y_pred_a,\n","        y_pred_b,\n","        mask=mask,\n","        n_bootstrap=n_bootstrap,\n","        conf_interval=conf_interval,\n","        seed=seed,\n","        **kwargs,\n","    )\n","    self._print_results(title, results)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"x4222NTc0xpR","executionInfo":{"status":"ok","timestamp":1717783770586,"user_tz":240,"elapsed":18,"user":{"displayName":"Ted Yun","userId":"09506118669803633658"}}},"outputs":[],"source":["N_BOOTSTRAP = 300\n","BOOTSTRAP_METRICS_LIST = [\n","    BinaryMetric('roc_auc', metrics.roc_auc_score),\n","    BinaryMetric('pr_auc', metrics.average_precision_score),\n","    ContinuousMetric('pearsonr', pearsonr),\n","    BinaryMetric('top10prev', frequency_fn(10)),\n","]\n","\n","def get_prs_eval_info(y_true, y_pred, name, as_dataframe=False):\n","  performance_metrics = PerformanceMetrics(\n","      'Metrics', metrics=BOOTSTRAP_METRICS_LIST)\n","  performance_metrics_values = performance_metrics.compute(\n","      y_true=y_true,\n","      y_pred=y_pred,\n","      n_bootstrap=N_BOOTSTRAP,\n","  )\n","  # print(performance_metrics_values, flush=True)\n","  roc_auc_ci = performance_metrics_values['roc_auc'].ci\n","  pr_auc_ci = performance_metrics_values['pr_auc'].ci\n","  pearsonr_ci = performance_metrics_values['pearsonr'].ci\n","  top10prev_ci = performance_metrics_values['top10prev'].ci\n","  info = {\n","      'method': name,\n","      'pearsonr': pearsonr_ci.mean,\n","      'pearsonr_std': pearsonr_ci.stddev,\n","      'pearsonr_lower': pearsonr_ci.ci_lower,\n","      'pearsonr_upper': pearsonr_ci.ci_upper,\n","      'roc_auc': roc_auc_ci.mean,\n","      'roc_auc_std': roc_auc_ci.stddev,\n","      'roc_auc_lower': roc_auc_ci.ci_lower,\n","      'roc_auc_upper': roc_auc_ci.ci_upper,\n","      'pr_auc': pr_auc_ci.mean,\n","      'pr_auc_std': pr_auc_ci.stddev,\n","      'pr_auc_lower': pr_auc_ci.ci_lower,\n","      'pr_auc_upper': pr_auc_ci.ci_upper,\n","      'top10prev': top10prev_ci.mean,\n","      'top10prev_std': top10prev_ci.stddev,\n","      'top10prev_lower': top10prev_ci.ci_lower,\n","      'top10prev_upper': top10prev_ci.ci_upper,\n","  }\n","  if as_dataframe:\n","    return pd.DataFrame(info, index=[0])\n","  else:\n","    return info\n","\n","\n","def get_prs_paired_eval_info(y_true,\n","                             y_pred1,\n","                             y_pred2,\n","                             name1,\n","                             name2,\n","                             as_dataframe=False):\n","  performance_metrics = PerformanceMetrics(\n","      'Metrics', metrics=BOOTSTRAP_METRICS_LIST)\n","  performance_metrics_values_paired = performance_metrics.compute_paired(\n","      y_true=y_true,\n","      y_pred_a=y_pred1,\n","      y_pred_b=y_pred2,\n","      n_bootstrap=N_BOOTSTRAP,\n","  )\n","  # print(performance_metrics_values_paired, flush=True)\n","  roc_auc_ci = performance_metrics_values_paired['roc_auc'].ci\n","  pr_auc_ci = performance_metrics_values_paired['pr_auc'].ci\n","  pearsonr_ci = performance_metrics_values_paired['pearsonr'].ci\n","  top10prev_ci = performance_metrics_values_paired['top10prev'].ci\n","  info = {\n","      'method_a': name1,\n","      'method_b': name2,\n","      'pearsonr': pearsonr_ci.mean,\n","      'pearsonr_std': pearsonr_ci.stddev,\n","      'pearsonr_lower': pearsonr_ci.ci_lower,\n","      'pearsonr_upper': pearsonr_ci.ci_upper,\n","      'roc_auc': roc_auc_ci.mean,\n","      'roc_auc_std': roc_auc_ci.stddev,\n","      'roc_auc_lower': roc_auc_ci.ci_lower,\n","      'roc_auc_upper': roc_auc_ci.ci_upper,\n","      'pr_auc': pr_auc_ci.mean,\n","      'pr_auc_std': pr_auc_ci.stddev,\n","      'pr_auc_lower': pr_auc_ci.ci_lower,\n","      'pr_auc_upper': pr_auc_ci.ci_upper,\n","      'top10prev': top10prev_ci.mean,\n","      'top10prev_std': top10prev_ci.stddev,\n","      'top10prev_lower': top10prev_ci.ci_lower,\n","      'top10prev_upper': top10prev_ci.ci_upper,\n","  }\n","  if as_dataframe:\n","    return pd.DataFrame(info, index=[0])\n","  else:\n","    return info"]},{"cell_type":"markdown","metadata":{"id":"NOaueJxRPmpG"},"source":["# Simulated data generation\n","\n","In this code example, we generate some simulated data (N=1,000) to demonstrate how to use the above code snippet to compute various metrics in the PRS evaluation part of the paper."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"iXHTm8dxzY2H","executionInfo":{"status":"ok","timestamp":1717783770587,"user_tz":240,"elapsed":16,"user":{"displayName":"Ted Yun","userId":"09506118669803633658"}}},"outputs":[],"source":["np.random.seed(42)\n","individual_prs1 = np.random.normal(size=(1000,))\n","individual_prs2 = 0.8 * individual_prs1 + 0.2 * np.random.normal(size=(1000,))\n","individual_phenotype = 0.3 * individual_prs1 + 0.7 * np.random.normal(\n","    size=(1000,)\n",")\n","individual_phenotype = (individual_phenotype >= 0).astype(int)\n","\n","data_df = pd.DataFrame({\n","    'prs1': individual_prs1,\n","    'prs2': individual_prs2,\n","    'phenotype': individual_phenotype,\n","})"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"height":206,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1717783770588,"user":{"displayName":"Ted Yun","userId":"09506118669803633658"},"user_tz":240},"id":"bzdHe1jqULbv","outputId":"d11b16cf-a363-47ad-b819-e306df9990f3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       prs1      prs2  phenotype\n","0  0.496714  0.677242          0\n","1 -0.138264  0.074315          0\n","2  0.647689  0.530077          0\n","3  1.523030  1.089037          1\n","4 -0.234153 -0.047678          0"],"text/html":["\n","  <div id=\"df-cd18c1b3-9796-4519-bf64-104aa58cdb3f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prs1</th>\n","      <th>prs2</th>\n","      <th>phenotype</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.496714</td>\n","      <td>0.677242</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.138264</td>\n","      <td>0.074315</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.647689</td>\n","      <td>0.530077</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.523030</td>\n","      <td>1.089037</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.234153</td>\n","      <td>-0.047678</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd18c1b3-9796-4519-bf64-104aa58cdb3f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cd18c1b3-9796-4519-bf64-104aa58cdb3f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cd18c1b3-9796-4519-bf64-104aa58cdb3f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d5df0d09-8df0-4e24-9f17-e94672213e43\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d5df0d09-8df0-4e24-9f17-e94672213e43')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d5df0d09-8df0-4e24-9f17-e94672213e43 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data_df","summary":"{\n  \"name\": \"data_df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"prs1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9792159381796757,\n        \"min\": -3.2412673400690726,\n        \"max\": 3.852731490654721,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          0.543360192379935,\n          0.9826909839455139,\n          -1.8408742313316453\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prs2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8005263506410991,\n        \"min\": -2.4852626735659844,\n        \"max\": 3.4321005411611654,\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          0.5511076945976712,\n          0.5725922028405726,\n          -1.4935892287728105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phenotype\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}],"source":["data_df.head()"]},{"cell_type":"markdown","metadata":{"id":"4LYsbEE3RdeF"},"source":["# PRS evaluation with bootstrapping\n","\n","The following code generates all evaluation metrics, namely Pearson R, AUC-ROC, AUC-PR, top 10% prevalence, and their 95% confidence intervals using bootstrapping. Note that, from the way we generated the simulated data, we expect the Pearson R of ~0.3 for `prs1` and we expect `prs1` to have higher correlation with the phenotype than `prs2`."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"height":101,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15212,"status":"ok","timestamp":1717783785790,"user":{"displayName":"Ted Yun","userId":"09506118669803633658"},"user_tz":240},"id":"WVJnK7BAPi33","outputId":"5b371f81-bc64-40ef-ed75-d9d080bd8475"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["  method  pearsonr  pearsonr_std  pearsonr_lower  pearsonr_upper  roc_auc  \\\n","0   prs1  0.333455      0.027456        0.277529        0.387433  0.69263   \n","\n","   roc_auc_std  roc_auc_lower  roc_auc_upper    pr_auc  pr_auc_std  \\\n","0     0.016445        0.65976       0.725288  0.675271    0.022152   \n","\n","   pr_auc_lower  pr_auc_upper  top10prev  top10prev_std  top10prev_lower  \\\n","0      0.632141      0.715912   0.770216       0.043321         0.688044   \n","\n","   top10prev_upper  \n","0          0.85078  "],"text/html":["\n","  <div id=\"df-ff180b96-08ac-4e83-a65c-65b91c7a1178\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>method</th>\n","      <th>pearsonr</th>\n","      <th>pearsonr_std</th>\n","      <th>pearsonr_lower</th>\n","      <th>pearsonr_upper</th>\n","      <th>roc_auc</th>\n","      <th>roc_auc_std</th>\n","      <th>roc_auc_lower</th>\n","      <th>roc_auc_upper</th>\n","      <th>pr_auc</th>\n","      <th>pr_auc_std</th>\n","      <th>pr_auc_lower</th>\n","      <th>pr_auc_upper</th>\n","      <th>top10prev</th>\n","      <th>top10prev_std</th>\n","      <th>top10prev_lower</th>\n","      <th>top10prev_upper</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>prs1</td>\n","      <td>0.333455</td>\n","      <td>0.027456</td>\n","      <td>0.277529</td>\n","      <td>0.387433</td>\n","      <td>0.69263</td>\n","      <td>0.016445</td>\n","      <td>0.65976</td>\n","      <td>0.725288</td>\n","      <td>0.675271</td>\n","      <td>0.022152</td>\n","      <td>0.632141</td>\n","      <td>0.715912</td>\n","      <td>0.770216</td>\n","      <td>0.043321</td>\n","      <td>0.688044</td>\n","      <td>0.85078</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff180b96-08ac-4e83-a65c-65b91c7a1178')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ff180b96-08ac-4e83-a65c-65b91c7a1178 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ff180b96-08ac-4e83-a65c-65b91c7a1178');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \")\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"method\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"prs1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pearsonr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.3334554859786796,\n        \"max\": 0.3334554859786796,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3334554859786796\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pearsonr_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.027455597173908577,\n        \"max\": 0.027455597173908577,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.027455597173908577\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pearsonr_lower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.2775293042598108,\n        \"max\": 0.2775293042598108,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.2775293042598108\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pearsonr_upper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.38743254268744753,\n        \"max\": 0.38743254268744753,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.38743254268744753\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6926303605619311,\n        \"max\": 0.6926303605619311,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6926303605619311\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.016445301315729702,\n        \"max\": 0.016445301315729702,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.016445301315729702\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc_lower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.659760150142918,\n        \"max\": 0.659760150142918,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.659760150142918\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc_upper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7252876945992696,\n        \"max\": 0.7252876945992696,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7252876945992696\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pr_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.675270596876246,\n        \"max\": 0.675270596876246,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.675270596876246\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pr_auc_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.02215152388674347,\n        \"max\": 0.02215152388674347,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.02215152388674347\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pr_auc_lower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6321413648383354,\n        \"max\": 0.6321413648383354,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6321413648383354\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pr_auc_upper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7159121917609861,\n        \"max\": 0.7159121917609861,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7159121917609861\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top10prev\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7702162426122681,\n        \"max\": 0.7702162426122681,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7702162426122681\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top10prev_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.04332125213088804,\n        \"max\": 0.04332125213088804,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.04332125213088804\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top10prev_lower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6880441176470588,\n        \"max\": 0.6880441176470588,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6880441176470588\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top10prev_upper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.8507797029702969,\n        \"max\": 0.8507797029702969,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8507797029702969\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":7}],"source":["get_prs_eval_info(\n","    y_true=data_df['phenotype'],\n","    y_pred=data_df['prs1'],\n","    name='prs1',\n","    as_dataframe=True\n",")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"height":101,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9709,"status":"ok","timestamp":1717783795493,"user":{"displayName":"Ted Yun","userId":"09506118669803633658"},"user_tz":240},"id":"puOfA5wuQeiJ","outputId":"99b92e16-0eb5-497f-f473-26ad3c955948"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["  method  pearsonr  pearsonr_std  pearsonr_lower  pearsonr_upper  roc_auc  \\\n","0   prs2  0.319189      0.027899        0.260433        0.373947   0.6837   \n","\n","   roc_auc_std  roc_auc_lower  roc_auc_upper    pr_auc  pr_auc_std  \\\n","0     0.016604       0.649911       0.717019  0.664467    0.022454   \n","\n","   pr_auc_lower  pr_auc_upper  top10prev  top10prev_std  top10prev_lower  \\\n","0      0.620486      0.706022   0.764624       0.042396         0.671552   \n","\n","   top10prev_upper  \n","0             0.84  "],"text/html":["\n","  <div id=\"df-09033991-c7e1-436e-a493-542a68bc86d3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>method</th>\n","      <th>pearsonr</th>\n","      <th>pearsonr_std</th>\n","      <th>pearsonr_lower</th>\n","      <th>pearsonr_upper</th>\n","      <th>roc_auc</th>\n","      <th>roc_auc_std</th>\n","      <th>roc_auc_lower</th>\n","      <th>roc_auc_upper</th>\n","      <th>pr_auc</th>\n","      <th>pr_auc_std</th>\n","      <th>pr_auc_lower</th>\n","      <th>pr_auc_upper</th>\n","      <th>top10prev</th>\n","      <th>top10prev_std</th>\n","      <th>top10prev_lower</th>\n","      <th>top10prev_upper</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>prs2</td>\n","      <td>0.319189</td>\n","      <td>0.027899</td>\n","      <td>0.260433</td>\n","      <td>0.373947</td>\n","      <td>0.6837</td>\n","      <td>0.016604</td>\n","      <td>0.649911</td>\n","      <td>0.717019</td>\n","      <td>0.664467</td>\n","      <td>0.022454</td>\n","      <td>0.620486</td>\n","      <td>0.706022</td>\n","      <td>0.764624</td>\n","      <td>0.042396</td>\n","      <td>0.671552</td>\n","      <td>0.84</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09033991-c7e1-436e-a493-542a68bc86d3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-09033991-c7e1-436e-a493-542a68bc86d3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-09033991-c7e1-436e-a493-542a68bc86d3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \")\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"method\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"prs2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pearsonr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.3191890184766251,\n        \"max\": 0.3191890184766251,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3191890184766251\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pearsonr_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.027898865889530153,\n        \"max\": 0.027898865889530153,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.027898865889530153\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pearsonr_lower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.2604328480042442,\n        \"max\": 0.2604328480042442,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.2604328480042442\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pearsonr_upper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.3739469506434232,\n        \"max\": 0.3739469506434232,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3739469506434232\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6836996447028457,\n        \"max\": 0.6836996447028457,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6836996447028457\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.01660378118234475,\n        \"max\": 0.01660378118234475,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.01660378118234475\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc_lower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6499110741641438,\n        \"max\": 0.6499110741641438,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6499110741641438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc_upper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7170185826451294,\n        \"max\": 0.7170185826451294,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7170185826451294\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pr_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6644674946186202,\n        \"max\": 0.6644674946186202,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6644674946186202\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pr_auc_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0224540065869167,\n        \"max\": 0.0224540065869167,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0224540065869167\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pr_auc_lower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6204864568922334,\n        \"max\": 0.6204864568922334,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6204864568922334\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pr_auc_upper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.7060224657169427,\n        \"max\": 0.7060224657169427,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.7060224657169427\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top10prev\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.764623511500396,\n        \"max\": 0.764623511500396,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.764623511500396\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top10prev_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.042396301865302535,\n        \"max\": 0.042396301865302535,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.042396301865302535\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top10prev_lower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6715519801980199,\n        \"max\": 0.6715519801980199,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6715519801980199\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top10prev_upper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.84,\n        \"max\": 0.84,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":8}],"source":["get_prs_eval_info(\n","    y_true=data_df['phenotype'],\n","    y_pred=data_df['prs2'],\n","    name='prs2',\n","    as_dataframe=True\n",")"]},{"cell_type":"markdown","metadata":{"id":"OiLCjqcrSjPg"},"source":["# PRS comparison with paired bootstrapping\n","\n","The following code snippet compares the performance of `prs1` and `prs2` using paired bootstrapping. Note that the difference is statistically significant with 95% paired bootstrapping confidence interval, if the lower and upper end of the confidence interval are both positive (implying `prs1` is significantly better than `prs2`) or both negative (implying `prs2` is significantly better than `prs1`)."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"height":101,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7610,"status":"ok","timestamp":1717783803097,"user":{"displayName":"Ted Yun","userId":"09506118669803633658"},"user_tz":240},"id":"oRKgjH_uR2wr","outputId":"8df67f16-31e6-4ae4-c904-b01a91390170"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["  method_a method_b  pearsonr  pearsonr_std  pearsonr_lower  pearsonr_upper  \\\n","0     prs1     prs2  0.014266      0.007112        0.000436        0.027211   \n","\n","    roc_auc  roc_auc_std  roc_auc_lower  roc_auc_upper    pr_auc  pr_auc_std  \\\n","0  0.008931     0.004466       0.000157       0.017171  0.010803    0.005761   \n","\n","   pr_auc_lower  pr_auc_upper  top10prev  top10prev_std  top10prev_lower  \\\n","0      -0.00061       0.02107   0.005593       0.026971        -0.042589   \n","\n","   top10prev_upper  \n","0         0.062382  "],"text/html":["\n","  <div id=\"df-f139f568-4da8-49a2-b47b-67a711340871\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>method_a</th>\n","      <th>method_b</th>\n","      <th>pearsonr</th>\n","      <th>pearsonr_std</th>\n","      <th>pearsonr_lower</th>\n","      <th>pearsonr_upper</th>\n","      <th>roc_auc</th>\n","      <th>roc_auc_std</th>\n","      <th>roc_auc_lower</th>\n","      <th>roc_auc_upper</th>\n","      <th>pr_auc</th>\n","      <th>pr_auc_std</th>\n","      <th>pr_auc_lower</th>\n","      <th>pr_auc_upper</th>\n","      <th>top10prev</th>\n","      <th>top10prev_std</th>\n","      <th>top10prev_lower</th>\n","      <th>top10prev_upper</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>prs1</td>\n","      <td>prs2</td>\n","      <td>0.014266</td>\n","      <td>0.007112</td>\n","      <td>0.000436</td>\n","      <td>0.027211</td>\n","      <td>0.008931</td>\n","      <td>0.004466</td>\n","      <td>0.000157</td>\n","      <td>0.017171</td>\n","      <td>0.010803</td>\n","      <td>0.005761</td>\n","      <td>-0.00061</td>\n","      <td>0.02107</td>\n","      <td>0.005593</td>\n","      <td>0.026971</td>\n","      <td>-0.042589</td>\n","      <td>0.062382</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f139f568-4da8-49a2-b47b-67a711340871')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f139f568-4da8-49a2-b47b-67a711340871 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f139f568-4da8-49a2-b47b-67a711340871');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"    as_dataframe=True)\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"method_a\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"prs1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"method_b\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"prs2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pearsonr\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.014266467502054426,\n        \"max\": 0.014266467502054426,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.014266467502054426\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pearsonr_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.007111892690604321,\n        \"max\": 0.007111892690604321,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.007111892690604321\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pearsonr_lower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.00043626824886599245,\n        \"max\": 0.00043626824886599245,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.00043626824886599245\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pearsonr_upper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.027211089302840434,\n        \"max\": 0.027211089302840434,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.027211089302840434\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.008930715859085309,\n        \"max\": 0.008930715859085309,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.008930715859085309\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.004466363148919537,\n        \"max\": 0.004466363148919537,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.004466363148919537\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc_lower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.00015733124729375172,\n        \"max\": 0.00015733124729375172,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.00015733124729375172\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roc_auc_upper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.017170818130808965,\n        \"max\": 0.017170818130808965,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.017170818130808965\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pr_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.010803102257625864,\n        \"max\": 0.010803102257625864,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.010803102257625864\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pr_auc_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.005760958016623593,\n        \"max\": 0.005760958016623593,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.005760958016623593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pr_auc_lower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": -0.0006104367572841078,\n        \"max\": -0.0006104367572841078,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.0006104367572841078\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pr_auc_upper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.02106968216083579,\n        \"max\": 0.02106968216083579,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.02106968216083579\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top10prev\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.005592731111872085,\n        \"max\": 0.005592731111872085,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.005592731111872085\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top10prev_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.026971273443313012,\n        \"max\": 0.026971273443313012,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.026971273443313012\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top10prev_lower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": -0.04258910891089107,\n        \"max\": -0.04258910891089107,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.04258910891089107\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"top10prev_upper\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.062381770529994184,\n        \"max\": 0.062381770529994184,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.062381770529994184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":9}],"source":["get_prs_paired_eval_info(\n","    y_true=data_df['phenotype'],\n","    y_pred1=data_df['prs1'],\n","    y_pred2=data_df['prs2'],\n","    name1='prs1',\n","    name2='prs2',\n","    as_dataframe=True)"]}]}