{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR4mdu8WQfRS"
      },
      "source": [
        "```\n",
        "Copyright 2021 Google LLC.\n",
        "\n",
        "Redistribution and use in source and binary forms, with or without\n",
        "modification, are permitted provided that the following conditions are met:\n",
        "\n",
        "1. Redistributions of source code must retain the above copyright notice, this\n",
        "   list of conditions and the following disclaimer.\n",
        "\n",
        "2. Redistributions in binary form must reproduce the above copyright notice,\n",
        "   this list of conditions and the following disclaimer in the documentation\n",
        "   and/or other materials provided with the distribution.\n",
        "\n",
        "3. Neither the name of the copyright holder nor the names of its contributors\n",
        "   may be used to endorse or promote products derived from this software\n",
        "   without specific prior written permission.\n",
        "\n",
        "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
        "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
        "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
        "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
        "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
        "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
        "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
        "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
        "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
        "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4mk2nI85A9S"
      },
      "source": [
        "##Phenotype Calling\n",
        "\n",
        "In this notebook, we load the model predictions, process them, call the phenotypes, join them with covariates and then store the final phenotypes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfB7_Xeb81Ct"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import functools\n",
        "import os\n",
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy as sp\n",
        "\n",
        "# Module defined within this repository.\n",
        "import pheno_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8U3gfjmn3lK"
      },
      "source": [
        "# Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-2PGonzlCYF"
      },
      "outputs": [],
      "source": [
        "# \"age\" is age at the first visit (visit 0)\n",
        "# \"age_1\" is age at the second visit (visit 1)\n",
        "COVARS = ['age', 'age_1', 'sex', 'genotype_array_enum', 'refractive_error'\n",
        "         ] + ['pc%d' % i for i in range(1, 16)]\n",
        "\n",
        "# The predction file should have the following columns. Categorical predictions\n",
        "# are encoded as {outcome}:{category} and their values should be in [0, 1]\n",
        "# and the values of all categories should sum to 1.\n",
        "# 'vertical_cup_to_disc:VERTICAL_CUP_TO_DISC' is a number in [0, 1].\n",
        "PRED_COLS = [\n",
        "    'eid',\n",
        "    'image_id',\n",
        "    'glaucoma_gradability:GRADABLE',\n",
        "    'glaucoma_gradability:UNGRADABLE',\n",
        "    'glaucoma_gradability:WITH_DIFFICULTY',\n",
        "    'vertical_cup_to_disc:VERTICAL_CUP_TO_DISC',\n",
        "    'vertical_cd_visibility:SUFFICIENT',\n",
        "    'vertical_cd_visibility:COMPROMISED',\n",
        "    'vertical_cd_visibility:UNABLE_TO_ASSESS',\n",
        "    'glaucoma_suspect_risk:HIGH_RISK',\n",
        "    'glaucoma_suspect_risk:LIKELY',\n",
        "    'glaucoma_suspect_risk:LOW_RISK',\n",
        "    'glaucoma_suspect_risk:NON_GLAUCOMATOUS',\n",
        "]\n",
        "\n",
        "# The covariates file with one row per \u003ceid\u003e that has \u003cCOVARS\u003e + 'eid' columns.\n",
        "COVARIATES_FILE = '/path/to/file'\n",
        "\n",
        "# the set of European ancestry EIDs\n",
        "EUROPEAN_EID_FILE = '/path/to/file'\n",
        "\n",
        "# Model predictions with one row per \u003cimage_id\u003e that has \u003cPRED_COLS\u003e columns.\n",
        "PREDS_FILE = '/path/to/file'\n",
        "\n",
        "OUTPUT_FILE = '/path/to/file'\n",
        "\n",
        "# indicates visits to use for calling VCDR\n",
        "_VISIT_IDS = [0, 1]\n",
        "\n",
        "# indicates eyes to use for calling VCDR\n",
        "# 1: left, 2: right\n",
        "_EYES = [1, 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n36aRPEpoEXp"
      },
      "source": [
        "#Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBOdqKFooDrc"
      },
      "outputs": [],
      "source": [
        "def _nan_date(datestr):\n",
        "  \"\"\"Convert date str to datetime.\"\"\"\n",
        "  try:\n",
        "    return datetime.datetime.strptime(datestr, '%Y-%m-%d')\n",
        "  except TypeError:\n",
        "    return np.nan\n",
        "\n",
        "\n",
        "def compute_age_1(df):\n",
        "  \"\"\"Returns a series corresponding to age_1.\"\"\"\n",
        "  retval = df['age_1_raw'].copy()\n",
        "  visit0_date = df['date_visit_0'].apply(_nan_date)\n",
        "  visit1_date = df['date_visit_1'].apply(_nan_date)\n",
        "  # Pick the midpoint between start of 2012 and end of 2013.\n",
        "  # Empirically, the mean date of the second visit is 2013/01/17,\n",
        "  # so this is reasonable.\n",
        "  visit1_mean_date = datetime.datetime(2013, 1, 1)\n",
        "  known_date_delta = ((visit1_date - visit0_date) /\n",
        "                      np.timedelta64(1, 'Y')).round()\n",
        "  mean_date_delta = ((visit1_mean_date - visit0_date) /\n",
        "                     np.timedelta64(1, 'Y')).round()\n",
        "\n",
        "  needed_mask = df['age_1_raw'].isna()\n",
        "  from_known_mask = needed_mask \u0026 known_date_delta.notna()\n",
        "  from_imputed_mask = needed_mask \u0026 ~from_known_mask\n",
        "  print('Inferring {} ages, {} from both visits and {} from first only.'.format(\n",
        "      needed_mask.sum(), from_known_mask.sum(), from_imputed_mask.sum()))\n",
        "  retval[from_known_mask] = (df['age'] + known_date_delta)[from_known_mask]\n",
        "  retval[from_imputed_mask] = (df['age'] + mean_date_delta)[from_imputed_mask]\n",
        "  assert retval.isna().sum() == 0\n",
        "  return retval\n",
        "\n",
        "\n",
        "def load_eid_file(filename):\n",
        "  \"\"\"Returns a set of EIDs from a CSV file with an 'eid' column.\"\"\"\n",
        "  retval = set()\n",
        "  with open(filename) as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "      try:\n",
        "        eid = int(row['eid'])\n",
        "      except (KeyError, ValueError):\n",
        "        raise ValueError(\n",
        "            'Row must contain an integer 'eid' field: {}'.format(row))\n",
        "      else:\n",
        "        retval.add(eid)\n",
        "  return retval\n",
        "\n",
        "\n",
        "def call_linear_risk(df_all,\n",
        "                     risk_col,\n",
        "                     filter_col=None,\n",
        "                     filter_threshold=0.7,\n",
        "                     base_cols=None,\n",
        "                     agg_op='max',\n",
        "                     pheno_name=None):\n",
        "  \"\"\"Call linear risk for the given risk type, filtering if needed.\"\"\"\n",
        "  name = pheno_name if pheno_name is not None else risk_col\n",
        "  print('Calling pheno for: {}'.format(name), flush=True)\n",
        "  df = df_all.copy()\n",
        "\n",
        "  if base_cols is None:\n",
        "    base_cols = ['eid', 'file_name']\n",
        "\n",
        "  cols_to_keep = [risk_col] + base_cols\n",
        "\n",
        "  if filter_col is not None:\n",
        "    df = drop_col_below_threshold(\n",
        "        df, filter_col, lower_bound=filter_threshold)\n",
        "\n",
        "  df = df[cols_to_keep]\n",
        "  if agg_op == 'max':\n",
        "    df = take_max(df, risk_col).drop(columns=['file_name'])\n",
        "  elif agg_op == 'avg':\n",
        "    df = take_avg(df, risk_col).reset_index()\n",
        "  else:\n",
        "    raise ValueError('agg_op can be either 'max' or 'avg'')  \n",
        "\n",
        "  if pheno_name is not None:\n",
        "    df = df.rename(columns={risk_col: pheno_name})\n",
        "  return df  \n",
        "\n",
        "\n",
        "def call_per_visit_phenotype(images, add_pheno):\n",
        "  \"\"\"Calls a per visit phenotype.\n",
        "\n",
        "  Args:\n",
        "    images: A list of pairs where each pair represents an image. The first \n",
        "      element is the name of image that we use to extract the corresponding eye\n",
        "      and visit for the image. The second element is the predicted phenotype.\n",
        "    add_pheno: A function that given the dictionary of visits and eyes, returns \n",
        "      a tuple of the phenotype and its covariates.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of the phenotype and its covariates.\n",
        "  \"\"\"\n",
        "  phenos = {}\n",
        "  for image in images:\n",
        "    _, eye, visit, _ = extract_attr(image[0])\n",
        "    pheno = image[1]\n",
        "    if visit not in phenos:\n",
        "      phenos[visit] = {}\n",
        "    if eye not in phenos[visit]:\n",
        "      phenos[visit][eye] = []\n",
        "    phenos[visit][eye].append(pheno)\n",
        "\n",
        "  return add_pheno(phenos)\n",
        "\n",
        "\n",
        "def pheno_visit(phenos):\n",
        "  \"\"\"Returns the aggregated phenotype for a visit with some predictions.\n",
        "\n",
        "  Visit 0 is preferred to visit 1.\n",
        "\n",
        "  Args:\n",
        "    phenos: Dictionary of per visit per eye predictions.\n",
        "\n",
        "  Returns:\n",
        "    A triple: 1) the phenotype which is aggregated PHENO for a visit, 2) a \n",
        "      covariate for the visit used in the aggregation, and 3) the number of eyes\n",
        "      with a prediction.\n",
        "  \"\"\"\n",
        "  for visit in _VISIT_IDS:\n",
        "    if visit in phenos:\n",
        "      eye_vals = [phenos[visit][eye] for eye in _EYES if eye in phenos[visit]]      \n",
        "      avg = np.mean([np.mean(vals) for vals in eye_vals])\n",
        "      return avg, visit, len(phenos[visit])\n",
        "  raise ValueError('No data in any visit')\n",
        "\n",
        "\n",
        "def pheno_visit_eye(phenos, visit, eye):\n",
        "  \"\"\"Returns the aggregated phenotype for the given visit and eye.\n",
        "\n",
        "  Args:\n",
        "    phenos: Dictionary of per visit per eye predictions.\n",
        "    visit: The visit to use for aggregation.\n",
        "    eye: The eye to use for aggregation.\n",
        "\n",
        "  Returns:\n",
        "    A pair: the phenotype which is aggregated PHENO over visit and eye, and a \n",
        "      covariate for the number of images used.\n",
        "    Note: If there are no images available, we return NAN for the phenotype \n",
        "    value.\n",
        "  \"\"\"\n",
        "  if visit in phenos and eye in phenos[visit]:\n",
        "    return np.mean(phenos[visit][eye]), len(phenos[visit][eye])\n",
        "  return np.nan, 0\n",
        "\n",
        "\n",
        "def get_pheno_df(images_df, pheno, columns, add_pheno_func):\n",
        "  \"\"\"Given the images DataFrame creates the phenotype DataFrame.\n",
        "\n",
        "  Args:\n",
        "    images_df: The DataFrame of images.\n",
        "    pheno: The name of the phenotype.\n",
        "    columns: The name of columns for the phenotype and its corresponding \n",
        "      covariates. These column names must match the return tuple of \n",
        "      `add_pheno_func`.\n",
        "    add_pheno_func: A function that given the dictionary of visits and eyes, \n",
        "      returns a tuple of the phenotype and its covariates.\n",
        "\n",
        "  Returns:\n",
        "    The phenotype DataFrame to be merged on EID with other phenotypes.\n",
        "  \"\"\"\n",
        "  pheno_df = images_df.copy()\n",
        "\n",
        "  # DataFrames are much faster if we apply a change on a single column rather \n",
        "  # than a row. We create a column to gather all information needed in a single\n",
        "  # column. Later, we derive the value of phenotype and covariates from the\n",
        "  # value of this column.\n",
        "  pheno_df['filename_pheno'] = list(\n",
        "      zip(pheno_df['file_name'], pheno_df[pheno]))\n",
        "  pheno_df = pheno_df[['eid', 'filename_pheno']]  # Keep only required columns.\n",
        "  pheno_df = pheno_df.groupby('eid').agg(list).reset_index()\n",
        "\n",
        "  # We define a column for each column name in `columns` in one shot.\n",
        "  pheno_df[columns] = pd.DataFrame(pheno_df['filename_pheno'].apply(\n",
        "      functools.partial(call_per_visit_phenotype,\n",
        "                        add_pheno=add_pheno_func)).tolist())\n",
        "\n",
        "  return pheno_df.drop(columns='filename_pheno')  # Drop the auxiliary column.     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ2zmlMfJhYN"
      },
      "source": [
        "# Extract Covariates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IO6fcwRsKEkv"
      },
      "outputs": [],
      "source": [
        "df_covar_all = pheno_utils.load_csv(COVARIATES_FILE, sep='\\t')\n",
        "\n",
        "# compute age at visit 1, so we have ages at both visits\n",
        "df_covar_all['age_1'] = compute_age_1(df_covar_all)\n",
        "df_covar = df_covar_all[['eid'] + COVARS]\n",
        "\n",
        "assert (df_covar_all['age_1'] \u003e= df_covar_all['age']).all()\n",
        "\n",
        "# Load European EIDs\n",
        "euro_eids = load_eid_file(EUROPEAN_EID_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAvynk09Jl_Y"
      },
      "source": [
        "# Load and preprocess predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jz66tbfEm2r"
      },
      "outputs": [],
      "source": [
        "# Load model predictions for all UKB images\n",
        "preds_all = pheno_utils.load_predictions(\n",
        "    preds_csv=PREDS_CSV, cols_to_use=PRED_COLS)\n",
        "\n",
        "# Return value is a quadruple of:\n",
        "# EID, eye in [1, 2], visit in [0, 1], index of the image.\n",
        "extract_attr = pheno_utils.extract_attributes_from_image_path\n",
        "\n",
        "# extract eids\n",
        "image_eids = preds_all['file_name'].apply(\n",
        "    lambda filename: extract_attr(filename)[0])\n",
        "pd.testing.assert_series_equal(preds_all['eid'], image_eids, check_names=False)\n",
        "\n",
        "# extract left/right eye\n",
        "preds_all['eye'] = preds_all['file_name'].apply(\n",
        "    lambda filename: extract_attr(filename)[1])\n",
        "\n",
        "# extract visit id\n",
        "preds_all['visit'] = preds_all['file_name'].apply(\n",
        "    lambda filename: extract_attr(filename)[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyr96hO89O3t"
      },
      "outputs": [],
      "source": [
        "# Add 'is_euro' flag to preds based on eid.\n",
        "preds_all['is_euro'] = preds_all['eid'].isin(euro_eids)\n",
        "\n",
        "# Immediately drop ungradable images\n",
        "preds_all = pheno_utils.drop_col_below_threshold(\n",
        "    preds_all, 'gradability', lower_bound=0.7)\n",
        "\n",
        "# Separate European and Non-European samples\n",
        "preds_euro = preds_all[preds_all['is_euro'] == True]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3_EuBsqrD14"
      },
      "source": [
        "# Call Phenotypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyiBmQWFWFPC"
      },
      "source": [
        "## Glaucoma liability phenotype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-oFoeCUJW0c"
      },
      "outputs": [],
      "source": [
        "linear_risk_phenos = [{\n",
        "    'label': 'glaucoma_risk',\n",
        "    'risk_col': 'glaucoma_risk',\n",
        "    'filter_col': 'gradability',\n",
        "    'filter_threshold': 0.7,\n",
        "}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ua8Q3zbW8qMZ"
      },
      "outputs": [],
      "source": [
        "# Create a 'master' dataframe of EIDs and then merge each phenotype to this\n",
        "# dataframe.\n",
        "phenos_euro = preds_euro[['eid']].copy().drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBPJPnC5L5J9"
      },
      "outputs": [],
      "source": [
        "# Call linear risk phenos\n",
        "for pheno in linear_risk_phenos:\n",
        "  pheno_df = call_linear_risk(\n",
        "      preds_euro,  \n",
        "      pheno['risk_col'],\n",
        "      filter_col=pheno['filter_col'],\n",
        "      filter_threshold=pheno['filter_threshold'],\n",
        "      agg_op=pheno['agg_op'] if 'agg_op' in pheno else 'max',\n",
        "      pheno_name=pheno['label'])\n",
        "  phenos_euro = phenos_euro.merge(pheno_df, on='eid', how='left')\n",
        "\n",
        "# Compute glaucoma risk logit\n",
        "phenos_euro['glaucoma_liability'] = sp.special.logit(\n",
        "    phenos_euro['glaucoma_risk'])  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzV84kdw8vVp"
      },
      "source": [
        "## VCDR per-visit phenotype\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scOe_J3R8vV-"
      },
      "outputs": [],
      "source": [
        "# For VCDR, drop the images with low 'vertical_cd_visibility'\n",
        "preds_euro_vcdr = pheno_utils.drop_col_below_threshold(\n",
        "    preds_euro.copy(), 'vertical_cd_visibility', lower_bound=0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGqPjZYR3qDJ"
      },
      "outputs": [],
      "source": [
        "# Note: grdabaility_visit is the covariate for the VCDR GWAS.\n",
        "visit_phenos = [{\n",
        "    'label': 'vcdr_visit',\n",
        "    'pheno': 'vertical_cup_to_disc',\n",
        "}, {\n",
        "    'label': 'gradability_visit',\n",
        "    'pheno': 'gradability'\n",
        "}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgeQpYdC8vWD"
      },
      "outputs": [],
      "source": [
        "visit_and_eyes_set = False\n",
        "\n",
        "for visit_pheno in visit_phenos:\n",
        "  label = visit_pheno['label']\n",
        "  pheno = visit_pheno['pheno']\n",
        "  print('Adding {} phenotype...'.format(label), flush=True)\n",
        "  pheno_df = get_pheno_df(preds_euro_vcdr, pheno, [label, 'visit', 'num_eyes'],\n",
        "                          pheno_visit)\n",
        "  # visit and num_eyes covariate will be the same for all 'visit' phenotypes.\n",
        "  if visit_and_eyes_set:\n",
        "    pheno_df = pheno_df.drop(columns=['visit', 'num_eyes'])\n",
        "\n",
        "  phenos_euro = phenos_euro.merge(pheno_df, on='eid', how='left')\n",
        "  for visit in _VISIT_IDS:\n",
        "    for eye in _EYES:\n",
        "      ve = '{}_eye{}'.format(visit, eye)\n",
        "      # The current `label` already has '_visit' as the suffix, so no need to \n",
        "      # add 'visit' prefix to `ve`.\n",
        "      pheno_name = label + ve\n",
        "      covariate_name = 'visit' + ve + '_num_images'\n",
        "\n",
        "      print('Adding {} phenotype...'.format(pheno_name), flush=True)\n",
        "      pheno_df = get_pheno_df(\n",
        "          preds_euro_vcdr, pheno, [pheno_name, covariate_name],\n",
        "          functools.partial(pheno_visit_eye, visit=visit, eye=eye))\n",
        "      if visit_and_eyes_set:\n",
        "        pheno_df = pheno_df.drop(columns=[covariate_name])\n",
        "      phenos_euro = phenos_euro.merge(pheno_df, on='eid', how='left')\n",
        "      \n",
        "  # all proper covariates are added so we do not need to add them again.\n",
        "  if not visit_and_eyes_set:\n",
        "    visit_and_eyes_set = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyUprW3RF3uW"
      },
      "source": [
        "# Prepare and write pheno-covar file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ily3wTdJMnt"
      },
      "outputs": [],
      "source": [
        "# Join with covariates\n",
        "phenos_euro = phenos_euro.merge(\n",
        "    df_covar, on='eid', how='inner', suffixes=('', '_covar'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8w7iYtcRUgF"
      },
      "outputs": [],
      "source": [
        "# Define a new covariate for the age of visit used in `vcdr_visit`.\n",
        "phenos_euro['visit_age'] = np.where(phenos_euro['visit'] == 0,\n",
        "                                    phenos_euro['age'], phenos_euro['age_1'])\n",
        "\n",
        "print('Num individuals with `vcdr_visit`:',\n",
        "      len(phenos_euro[phenos_euro['vcdr_visit'].notna()]))\n",
        "print(\n",
        "    'Num individuals with `vcdr_visit` and `visit_age`:',\n",
        "    len(phenos_euro[phenos_euro['vcdr_visit'].notna()\n",
        "                    \u0026 phenos_euro['visit_age'].notna()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xLVyFc8N3Pt"
      },
      "outputs": [],
      "source": [
        "with open(OUTPUT_FILE, 'w') as fw:\n",
        "  phenos_euro.to_csv(fw, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "phenotype_calling",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1vOF5n9aA-u-UD0Oatp4fiMmvCEKB4rwE",
          "timestamp": 1615658631402
        },
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/colab/notebooks/glaucoma_phenotype_calling.vcdr.ipynb",
          "timestamp": 1615487781455
        },
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/colab/notebooks/glaucoma_phenotype_calling.v2.ipynb?workspaceId=babaka:gcs::citc",
          "timestamp": 1580435228346
        },
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/colab/notebooks/phenotype_calling.ipynb",
          "timestamp": 1573670795749
        },
        {
          "file_id": "/piper/depot/google3/experimental/users/jtcosentino/mlderived_gwas/notebooks/ML_derived_GWAS_Proposal.ipynb?workspaceId=jtcosentino:mlderived-gwas::citc",
          "timestamp": 1568936381805
        },
        {
          "file_id": "1LY-fvCZ49yOFP-_l6-pu2OJCmzvnONgV",
          "timestamp": 1566336861140
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
