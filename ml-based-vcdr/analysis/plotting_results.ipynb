{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xByuHu-fQoW0"
      },
      "source": [
        "```\n",
        "Copyright 2021 Google LLC.\n",
        "\n",
        "Redistribution and use in source and binary forms, with or without\n",
        "modification, are permitted provided that the following conditions are met:\n",
        "\n",
        "1. Redistributions of source code must retain the above copyright notice, this\n",
        "   list of conditions and the following disclaimer.\n",
        "\n",
        "2. Redistributions in binary form must reproduce the above copyright notice,\n",
        "   this list of conditions and the following disclaimer in the documentation\n",
        "   and/or other materials provided with the distribution.\n",
        "\n",
        "3. Neither the name of the copyright holder nor the names of its contributors\n",
        "   may be used to endorse or promote products derived from this software\n",
        "   without specific prior written permission.\n",
        "\n",
        "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
        "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
        "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
        "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
        "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
        "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
        "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
        "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
        "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
        "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44IoOcCX6Yny"
      },
      "source": [
        "# ML-based Phenotyping Manuscript Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBD2x13TJY-7"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import csv\n",
        "import functools\n",
        "import os\n",
        "import random\n",
        "from matplotlib import lines\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import matplotlib_venn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as ss\n",
        "import seaborn as sns\n",
        "from sklearn import metrics as sklearn_metrics\n",
        "from sklearn import utils as sklearn_utils\n",
        "import statsmodels.api as sm\n",
        "from typing import Dict, List, Optional, Tuple, Text\n",
        "\n",
        "# Modules defined within this repository.\n",
        "import perf_metrics\n",
        "import pheno_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE-p7Bwm1sIo"
      },
      "outputs": [],
      "source": [
        "AX = plt.axes\n",
        "FIG = mpl.figure.Figure\n",
        "\n",
        "mpl.rcParams['figure.dpi'] = 300\n",
        "mpl.rcParams['ps.fonttype'] = 42\n",
        "mpl.rcParams['pdf.fonttype'] = 42\n",
        "\n",
        "mpl.rcParams['savefig.transparent'] = True\n",
        "mpl.rcParams['savefig.bbox'] = 'tight'\n",
        "mpl.rcParams['savefig.dpi'] = 300\n",
        "\n",
        "pd.set_option('mode.chained_assignment', 'raise')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJy7rWdLQQIy"
      },
      "source": [
        "##Global and Constant variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbDgc9hUQPaf"
      },
      "outputs": [],
      "source": [
        "_ABLATION_FR = 10\n",
        "_SIG_CUTOFF = 5e-8\n",
        "_MANHATTAN_CUTOFF = 0.001\n",
        "_RANDOM_SEED = 42\n",
        "\n",
        "# Colors from the PRS plots \"vcdr_prs_manuscript_results.ipynb\"\n",
        "ML_COLOR = '#4285f4'\n",
        "CRAIG_COLOR = '#fbbc05'\n",
        "\n",
        "# ML-based VCDR GWAS information\n",
        "_VCDR_GWAS = '/path/to/file'\n",
        "_VCDR_HITS = '/path/to/file'\n",
        "_VCDR_LOCI = '/path/to/file'\n",
        "\n",
        "# hits from Craig et al.\n",
        "_CRAIG_HITS = '/path/to/file'\n",
        "# Overlap between VCDR (meta) and Craig et al. (meta) GWAS - 62 loci\n",
        "_VCDR_CRAIG_OVERLAP = '/path/to/file'\n",
        "# VCDR PRS predictions\n",
        "_VCDR_PRS_PREDS = '/path/to/file'\n",
        "\n",
        "\n",
        "# expert labels with one row per image\n",
        "# columsn are \n",
        "#  'GLAUCOMA_GRADABILITY'\n",
        "#  'VERTICAL_CUP_TO_DISC' \n",
        "#  'VCDR_GRADERS' (how many experts have graded the image) \n",
        "#  'VCDR_CONFIDENCE' (a QC metric between 0 and 1)\n",
        "TRAIN_TRUTH = '/path/to/file'\n",
        "TUNE_TRUTH = '/path/to/file'\n",
        "TEST_TRUTH = '/path/to/file'\n",
        "UKB_TRUTH = '/path/to/file'\n",
        "\n",
        "# model predictions with one row per image\n",
        "# column names are the same as described in the \"phenotype_calling\" notebook\n",
        "TRAIN_PRED = '/path/to/file'\n",
        "TUNE_PRED = '/path/to/file'\n",
        "TEST_PRED = '/path/to/file'\n",
        "UKB_PRED = '/path/to/file'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6Ovx69rAjtg"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHvrqMX_RlJL"
      },
      "outputs": [],
      "source": [
        "def pearson_corr(targets, predictions):\n",
        "  \"\"\"Returns Pearson correlation between \u003ctargets\u003e and \u003cpredictions\u003e.\"\"\"\n",
        "  return ss.pearsonr(targets, predictions)[0]\n",
        "\n",
        "\n",
        "def spearman_corr(targets, predictions):\n",
        "  \"\"\"Returns Pearman correlation between \u003ctargets\u003e and \u003cpredictions\u003e.\"\"\"\n",
        "  return ss.spearmanr(targets, predictions)[0]\n",
        "\n",
        "\n",
        "_METRICS = [\n",
        "    perf_metrics.Metric(\n",
        "        'num', lambda y_true, y_pred: len(y_true), binary_only=False),\n",
        "    perf_metrics.Metric('Pearson corr', pearson_corr, binary_only=False),\n",
        "    perf_metrics.Metric('Spearman corr', spearman_corr, binary_only=False)\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwmY4T9dfPGY"
      },
      "source": [
        "##Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKlz1ahdfPct"
      },
      "outputs": [],
      "source": [
        "def get_snp_id(row):\n",
        "  \"\"\"Returns RS ID if exists, else returns chr:bp_ref_alt.\"\"\"\n",
        "  if row['RS'] != '.':\n",
        "    return row['RS']\n",
        "  else:\n",
        "    return f'{row[\"CHR\"]}:{row[\"BP\"]}_{row[\"REF\"]}_{row[\"ALT\"]}'\n",
        "\n",
        "\n",
        "_GENE_CONTEXT = 'GENE_CONTEXT'\n",
        "_CHROMOSOME_SIZE_UPPERBOUND = 10**10\n",
        "_GENE_DISTANCE_ANNOTATION_LIMITS = [10**3, 10**4, 10**5, 10**6]\n",
        "\n",
        "Gene = collections.namedtuple('Gene', ['start', 'end', 'name'])\n",
        "\n",
        "\n",
        "def _build_genes(gencode_filepath):\n",
        "  \"\"\"Creates the genes from an input file.\n",
        "\n",
        "  Args:\n",
        "    gencode_filepath: The path of file containing gene context information. The\n",
        "      file is a TSV file with six columns for chromosome, start, end, strand,\n",
        "      Ensembl gene ID, and HGNC gene name. Start and end are both 1-based\n",
        "      inclusive positions.\n",
        "\n",
        "  Returns:\n",
        "    genes: A mapping from a each chromosome to its genes. Each gene is a triple\n",
        "      consisting of start, end, and HGNC name of the gene.\n",
        "  \"\"\"\n",
        "  genes = collections.defaultdict(list)\n",
        "  with open(gencode_filepath) as f:\n",
        "    gene_rows = list(csv.reader(f, delimiter='\\t'))\n",
        "  for chrom, start, end, _, _, hgnc in gene_rows[1:]:  # Skip the header row.\n",
        "    start, end = int(start), int(end)\n",
        "    if start \u003e= end:\n",
        "      raise ValueError(\n",
        "          'start \u003e= end for gene {} in chromosome {}: {:d} \u003e= {:d}'.format(\n",
        "              hgnc, chrom, start, end))\n",
        "    genes[chrom].append(Gene(start=start, end=end, name=hgnc))\n",
        "  return genes\n",
        "\n",
        "\n",
        "def _annotate_distance(distance):\n",
        "  \"\"\"Returns the distance annotation to neighbor genes.\"\"\"\n",
        "  for i, limit in enumerate(_GENE_DISTANCE_ANNOTATION_LIMITS):\n",
        "    if distance \u003c= limit:\n",
        "      return '-' * i\n",
        "  return None\n",
        "\n",
        "\n",
        "class GeneContext(object):\n",
        "  \"\"\"Class representing gene contexts.\"\"\"\n",
        "\n",
        "  def __init__(self, gencode_filepath: str) -\u003e None:\n",
        "    self._genes = _build_genes(gencode_filepath)\n",
        "\n",
        "  def get_context(self, chrom, base_pair_position):\n",
        "    \"\"\"Gets the gene context of a variant.\n",
        "\n",
        "    Args:\n",
        "      chrom: The chromosome of variant.\n",
        "      base_pair_position: The 1-based base-pair position of variant.\n",
        "\n",
        "    Returns:\n",
        "      gene_context: The gene context of variant where distance is annotated\n",
        "        with some dashes.\n",
        "    \"\"\"\n",
        "    # Check whether the variant falls into any genes.\n",
        "    variant_genes = [\n",
        "        gene.name\n",
        "        for gene in self._genes[chrom]\n",
        "        if gene.start \u003c= base_pair_position \u003c= gene.end\n",
        "    ]\n",
        "    if variant_genes:\n",
        "      return '[{}]'.format(','.join(variant_genes))\n",
        "\n",
        "    gene_before = Gene(start=None, end=0, name=None)\n",
        "    gene_after = Gene(start=_CHROMOSOME_SIZE_UPPERBOUND, end=None, name=None)\n",
        "    for gene in self._genes[chrom]:\n",
        "      if gene_before.end \u003c gene.end \u003c base_pair_position:\n",
        "        gene_before = gene\n",
        "      if base_pair_position \u003c gene.start \u003c gene_after.start:\n",
        "        gene_after = gene\n",
        "\n",
        "    before, after = '', ''\n",
        "    if gene_before.name:\n",
        "      # When there is a gene before.\n",
        "      left_distance_annotation = _annotate_distance(base_pair_position -\n",
        "                                                    gene_before.end)\n",
        "      if left_distance_annotation is not None:\n",
        "        before = gene_before.name + left_distance_annotation\n",
        "    if gene_after.name:\n",
        "      # When there is a gene after.\n",
        "      right_distance_annotation = _annotate_distance(gene_after.start -\n",
        "                                                     base_pair_position)\n",
        "      if right_distance_annotation is not None:\n",
        "        after = right_distance_annotation + gene_after.name\n",
        "    return '{}[]{}'.format(before, after)\n",
        "\n",
        "\n",
        "def _add_gene_contexts(clusters, gencode_filepath):\n",
        "  \"\"\"Adds the gene context to each cluster.\n",
        "\n",
        "  Args:\n",
        "    clusters: A list of variants where each variant is a cluster representative,\n",
        "      i.e. the most significant variant in the cluster.\n",
        "   gencode_filepath: The path of file containing gene context information. The\n",
        "     file is a TSV file with six columns for chromosome, start, end, strand,\n",
        "     Ensembl gene ID, and HGNC gene name. Start and end are both 1-based\n",
        "     inclusive positions.\n",
        "  \"\"\"\n",
        "  logging.info('Annotating the clusters with gene context...')\n",
        "  gene_context = GeneContext(gencode_filepath)\n",
        "  for cluster in clusters:\n",
        "    cluster[_GENE_CONTEXT] = gene_context.get_context('CHR', 'BP')\n",
        "\n",
        "\n",
        "def _add_gene_labels(df_hits):\n",
        "  \"\"\"Adds gene context and label to hits.\"\"\"\n",
        "  chroms = df_hits['CHR'].to_list()\n",
        "  positions = df_hits['BP'].to_list()\n",
        "\n",
        "  variants = [{\n",
        "      'CHR': str(chrom),\n",
        "      'BP': position\n",
        "  } for chrom, position in zip(chroms, positions)]\n",
        "\n",
        "  with open(_GENCODE_FILE) as f:\n",
        "    _add_gene_contexts(variants, gencode_filepath=f)\n",
        "\n",
        "  df_hits['GENE_CONTEXT'] = [variant['GENE_CONTEXT'] for variant in variants]\n",
        "  return df_hits\n",
        "\n",
        "\n",
        "def _get_preds_filename(dataset):\n",
        "  \"\"\"Returns the path to the prediction file.\"\"\"\n",
        "    if dataset == 'tune':\n",
        "      return TUNE_PRED\n",
        "    elif dataset == 'test':\n",
        "      return TEST_PRED\n",
        "    elif dataset == 'train':\n",
        "      return TRAIN_PRED\n",
        "    elif dataset == 'ukb':\n",
        "      return UKB_PRED\n",
        "    else:\n",
        "      raise ValueError('Invalid dataset: {}'.format(dataset))\n",
        "\n",
        "\n",
        "def _eid_from_image_path(path):\n",
        "  \"\"\"Returns \u003ceid\u003e from \u003cimage_path\u003e.\"\"\"\n",
        "  return int(os.path.basename(path).split('_')[0])\n",
        "\n",
        "\n",
        "def load_predictions(dataset):\n",
        "  \"\"\"Return predictions for \u003cdataset\u003e.\"\"\"\n",
        "  filename = _get_preds_filename(dataset)\n",
        "  raw_df = pheno_utils.load_csv(filename)\n",
        "  converted_df = pheno_utils.convert_categorical_to_binary(\n",
        "      raw_df, 'vertical_cd_visibility',\n",
        "      'vertical_cd_visibility:UNABLE_TO_ASSESS', [\n",
        "          'vertical_cd_visibility:SUFFICIENT',\n",
        "          'vertical_cd_visibility:COMPROMISED',\n",
        "          'vertical_cd_visibility:UNABLE_TO_ASSESS',\n",
        "      ])\n",
        "\n",
        "  col_map = {\n",
        "      'image_id': 'image_id',\n",
        "      'vertical_cd_visibility': 'gradability_prediction',\n",
        "      'vertical_cup_to_disc:VERTICAL_CUP_TO_DISC': 'vcdr_prediction',\n",
        "  }\n",
        "\n",
        "  # Keep only image_id, vertical_cd_visibility, and vcdr_prediction.\n",
        "  retval = converted_df[col_map.keys()].rename(columns=col_map)\n",
        "\n",
        "  if len(retval) != len(set(retval.image_id)):\n",
        "    raise ValueError('Duplicate image in prediction set {} {}'.format(\n",
        "        downsample_fraction, dataset))\n",
        "\n",
        "  if retval.vcdr_prediction.isna().any():\n",
        "    raise ValueError('Unexpected NA present in predictions.')\n",
        "\n",
        "  return retval\n",
        "\n",
        "\n",
        "def load_labels(dataset):\n",
        "  \"\"\"Load VCDR labels.\"\"\"\n",
        "  if dataset == 'train':\n",
        "    filename = TRAIN_TRUTH\n",
        "  elif dataset == 'eval':\n",
        "    filename = TUNE_TRUTH\n",
        "  elif dataset == 'test':\n",
        "    filename = TEST_TRUTH\n",
        "  elif dataset == 'ukb':\n",
        "    filename = UKB_TRUTH\n",
        "  else:\n",
        "    raise ValueError('Invalid dataset: {}'.format(dataset))\n",
        "\n",
        "  raw_df = pheno_utils.load_csv(filename)\n",
        "  col_map = {\n",
        "      'Unnamed: 0': 'image_id',\n",
        "      'GLAUCOMA_GRADABILITY': 'gradability_label',\n",
        "      'VERTICAL_CUP_TO_DISC': 'vcdr_label',\n",
        "      'VCDR_GRADERS': 'num_graders',\n",
        "  }\n",
        "\n",
        "  if dataset == 'ukb':\n",
        "    # Restrict to records with confidence == 1.\n",
        "    raw_df = raw_df.loc[raw_df['VCDR_CONFIDENCE'] \u003e 0.75]\n",
        "  retval = raw_df[col_map.keys()].rename(columns=col_map)\n",
        "\n",
        "  if len(retval) != len(set(retval.image_id)):\n",
        "    raise ValueError('Duplicate image in truth set {}'.format(dataset))\n",
        "\n",
        "  return retval[~retval.vcdr_label.isna()]\n",
        "\n",
        "\n",
        "def prediction_vs_label_scatterplot(dataset):\n",
        "  \"\"\"Generates the scatter plot of predicted vs labeled VCDR for \u003cdataset\u003e.\"\"\"\n",
        "  labels = load_labels(dataset)\n",
        "  predictions = load_predictions(dataset=dataset)\n",
        "\n",
        "  joined = predictions.set_index('image_id').join(\n",
        "      labels.set_index('image_id'), how='inner')\n",
        "\n",
        "  print('graders for {} - mean: {:.2f} - median: {:.2f}'.format(\n",
        "      dataset, joined['num_graders'].mean(), joined['num_graders'].median()))\n",
        "\n",
        "  jax = sns.jointplot(\n",
        "      data=joined,\n",
        "      x='vcdr_label',\n",
        "      y='vcdr_prediction',\n",
        "      kind='reg',\n",
        "      space=0,\n",
        "      xlim=[0.0, 1],\n",
        "      ylim=[0.0, 1],\n",
        "      height=2,\n",
        "      annot_kws=dict(stat='r'),\n",
        "      marginal_kws=dict(hist=False, kde_kws=dict(lw=0.75)),\n",
        "      scatter_kws=dict(\n",
        "          s=3, alpha=0.5, color='g', edgecolor='none', rasterized=True),\n",
        "      joint_kws=dict(line_kws=dict(linewidth=0.75)))\n",
        "\n",
        "  jax.ax_joint.set_xlabel('')\n",
        "  jax.ax_joint.set_ylabel('')\n",
        "\n",
        "  jax.ax_joint.set_xticks([0, 0.5, 1])\n",
        "  jax.ax_joint.set_yticks([0, 0.5, 1])\n",
        "  jax.ax_joint.set_xticklabels([0, 0.5, 1], fontsize=5)\n",
        "  jax.ax_joint.set_yticklabels([0, 0.5, 1], fontsize=5)\n",
        "\n",
        "  return jax  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5T6QFneo76L"
      },
      "source": [
        "# VCDR Predictions Scatter plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMu3mcacpD12"
      },
      "outputs": [],
      "source": [
        "for dataset in ['train', 'tune', 'test', 'ukb']:\n",
        "  jax = prediction_vs_label_scatterplot(dataset)\n",
        "  jax.savefig(f'{dataset}.pdf', transparent=True, bbox_inches='tight', dpi=1200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq7Ah_72OoaW"
      },
      "source": [
        "# VCDR Bins vs Odds Ratio Boxplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SvHJ6dMeZjw"
      },
      "outputs": [],
      "source": [
        "def get_phenos_plot(phenos: pd.DataFrame,\n",
        "                    x: Text,\n",
        "                    y: Text,\n",
        "                    new_x: Text = '',\n",
        "                    new_y: Text = '') -\u003e pd.DataFrame:\n",
        "  \"\"\"Given the all phenotypes returns the phenotypes needed for plotting.\"\"\"\n",
        "  phenos_plot = phenos[[x, y]].dropna()\n",
        "  if new_x and new_y:\n",
        "    phenos_plot = phenos_plot.rename(columns={x: new_x, y: new_y})\n",
        "  return phenos_plot\n",
        "\n",
        "\n",
        "def _get_odds_ratio(counts_ref, counts):\n",
        "    \"\"\"Returns the sample odds ratio.\"\"\"\n",
        "    return (counts_ref[0] * counts[1]) / (counts_ref[1] * counts[0])\n",
        "\n",
        "\n",
        "def get_bin_odds_ratios(phenos_plot: pd.DataFrame,\n",
        "                        x_col: Text,\n",
        "                        y_col: Text,\n",
        "                        num_bootstrap_samples: int,\n",
        "                        x_bins: np.ndarray,\n",
        "                        seed: int,\n",
        "                        fast_or=False) -\u003e np.ndarray:\n",
        "  \"\"\"Returns the bootstrap ORs of \u003cx\u003e bins defined by \u003cxbins\u003e.\n",
        "\n",
        "  The reference odds are computed for the entire set.\n",
        "  \"\"\"\n",
        "\n",
        "  def _count_vals(array, ref_vals=[1, 2]):\n",
        "    \"\"\"Returns the counts of controls (\"1\") and cases (\"2\").\"\"\"\n",
        "    return [(array == val).sum() for val in ref_vals]\n",
        "\n",
        "  def _get_bin_counts(x, y, x_bins, rand_idx=None):\n",
        "    \"\"\"Retruns counts of controls and cases in bins defined by \u003cx_bins\u003e.\"\"\"\n",
        "    if rand_idx is not None:\n",
        "      x = x[rand_idx]\n",
        "      y = y[rand_idx]\n",
        "    n_bins = len(x_bins) - 1\n",
        "    bin_idx = np.digitize(x, x_bins)\n",
        "    bin_counts = [_count_vals(y[bin_idx == j + 1]) for j in range(n_bins)]\n",
        "    return bin_counts\n",
        "\n",
        "  prng = np.random.RandomState(seed)\n",
        "  num = phenos_plot.shape[0]\n",
        "\n",
        "  x = phenos_plot[x_col].to_numpy(copy=True)\n",
        "  y = phenos_plot[y_col].to_numpy(copy=True)\n",
        "\n",
        "  perf_metrics.PerformanceMetrics(\n",
        "      name='glaucoma prediction', default_metrics='binary').compute_and_print(\n",
        "          y - 1, x, n_bootstrap=2000)\n",
        "\n",
        "  x_bins = [-np.inf] + list(x_bins) + [np.inf]\n",
        "  num_bins = len(x_bins) - 1\n",
        "\n",
        "  # bin counts for the original (non-bootstrapped samples)\n",
        "  ref_bin_counts = _get_bin_counts(x, y, x_bins)\n",
        "\n",
        "  bs_stats = np.empty((num_bootstrap_samples, num_bins))\n",
        "  for i in range(num_bootstrap_samples):\n",
        "    if (i + 1) % 100 == 0:\n",
        "      print('Processed %d bootstrap samples...' % (i + 1))\n",
        "    rand_idx = prng.randint(0, high=num, size=num)\n",
        "    bin_counts = _get_bin_counts(x, y, x_bins, rand_idx=rand_idx)\n",
        "    # ORs are defined w.r.t the first bin.\n",
        "    for j in range(num_bins):\n",
        "      if fast_or:\n",
        "        bs_stats[i, j] = _get_odds_ratio(bin_counts[0], bin_counts[j])\n",
        "      else:\n",
        "        bs_stats[i, j] = ss.fisher_exact([bin_counts[0], bin_counts[j]])[0]\n",
        "\n",
        "  return bs_stats, ref_bin_counts\n",
        "\n",
        "\n",
        "def plot_vcdr_bins_odds_ratios_boxplot(phenos_file: Text,\n",
        "                                       num_bootstrap_samples: int, seed: int,\n",
        "                                       fast_or) -\u003e Tuple[FIG, AX]:\n",
        "  x_bins = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
        "\n",
        "  phenos = pheno_utils.load_csv(phenos_file, sep='\\t', index_col=None)\n",
        "  phenos.replace(-9, np.nan, inplace=True)\n",
        "  phenos.dropna(\n",
        "      axis='rows',\n",
        "      how='any',\n",
        "      subset=['visit', 'visit_age', 'refractive_error'],\n",
        "      inplace=True)\n",
        "\n",
        "  df = get_phenos_plot(\n",
        "      phenos,\n",
        "      x='vcdr_visit',\n",
        "      y='has_touchscreen_plus_icd_poag',\n",
        "      new_x='vcdr',\n",
        "      new_y='glaucoma')\n",
        "\n",
        "  odds_ratios, ref_bin_counts = get_bin_odds_ratios(\n",
        "      df,\n",
        "      x_col='vcdr',\n",
        "      y_col='glaucoma',\n",
        "      num_bootstrap_samples=num_bootstrap_samples,\n",
        "      x_bins=x_bins,\n",
        "      seed=seed,\n",
        "      fast_or=fast_or)\n",
        "\n",
        "  num = np.asarray([sum(b) for b in ref_bin_counts])\n",
        "  print('bin counts: ', num)\n",
        "  print('bin fractions: ', 100 * num /(num.sum()))\n",
        "\n",
        "  plot_data = [odds_ratios[:, i] for i in range(odds_ratios.shape[1])]\n",
        "\n",
        "  print('OR: ', _get_odds_ratio(ref_bin_counts[0], ref_bin_counts[-1]))\n",
        "  print('95% CI: ', np.percentile(plot_data[-1], [2.5, 97.5]))\n",
        "\n",
        "  labels = [f'\u003c {x_bins[0]}'] + [\n",
        "      '{}-{}'.format(*x_bins[i:i + 2]) for i in range(len(x_bins) - 1)\n",
        "  ] + [f'\u003e {x_bins[-1]}']\n",
        "  fig, ax = plt.subplots(figsize=(6, 4))\n",
        "  ax.boxplot(plot_data, showfliers=False, labels=labels, whis=[5, 95])\n",
        "  ax.axhline(y=1, ls='--', c='k', lw=0.5)\n",
        "  ax.set_ylim([0, 100])\n",
        "\n",
        "  ax.set_yticks([0, 20, 40, 60, 80, 100])\n",
        "\n",
        "  return fig, ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5NelMBZbQTs"
      },
      "outputs": [],
      "source": [
        "fig, ax = plot_vcdr_bins_odds_ratios_boxplot(\n",
        "    phenos_filepath,\n",
        "    num_bootstrap_samples=1000,\n",
        "    seed=_RANDOM_SEED,\n",
        "    fast_or=True)\n",
        "\n",
        "fig.savefig(\n",
        "    'vcdr_glaucoma_oddsratios_boxplots.pdf',\n",
        "    transparent=True,\n",
        "    bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAJGNTLyLbci"
      },
      "source": [
        "# VCDR-PRS Bins vs Odds Ratio Boxplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BW4l1y1Lac5"
      },
      "outputs": [],
      "source": [
        "def _get_prs_bins(preds, df_phenos, vcdr_bins):\n",
        "  \"\"\"Computes PRS bins using predicted VCDRs and vcdr_bins.\"\"\"\n",
        "  prs = preds.copy(deep=True)\n",
        "  pheno = df_phenos.copy(deep=True)\n",
        "  df = pd.merge(prs, pheno, left_index=True, right_index=True, how='inner')\n",
        "\n",
        "  # drop samples that do not have fundus predictions or have\n",
        "  # missing covariates\n",
        "  df.dropna(\n",
        "      axis='rows',\n",
        "      how='any',\n",
        "      subset=['visit', 'refractive_error', 'vcdr_visit', 'visit_age'],\n",
        "      inplace=True)\n",
        "\n",
        "  mlb_vcdr = df['vcdr_visit'].to_numpy(copy=True)\n",
        "  prs_vcdr = df['prs'].to_numpy(copy=True)\n",
        "\n",
        "  prs_avg = np.mean(prs_vcdr)\n",
        "  prs_std = np.std(prs_vcdr)\n",
        "\n",
        "  # convert PRS to Z-scores\n",
        "  prs_z = (prs_vcdr - prs_avg) / prs_std\n",
        "\n",
        "  # need to pad vcdr_bins from left\n",
        "  vcdr_bins = [-np.inf] + list(vcdr_bins)\n",
        "  n_bins = len(vcdr_bins) - 1\n",
        "  bin_idx = np.digitize(mlb_vcdr, vcdr_bins)\n",
        "  # compute counts in each bin\n",
        "  bin_counts = [mlb_vcdr[bin_idx == j + 1].shape[0] for j in range(n_bins)]\n",
        "  # convert counts to percentiles\n",
        "  bin_pcs = 100 * np.cumsum(bin_counts) / mlb_vcdr.shape[0]\n",
        "  # get the same PRS percentiles\n",
        "  prs_bins = np.percentile(prs_z, bin_percs)\n",
        "  return prs_bins, prs_avg, prs_std, df.index\n",
        "\n",
        "\n",
        "def plot_vcdr_prs_bins_odds_ratios_boxplot(phenos_file: Text,\n",
        "                                           num_bootstrap_samples: int,\n",
        "                                           seed: int,\n",
        "                                           fast_or) -\u003e Tuple[FIG, AX]:\n",
        "  # load the glaucoma phenotypes\n",
        "  df_phenos = pheno_utils.load_csv(\n",
        "      phenos_file,\n",
        "      sep='\\t',\n",
        "      index_col=None,\n",
        "      usecols=[\n",
        "          'IID',\n",
        "          'visit',\n",
        "          'visit_age',\n",
        "          'vcdr_visit',\n",
        "          'refractive_error',\n",
        "          'has_touchscreen_plus_icd_poag',\n",
        "          'has_touchscreen_plus_icd_poag_nofundus',\n",
        "      ])\n",
        "\n",
        "  df_phenos.rename(\n",
        "      columns={\n",
        "          'has_touchscreen_plus_icd_poag': 'glaucoma',\n",
        "          'has_touchscreen_plus_icd_poag_nofundus': 'glaucoma_nofundus'\n",
        "      },\n",
        "      inplace=True)\n",
        "\n",
        "  df_phenos.replace(-9, np.nan, inplace=True)\n",
        "  df_phenos = df_phenos.set_index('IID')\n",
        "\n",
        "  # load PRS predictions.\n",
        "  preds = pheno_utils.load_csv(\n",
        "      _VCDR_PRS_PREDS,\n",
        "      index_col=None,\n",
        "      delim_whitespace=True,\n",
        "      usecols=['IID', 'SCORE'])\n",
        "\n",
        "  preds.rename(columns={'SCORE': 'prs'}, inplace=True)\n",
        "  preds = preds.set_index('IID')\n",
        "\n",
        "  # get the PRS bins using samples with fundus image.\n",
        "  vcdr_bins = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
        "  prs_bins, prs_avg, prs_std, idx_fundus = _get_prs_bins(\n",
        "      preds, df_phenos, vcdr_bins)\n",
        "\n",
        "  df_plot = pd.merge(\n",
        "      df_phenos, preds, left_index=True, right_index=True, how='inner')\n",
        "\n",
        "  idx_nofundus = df_phenos.loc[df_phenos['vcdr_visit'].isna()].index\n",
        "\n",
        "  freq_glaucoma_fundus = (df_phenos.loc[idx_fundus, 'glaucoma'] == 2).mean()\n",
        "  freq_glaucoma_nofundus = (df_phenos.loc[idx_nofundus, 'glaucoma'] == 2).mean()\n",
        "\n",
        "  print(\n",
        "      'freq of glaucoma in inds. w/ fundus: {:.2f} - w/o fundus: {:.2f}'.format(\n",
        "          100 * freq_glaucoma_fundus, 100 * freq_glaucoma_nofundus))\n",
        "\n",
        "  df_plot = df_plot.loc[df_plot['vcdr_visit'].isna(), ['glaucoma', 'prs']]\n",
        "  df_plot.dropna(inplace=True)\n",
        "\n",
        "  # convert PRS predictions to Z-scores\n",
        "  df_plot['prs'] = df_plot['prs'].apply(lambda x: (x - prs_avg) / prs_std)\n",
        "\n",
        "  print(f'{df_plot.shape[0]} inds. with PRS + glaucoma stats')\n",
        "\n",
        "  odds_ratios, ref_bin_counts = get_bin_odds_ratios(\n",
        "      df_plot,\n",
        "      x_col='prs',\n",
        "      y_col='glaucoma',\n",
        "      num_bootstrap_samples=num_bootstrap_samples,\n",
        "      x_bins=prs_bins,\n",
        "      seed=seed,\n",
        "      fast_or=fast_or)\n",
        "\n",
        "  plot_data = [odds_ratios[:, i] for i in range(odds_ratios.shape[1])]\n",
        "\n",
        "  num = np.asarray([sum(b) for b in ref_bin_counts])\n",
        "  print('bin counts: ', num)\n",
        "  print('bin fractions: ', 100 * num / (num.sum()))\n",
        "\n",
        "  print('OR and 95% CI of the top bucket:')\n",
        "  print('mean: {:.3f} - ({:.3f}-{:.3f})'.format(\n",
        "      _get_odds_ratio(ref_bin_counts[0], ref_bin_counts[-1]),\n",
        "      * np.percentile(plot_data[-1], [2.5, 97.5])))\n",
        "\n",
        "  labels = ['\u003c {:.1f}'.format(prs_bins[0])] + [\n",
        "      '{:.1f}-{:.1f}'.format(*prs_bins[i:i + 2])\n",
        "      for i in range(len(prs_bins) - 1)\n",
        "  ] + ['\u003e {:.1f}'.format(prs_bins[-1])]\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(6, 4))\n",
        "  ax.boxplot(plot_data, showfliers=False, labels=labels, whis=[5, 95])\n",
        "\n",
        "  ax.axhline(y=1, ls='--', c='k', lw=0.5)\n",
        "\n",
        "  ax.set_ylim([0.0, 5])\n",
        "  ax.set_yticks([0, 1, 2, 3, 4, 5])\n",
        "\n",
        "  return fig, ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ySK4JukoryU"
      },
      "outputs": [],
      "source": [
        "fig, ax = plot_vcdr_prs_bins_odds_ratios_boxplot(\n",
        "    phenos_file=phenos_filepath,\n",
        "    num_bootstrap_samples=1000,\n",
        "    seed=_RANDOM_SEED,\n",
        "    fast_or=True)\n",
        "\n",
        "fig.savefig(\n",
        "    'vcdr_prs_glaucoma_oddsratios_boxplots.pdf',\n",
        "    transparent=True,\n",
        "    bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gcROWpoTtje"
      },
      "source": [
        "# VCDR vs Glaucoma Referral Risk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjHeo4O-eABM"
      },
      "outputs": [],
      "source": [
        "def plot_vcdr_p4_scatter(phenos_file, seed):\n",
        "  \"\"\"Plots vcdr vs glaucoma liability 2D histogram.\"\"\"\n",
        "  n_bins = 50\n",
        "  marker_size = 7.5\n",
        "  vcdr = 'vcdr_visit'\n",
        "  p4 = 'glaucoma_p4_max_logit'\n",
        "\n",
        "  phenos = pheno_utils.load_csv(phenos_file, sep='\\t', index_col=None)\n",
        "  phenos.replace(-9, np.nan, inplace=True)\n",
        "  phenos.dropna(\n",
        "      axis='rows',\n",
        "      how='any',\n",
        "      subset=['visit', 'visit_age', 'refractive_error'],\n",
        "      inplace=True)\n",
        "  \n",
        "  phenos_plot = phenos[[vcdr, p4]].dropna()\n",
        "\n",
        "  perf_metrics.PerformanceMetrics(\n",
        "      name='VCDR vs P4', metrics=_METRICS).compute_and_print(\n",
        "          phenos_plot['vcdr_visit'].to_numpy(copy=True),\n",
        "          phenos_plot['glaucoma_p4_max_logit'].to_numpy(copy=True),\n",
        "          n_bootstrap=2000,\n",
        "          seed=seed)\n",
        "\n",
        "  jax = sns.jointplot(\n",
        "      data=phenos_plot,\n",
        "      x='vcdr_visit',\n",
        "      y='glaucoma_p4_max_logit',\n",
        "      kind='reg',\n",
        "      xlim=[0.0, 1],\n",
        "      ylim=[-12, 4],\n",
        "      height=3,\n",
        "      annot_kws=dict(stat='r'),\n",
        "      scatter_kws=dict(s=2.5, alpha=0.1, color='g'))\n",
        "\n",
        "  jax.ax_joint.cla()\n",
        "\n",
        "  h, x_edges, y_edges = np.histogram2d(\n",
        "      phenos_plot['vcdr_visit'],\n",
        "      phenos_plot['glaucoma_p4_max_logit'],\n",
        "      bins=n_bins)\n",
        "\n",
        "  x_centers = (x_edges[:-1] + x_edges[1:]) / 2\n",
        "  y_centers = (y_edges[:-1] + y_edges[1:]) / 2\n",
        "\n",
        "  x_mesh, y_mesh = np.meshgrid(x_centers, y_centers)\n",
        "\n",
        "  x = x_mesh.ravel()\n",
        "  y = y_mesh.ravel()\n",
        "  h = h.T.ravel()\n",
        "\n",
        "  jax.ax_joint.scatter(\n",
        "      x, y, edgecolors='none', s=marker_size, c=h, norm=mpl.colors.LogNorm())\n",
        "\n",
        "  jax.ax_joint.set_xlabel('')\n",
        "  jax.ax_joint.set_ylabel('')\n",
        "\n",
        "  jax.ax_joint.set_xticks([0, 0.5, 1])\n",
        "  jax.ax_joint.set_yticks([-12, -8, -4, 0, 4])\n",
        "\n",
        "  return jax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwz0n-Dtc8Yf"
      },
      "outputs": [],
      "source": [
        "jax = plot_vcdr_p4_scatter(phenos_filepath, seed=_RANDOM_SEED)\n",
        "\n",
        "jax.savefig(\n",
        "    'vcdr_glaucoma_p4.pdf',\n",
        "    transparent=True,\n",
        "    bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSBBcdKiMpO3"
      },
      "source": [
        "#Manhattan Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycAP5ayTiIJN"
      },
      "outputs": [],
      "source": [
        "def get_chromosome_sizes(chrom_sizes_filepath):\n",
        "  \"\"\"Returns the chromosome sizes.\n",
        "\n",
        "  Args:\n",
        "    chrom_sizes_filepath: The filepath or open file handle of a TSV file with\n",
        "      two columns for chromosome names and chromosome sizes.\n",
        "\n",
        "  Returns:\n",
        "    A dictionary from chromosomes to their size in the number of base-pairs.\n",
        "  \"\"\"\n",
        "  with open(chrom_sizes_filepath) as f:\n",
        "    size_rows = list(csv.reader(f, delimiter='\\t'))\n",
        "  return {chrom: int(size) for chrom, size in size_rows}\n",
        "\n",
        "\n",
        "def get_chromosome_offsets(chromosome_sizes):\n",
        "  \"\"\"Calculates the chromosome offsets needed for a Manhattan plot.\n",
        "\n",
        "  Args:\n",
        "    chromosome_sizes: A dictionary from chromosome to their sizes in base pairs.\n",
        "\n",
        "  Returns:\n",
        "    chr_offsets: Maps a chromosome to the number of base-pairs in\n",
        "      chromosomes before it. This is the offset that must be added to base-pair\n",
        "      positions of this chromosome in a Manhattan plot. The last element of\n",
        "      ordered dictionary corresponds to the total size of chromosomes with `$`\n",
        "      as its key.\n",
        "  \"\"\"\n",
        "  chr_offsets = collections.OrderedDict()\n",
        "  offset = 0\n",
        "  for chrom in str(i) for i in range(1, 23):\n",
        "    chr_offsets[chrom] = offset\n",
        "    offset += chromosome_sizes[chrom]\n",
        "  chr_offsets['$'] = offset\n",
        "  return chr_offsets\n",
        "\n",
        "\n",
        "def plot_manhattan():\n",
        "  \"\"\"Plots the Manhattan plot for the VCDR GWAS.\"\"\"\n",
        "  prng = np.random.RandomState(_RANDOM_SEED)\n",
        "\n",
        "  # load chrom sizes and compute offsets\n",
        "  with open(_CHROMSIZES_PATH) as f:\n",
        "    chrom_sizes = get_chromosome_sizes(f)\n",
        "    chrom_offsets = get_chromosome_offsets(chrom_sizes)\n",
        "\n",
        "  # plot ticks and tick labels\n",
        "  offsets = np.asarray(list(chrom_offsets.values()))\n",
        "  xticks = (offsets[1:] + offsets[:-1]) / 2\n",
        "  xticklabs = chrom_offsets.keys()\n",
        "\n",
        "  df_gwas = pheno_utils.load_csv(_VCDR_GWAS, sep='\\t', index_col=None)\n",
        "  df_hits = pheno_utils.load_csv(_VCDR_HITS, sep='\\t', index_col=None)\n",
        "  df_loci = pheno_utils.load_csv(_VCDR_LOCI, sep='\\t', index_col=None)\n",
        "\n",
        "  df_hits['SNP'] = df_hits.apply(get_snp_id, axis='columns')\n",
        "  df_hits = df_hits.assign(LOGP=-np.log10(df_hits['P']))\n",
        "\n",
        "  df_hits = pd.merge(df_hits, df_loci, on='SNP', suffixes=('', '_LOCI'))\n",
        "\n",
        "  # snp ids of genmed loci\n",
        "  genmed_hits = set(df_hits['SNP'])\n",
        "\n",
        "  # intersection of genmed and craig et al.\n",
        "  df_intersection = pheno_utils.load_csv(_VCDR_CRAIG_OVERLAP, sep='\\t', index_col=None)\n",
        "\n",
        "  # snp ids of replicated hits\n",
        "  common_hits = set(df_intersection['A_SNP'])\n",
        "\n",
        "  # subset SNPs to those with a max p-value\n",
        "  df = df_gwas.loc[df_gwas['P'] \u003c= _MANHATTAN_CUTOFF]\n",
        "  df = df.assign(LOGP=-np.log10(df['P']))\n",
        "\n",
        "  # plot the does in PNG format (PDF will be too large)\n",
        "  colors = ['#c2a5cf', '#a6dba0']\n",
        "  hit_colors = ['#4575b4', '#d73027']\n",
        "\n",
        "  max_y = 135\n",
        "  min_y = -5\n",
        "  min_x = -1.5e8\n",
        "  max_x = 3.025e9\n",
        "\n",
        "  xs, ys, cs = [], [], []\n",
        "  xhs, yhs, chs = [], [], []\n",
        "\n",
        "  for row in df.itertuples():\n",
        "    x = chrom_offsets[str(row.CHR)] + row.BP\n",
        "    y = row.LOGP\n",
        "    if row.SNP in genmed_hits:\n",
        "      xhs.append(x)\n",
        "      yhs.append(y)\n",
        "      if row.SNP in common_hits:\n",
        "        chs.append(hit_colors[0])\n",
        "      else:\n",
        "        chs.append(hit_colors[1])\n",
        "    else:\n",
        "      xs.append(x)\n",
        "      ys.append(y)\n",
        "      cs.append(colors[row.CHR % len(colors)])\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(7, 3.5), dpi=600)\n",
        "  ax.scatter(xs, ys, c=cs, s=1, rasterized=True)\n",
        "  ax.scatter(xhs, yhs, c=chs, s=1.5)\n",
        "\n",
        "  ax.axhline(y=-np.log10(_SIG_CUTOFF), linestyle='--', color='r', linewidth=0.5)\n",
        "\n",
        "  ax.set_xlabel('Chromosomes', fontsize=6)\n",
        "  ax.set_ylabel(r'$-\\log_{10}(P)$', fontsize=6)\n",
        "\n",
        "  for row in df_hits.itertuples():\n",
        "    x_hit = chrom_offsets[str(row.CHR)] + row.BP\n",
        "    y_hit = row.LOGP\n",
        "    if row.SNP in common_hits:\n",
        "      c_text = '#08306b'\n",
        "    else:\n",
        "      c_text = 'k'\n",
        "\n",
        "  ax.set_xticks(xticks)\n",
        "  ax.set_xticklabels(xticklabs, fontsize=5)\n",
        "  ax.set_yticks([0, 30, 60, 90, 120])\n",
        "  ax.set_yticklabels([0, 30, 60, 90, 120], fontsize=5)\n",
        "\n",
        "  ax.set_ylim([min_y, max_y])\n",
        "  ax.set_xlim([min_x, max_x])\n",
        "\n",
        "  return fig, df_hits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcHdEJXwijdT"
      },
      "outputs": [],
      "source": [
        "fig = plot_manhattan()\n",
        "\n",
        "fig.savefig('manhattan.pdf', transparent=True, bbox_inches='tight', dpi=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxMqecxyxNjr"
      },
      "source": [
        "# Craig *et al.* hits effect sizes in ML-Based GWAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0Uj1rflXvQy"
      },
      "outputs": [],
      "source": [
        "def plot_craig_genmed_effect_sizes():\n",
        "  \"\"\"Plots the effect sizes of Craig and Genmed SNP using Craig hits as ref.\"\"\"\n",
        "  df_gwas = pheno_utils.load_csv(_VCDR_GWAS, sep='\\t', index_col=None)\n",
        "  df_craig = pheno_utils.load_csv(_CRAIG_HITS, index_col=None)\n",
        "  df_merged = pd.merge(df_craig, df_gwas, how='inner', on='SNP')\n",
        "\n",
        "  if df_merged.loc[df_merged['EA'] != df_merged['EFF']].shape[0] \u003e 0:\n",
        "    raise ValueError('Alleles between GenMed and Craig hits are different.')\n",
        "\n",
        "  colors = ['#2166ac', '#b2182b']\n",
        "  xs, ex, ys, ey, cs = [], [], [], [], []\n",
        "  px, py = [], []\n",
        "\n",
        "  x_gene, y_gene, gene_name = [], [], []\n",
        "  for row in df_merged.itertuples():\n",
        "    # x: suffix for Craig et al\n",
        "    # y: suffix for ML-based\n",
        "    xs.append(row.BETA_x)\n",
        "    ys.append(_VCDR_STD * row.BETA_y)\n",
        "\n",
        "    ex.append(row.SE_x)\n",
        "    ey.append(_VCDR_STD * row.SE_y)\n",
        "\n",
        "    px.append(-np.log10(row.P_x))\n",
        "    py.append(-np.log10(row.P_y))\n",
        "\n",
        "    # color based on P-value\n",
        "    if row.P_x \u003e= row.P_y:\n",
        "      cs.append(colors[0])\n",
        "    else:\n",
        "      cs.append(colors[1])\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(3, 2.25))\n",
        "\n",
        "  rho, pval = ss.pearsonr(xs, ys)\n",
        "  print(f'rho: {rho} - p-value: {pval}')\n",
        "\n",
        "  sct = ax.scatter(xs, ys, s=1.5, c=cs, alpha=0.75)\n",
        "\n",
        "  ax.errorbar(\n",
        "      xs,\n",
        "      ys,\n",
        "      xerr=ex,\n",
        "      fmt='none',\n",
        "      elinewidth=0.25,\n",
        "      ecolor=cs,\n",
        "      alpha=0.5,\n",
        "      barsabove=False)\n",
        "  ax.errorbar(\n",
        "      xs,\n",
        "      ys,\n",
        "      yerr=ey,\n",
        "      fmt='none',\n",
        "      elinewidth=0.25,\n",
        "      ecolor=cs,\n",
        "      alpha=0.5,\n",
        "      barsabove=False)\n",
        "\n",
        "  ax.set_ylim([-0.042, 0.042])\n",
        "  ax.set_xlim([-0.042, 0.042])\n",
        "\n",
        "  ax.axhline([0], ls='--', lw=0.5)\n",
        "  ax.axvline([0], ls='--', lw=0.5)\n",
        "\n",
        "  sns.regplot(xs, ys, scatter=False, truncate=False, line_kws={'lw': 0.5})\n",
        "\n",
        "  ticks = [-0.04, -0.02, 0, 0.02, 0.04]\n",
        "\n",
        "  ax.set_yticks(ticks)\n",
        "  ax.set_yticklabels(ticks, fontsize=5)\n",
        "\n",
        "  ax.set_xticks(ticks)\n",
        "  ax.set_xticklabels(ticks, fontsize=5)\n",
        "\n",
        "  ax.set_aspect('equal')\n",
        "\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTYYwS9ByPzc"
      },
      "outputs": [],
      "source": [
        "fig = plot_craig_genmed_effect_sizes()\n",
        "\n",
        "fig.savefig(\n",
        "    'craig_effect_size.pdf', transparent=True, bbox_inches='tight', dpi=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_38tVvhdLeF"
      },
      "source": [
        "#Risk loci Venn diagram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km58drS5dNxt"
      },
      "outputs": [],
      "source": [
        "def plot_venn_diagram(subsets, set_colors=None):\n",
        "  \"\"\"Plots the Venn diagram specified in `subsets`.\"\"\"\n",
        "\n",
        "  if set_colors is None:\n",
        "    set_colors = ['#fbbc05', '#4285f4']\n",
        "  \n",
        "  fig, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "  venn_out = matplotlib_venn.venn2(\n",
        "      subsets=subsets,\n",
        "      set_labels=['', ''],\n",
        "      set_colors=set_colors,\n",
        "      alpha=1,ax=ax)\n",
        "\n",
        "  for text in venn_out.subset_labels:\n",
        "    text.set_fontsize(20)\n",
        "\n",
        "  fig.savefig(\"mlbased_craig_loci_venn.pdf\", dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDXvQrGPnWSU"
      },
      "outputs": [],
      "source": [
        "subsets = {'10': 3, '01': 94, '11': 62}\n",
        "\n",
        "plot_venn_diagram(subsets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By5cywY6o6jV"
      },
      "source": [
        "# PRS Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_JYv0GnoyQu"
      },
      "outputs": [],
      "source": [
        "# Note: These numberes are updated based on PLINK scores.\n",
        "def plot_prs_with_cis():\n",
        "\n",
        "  prun_thresh_bar_data = pd.DataFrame({\n",
        "      'dataset': ['Craig et al', 'ML model', 'Craig et al', 'ML model'],\n",
        "      'model': ['UKB', 'UKB', 'EPIC-Norfolk', 'Epic-Norfolk'],\n",
        "      'R': [0.287, 0.366, 0.228, 0.310],\n",
        "      'low': [0.247, 0.331, 0.203, 0.287],\n",
        "      'high': [0.326, 0.401, 0.252, 0.333]\n",
        "  })\n",
        "\n",
        "  elastic_net_bar_data = pd.DataFrame({\n",
        "      'dataset': ['Craig et al', 'ML model', 'Craig et al', 'ML model'],\n",
        "      'model': ['UKB', 'UKB', 'EPIC-Norfolk', 'Epic-Norfolk'],\n",
        "      'R': [0.313, 0.376, 0.272, 0.326],\n",
        "      'low': [0.276, 0.341, 0.249, 0.303],\n",
        "      'high': [0.349, 0.410, 0.296, 0.349]\n",
        "  })\n",
        "\n",
        "  orig_bar_data = pd.DataFrame({\n",
        "      'dataset': ['Craig et al', 'ML model', 'Craig et al', 'ML model'],\n",
        "      'model': ['P+T', 'P+T', 'Elastic Net', 'Elastic Net'],\n",
        "      'R': [0.308, 0.359, 0.317, 0.376],\n",
        "      'low': [0.269, 0.322, 0.280, 0.339],\n",
        "      'high': [0.345, 0.395, 0.354, 0.410]\n",
        "  })\n",
        "\n",
        "  max_y = 0.50\n",
        "  lab_y = 0.46\n",
        "  width = 0.25\n",
        "  fig_pt, ax = plt.subplots(figsize=(3, 2.25))\n",
        "\n",
        "  x = [0, 0.8]\n",
        "  labels = ['UKB', 'EPIC-Norfolk']\n",
        "  x_bar = [\n",
        "      x[0] - width / 2, x[0] + width / 2, x[1] - width / 2, x[1] + width / 2\n",
        "  ]\n",
        "\n",
        "  ml_patch = patches.Patch(color=ML_COLOR, label='ML-based')\n",
        "  cr_patch = patches.Patch(color=CRAIG_COLOR, label='Craig et al.')\n",
        "\n",
        "  ax.bar(\n",
        "      x_bar,\n",
        "      prun_thresh_bar_data.R,\n",
        "      yerr=[\n",
        "          prun_thresh_bar_data.R - prun_thresh_bar_data.low, \n",
        "          prun_thresh_bar_data.high - prun_thresh_bar_data.R,\n",
        "      ],\n",
        "      width=width,\n",
        "      color=[CRAIG_COLOR, ML_COLOR, CRAIG_COLOR, ML_COLOR],\n",
        "      capsize=2,\n",
        "      error_kw=dict(elinewidth=0.5, capthick=0.5))\n",
        "  ax.set_ylabel('Correlation', fontsize=6)\n",
        "  ax.set_yticks([0, 0.1, 0.2, 0.3, 0.4])\n",
        "  ax.set_yticklabels([0, 0.1, 0.2, 0.3, 0.4], fontsize=5)\n",
        "  ax.set_xticks(x)\n",
        "  ax.set_xticklabels(labels, fontsize=6)\n",
        "  ax.set_title('P+T', fontsize=6)\n",
        "  ax.tick_params(\n",
        "      axis='x',  # changes apply to the x-axis\n",
        "      which='both',  # both major and minor ticks are affected\n",
        "      top=False)  # ticks along the top edge are off\n",
        "  ax.set_ylim((0, max_y))\n",
        "  ax.legend(handles=[ml_patch, cr_patch], fontsize=6, fancybox=False)\n",
        "\n",
        "  for x_text, r in zip(x_bar, prun_thresh_bar_data.R):\n",
        "    ax.text(x_text, lab_y, f'{r:.2f}', horizontalalignment='center', fontsize=6)\n",
        "\n",
        "  fig_pt.show()\n",
        "\n",
        "  fig_en, ax = plt.subplots(figsize=(3, 2.25))\n",
        "\n",
        "  ax.bar(\n",
        "      x_bar,\n",
        "      elastic_net_bar_data.R,\n",
        "      yerr=[\n",
        "          elastic_net_bar_data.R - elastic_net_bar_data.low,\n",
        "          elastic_net_bar_data.high - elastic_net_bar_data.R,\n",
        "      ],\n",
        "      color=[CRAIG_COLOR, ML_COLOR, CRAIG_COLOR, ML_COLOR],\n",
        "      width=width,\n",
        "      capsize=2,\n",
        "      error_kw=dict(elinewidth=0.75, capthick=0.75))\n",
        "  ax.set_ylabel('Correlation', fontsize=6)\n",
        "  ax.set_yticks([0, 0.1, 0.2, 0.3, 0.4])\n",
        "  ax.set_yticklabels([0, 0.1, 0.2, 0.3, 0.4], fontsize=5)\n",
        "  ax.set_xticks(x)\n",
        "  ax.set_xticklabels(labels, fontsize=6)\n",
        "  ax.set_title('Elastic Net', fontsize=6)\n",
        "  ax.tick_params(\n",
        "      axis='x',  # changes apply to the x-axis\n",
        "      which='both',  # both major and minor ticks are affected\n",
        "      top=False)  # ticks along the top edge are off\n",
        "  ax.set_ylim((0, max_y))\n",
        "\n",
        "  for x_text, r in zip(x_bar, elastic_net_bar_data.R):\n",
        "    ax.text(x_text, lab_y, f'{r:.2f}', horizontalalignment='center', fontsize=6)\n",
        "\n",
        "  fig_en.show()\n",
        "\n",
        "  # Results of the original hits\n",
        "  fig_og, ax = plt.subplots(figsize=(3, 2.25))\n",
        "\n",
        "  x = [0, 0.8]\n",
        "  labels = ['P+T', 'Elastic Net']\n",
        "  x_bar = [\n",
        "      x[0] - width / 2, x[0] + width / 2, x[1] - width / 2, x[1] + width / 2\n",
        "  ]\n",
        "\n",
        "  ax.bar(\n",
        "      x_bar,\n",
        "      orig_bar_data.R,\n",
        "      yerr=[\n",
        "          orig_bar_data.R - orig_bar_data.low,\n",
        "          orig_bar_data.high - orig_bar_data.R,\n",
        "      ],\n",
        "      color=[CRAIG_COLOR, ML_COLOR, CRAIG_COLOR, ML_COLOR],\n",
        "      width=width,\n",
        "      capsize=2,\n",
        "      error_kw=dict(elinewidth=0.75, capthick=0.75))\n",
        "  ax.set_ylabel('Correlation', fontsize=6)\n",
        "  ax.set_yticks([0, 0.1, 0.2, 0.3, 0.4])\n",
        "  ax.set_yticklabels([0, 0.1, 0.2, 0.3, 0.4], fontsize=5)\n",
        "  ax.set_xticks(x)\n",
        "  ax.set_xticklabels(labels, fontsize=6)\n",
        "  ax.set_title('Original', fontsize=6)\n",
        "  ax.tick_params(\n",
        "      axis='x',  # changes apply to the x-axis\n",
        "      which='both',  # both major and minor ticks are affected\n",
        "      top=False)  # ticks along the top edge are off\n",
        "  ax.set_ylim((0, max_y))\n",
        "\n",
        "  for x_text, r in zip(x_bar, orig_bar_data.R):\n",
        "    ax.text(x_text, lab_y, f'{r:.2f}', horizontalalignment='center', fontsize=6)\n",
        "\n",
        "  fig_og.show()\n",
        "\n",
        "\n",
        "  return fig_pt, fig_en, fig_og\n",
        "\n",
        "\n",
        "fig_pt, fig_en, fig_og = plot_prs_with_cis()\n",
        "\n",
        "fig_pt.savefig('pt_prs.pdf', transparent=True, bbox_inches='tight')\n",
        "\n",
        "fig_en.savefig('en_prs.pdf', transparent=True, bbox_inches='tight')\n",
        "\n",
        "fig_og.savefig('og_prs.pdf', transparent=True, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Nj5zgiNt6_F"
      },
      "source": [
        "#EPIC PRS plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyzRnKsyt7RU"
      },
      "outputs": [],
      "source": [
        "def plot_epic_prs_deciles() -\u003e Tuple[FIG, AX]:\n",
        "  \"\"\"Plots GenMed and Craig PRS deciles for glaucoma subtypes.\"\"\"\n",
        "\n",
        "  x = np.arange(1, 11)\n",
        "  width = 0.25\n",
        "\n",
        "  x_cr = x - width / 2\n",
        "  x_ml = x + width / 2\n",
        "\n",
        "  craig = {}\n",
        "  genmed = {}\n",
        "\n",
        "  genmed = {\n",
        "      'poag':\n",
        "          np.asarray([\n",
        "              [1, 1, 1],\n",
        "              [3.161, 1.021, 9.788],\n",
        "              [2.025, 0.604, 6.785],\n",
        "              [3.453, 1.126, 10.592],\n",
        "              [3.951, 1.308, 11.936],\n",
        "              [6.011, 2.058, 17.560],\n",
        "              [3.995, 1.323, 12.067],\n",
        "              [5.510, 1.880, 16.152],\n",
        "              [5.941, 2.040, 17.298],\n",
        "              [9.705, 3.413, 27.597],\n",
        "          ]),\n",
        "      'htg':\n",
        "          np.asarray([\n",
        "              [1, 1, 1],\n",
        "              [3.257, 0.888, 11.942],\n",
        "              [2.041, 0.506, 8.227],\n",
        "              [3.607, 0.997, 13.047],\n",
        "              [2.977, 0.799, 11.094],\n",
        "              [3.469, 0.946, 12.722],\n",
        "              [3.022, 0.811, 11.260],\n",
        "              [3.684, 1.018, 13.325],\n",
        "              [2.942, 0.789, 10.968],\n",
        "              [7.413, 2.181, 25.194],\n",
        "          ]),\n",
        "      'ntg':\n",
        "          np.asarray([\n",
        "              [1, 1, 1],\n",
        "              [2.921, 0.302, 28.209],\n",
        "              [2.03, 0.183, 22.477],\n",
        "              [2.96, 0.307, 28.587],\n",
        "              [6.978, 0.854, 56.999],\n",
        "              [13.456, 1.751, 103.394],\n",
        "              [6.976, 0.854, 56.976],\n",
        "              [11.049, 1.419, 86.019],\n",
        "              [14.822, 1.948, 112.789],\n",
        "              [16.543, 2.174, 125.904],\n",
        "          ]),\n",
        "  }\n",
        "\n",
        "  craig = {\n",
        "      'poag':\n",
        "          np.asarray([\n",
        "              [1, 1, 1],\n",
        "              [0.756, 0.260, 2.202],\n",
        "              [1.829, 0.766, 4.368],\n",
        "              [2.008, 0.849, 4.751],\n",
        "              [2.586, 1.131, 5.916],\n",
        "              [3.014, 1.336, 6.797],\n",
        "              [1.612, 0.660, 3.936],\n",
        "              [2.143, 0.913, 5.030],\n",
        "              [3.373, 1.507, 7.550],\n",
        "              [3.859, 1.740, 8.557],\n",
        "          ]),\n",
        "      'htg':\n",
        "          np.asarray([\n",
        "              [1, 1, 1],\n",
        "              [0.831, 0.251, 2.751],\n",
        "              [1.951, 0.724, 5.261],\n",
        "              [1.48, 0.521, 4.204],\n",
        "              [2.115, 0.795, 5.629],\n",
        "              [2.65, 1.025, 6.853],\n",
        "              [0.82, 0.248, 2.712],\n",
        "              [1.505, 0.530, 4.276],\n",
        "              [2.073, 0.769, 5.588],\n",
        "              [1.905, 0.697, 5.212],\n",
        "          ]),\n",
        "      'ntg':\n",
        "          np.asarray([\n",
        "              [1, 1, 1],\n",
        "              [0.512, 0.046, 5.672],\n",
        "              [1.482, 0.246, 8.921],\n",
        "              [3.515, 0.725, 17.032],\n",
        "              [3.975, 0.839, 18.844],\n",
        "              [4.055, 0.856, 19.223],\n",
        "              [3.992, 0.842, 18.927],\n",
        "              [4.103, 0.866, 19.447],\n",
        "              [7.257, 1.638, 32.149],\n",
        "              [9.506, 2.190, 41.263],\n",
        "          ]),\n",
        "  }\n",
        "\n",
        "  # figure has 3 panels: POAG, HTG, NTG\n",
        "  fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(16, 3.5))\n",
        "\n",
        "  for i, k in enumerate(['poag', 'htg', 'ntg']):\n",
        "\n",
        "    # cmpute the upper and lower bounds for errorbars\n",
        "    # upper bound\n",
        "    craig[k][:, 2] = craig[k][:, 2] - craig[k][:, 0]\n",
        "    genmed[k][:, 2] = genmed[k][:, 2] - genmed[k][:, 0]\n",
        "    # lower bound\n",
        "    craig[k][:, 1] = craig[k][:, 0] - craig[k][:, 1]\n",
        "    genmed[k][:, 1] = genmed[k][:, 0] - genmed[k][:, 1]\n",
        "\n",
        "    ax[i].errorbar(\n",
        "        x_ml,\n",
        "        genmed[k][:, 0],\n",
        "        yerr=genmed[k][:, [1, 2]].T,\n",
        "        fmt='o',\n",
        "        c=ML_COLOR,\n",
        "        linewidth=2,\n",
        "        label='ML-based')\n",
        "    ax[i].errorbar(\n",
        "        x_cr,\n",
        "        craig[k][:, 0],\n",
        "        yerr=craig[k][:, [1, 2]].T,\n",
        "        fmt='o',\n",
        "        c=CRAIG_COLOR,\n",
        "        linewidth=2,\n",
        "        label='Craig et al.')\n",
        "\n",
        "    ax[i].hlines(1, 0, 11, linestyle='--')\n",
        "    ax[i].set_xlim([0, 11])\n",
        "\n",
        "    lg = ax[i].legend(loc='upper left', fancybox=False)\n",
        "    lg.get_frame().set_edgecolor('k')\n",
        "\n",
        "    _ = ax[i].set_xticks(x)\n",
        "    ax[i].set_xlabel('VCDR PRS deciles', fontsize=12)\n",
        "    ax[i].set_ylabel(f'{k.upper()} (95% CI)', fontsize=12)\n",
        "    ax[i].set_yscale('log')\n",
        "    ax[i].set_yticks([0.5, 1, 2, 5, 10, 20, 50, 100])\n",
        "    ax[i].set_yticklabels([0.5, 1, 2, 5, 10, 20, 50, 100])\n",
        "    ax[i].set_ylim([0.25, 140])\n",
        "    ax[i].minorticks_off()\n",
        "\n",
        "  return fig, ax\n",
        "\n",
        "fig, ax = plot_epic_prs_deciles()\n",
        "fig.savefig('epic_poag_prs.pdf', transparent=True, bbox_inches='tight')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/genomics/internal:genomics_colab",
        "kind": "private"
      },
      "name": "plotting_results",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1Rj0zqc2a8ZQhhwuENk7UvDC1tTQLH_A6",
          "timestamp": 1615658555082
        },
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/colab/notebooks/vcdr/vcdr_manuscript_plots.ipynb",
          "timestamp": 1615572605820
        },
        {
          "file_id": "1lGAeoLJcvbUSU86NgaIxH_Z_x8CdqwVQ",
          "timestamp": 1588601316474
        },
        {
          "file_id": "1-bkX-fMQGmbrU8atSk3n55d0aOjGqyzi",
          "timestamp": 1588360483066
        },
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/colab/notebooks/glaucoma_phenotype_calling.vcdr.ipynb?workspaceId=behsaz:vcdr00::citc",
          "timestamp": 1584744622409
        },
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/colab/notebooks/glaucoma_phenotype_calling.v2.ipynb?workspaceId=babaka:gcs::citc",
          "timestamp": 1580435228346
        },
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/colab/notebooks/phenotype_calling.ipynb",
          "timestamp": 1573670795749
        },
        {
          "file_id": "/piper/depot/google3/experimental/users/jtcosentino/mlderived_gwas/notebooks/ML_derived_GWAS_Proposal.ipynb?workspaceId=jtcosentino:mlderived-gwas::citc",
          "timestamp": 1568936381805
        },
        {
          "file_id": "1LY-fvCZ49yOFP-_l6-pu2OJCmzvnONgV",
          "timestamp": 1566336861140
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
