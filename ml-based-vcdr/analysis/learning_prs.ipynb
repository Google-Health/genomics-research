{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgieGK9qPiHP"
      },
      "source": [
        "```\n",
        "Copyright 2021 Google LLC.\n",
        "\n",
        "Redistribution and use in source and binary forms, with or without\n",
        "modification, are permitted provided that the following conditions are met:\n",
        "\n",
        "1. Redistributions of source code must retain the above copyright notice, this\n",
        "   list of conditions and the following disclaimer.\n",
        "\n",
        "2. Redistributions in binary form must reproduce the above copyright notice,\n",
        "   this list of conditions and the following disclaimer in the documentation\n",
        "   and/or other materials provided with the distribution.\n",
        "\n",
        "3. Neither the name of the copyright holder nor the names of its contributors\n",
        "   may be used to endorse or promote products derived from this software\n",
        "   without specific prior written permission.\n",
        "\n",
        "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
        "AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
        "IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
        "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
        "FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
        "DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
        "SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
        "CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
        "OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
        "OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
        " ```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayHgU_ppI5zd"
      },
      "source": [
        "##PRS Analyses\n",
        "\n",
        "This notebook reports the final PRS analyses. The models are fit using the ML-based VCDR prediction on all European individuals in UKB not in the test set, and evaluated in the adjudicated set of images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2DzMhTJl9pb"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "from concurrent import futures\n",
        "import copy\n",
        "import csv\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import patches\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from scipy import stats\n",
        "from sklearn import linear_model\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection\n",
        "from sklearn import preprocessing\n",
        "from sklearn.utils import resample\n",
        "from typing import List, Sequence, Dict,Text\n",
        "\n",
        "# Modules defined within this repository.\n",
        "import perf_metrics\n",
        "import pheno_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEZUCUebUpXC"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "mpl.rcParams['figure.dpi'] = 300\n",
        "mpl.rcParams['ps.fonttype'] = 42\n",
        "mpl.rcParams['pdf.fonttype'] = 42\n",
        "\n",
        "mpl.rcParams['savefig.transparent'] = True\n",
        "mpl.rcParams['savefig.bbox'] = 'tight'\n",
        "mpl.rcParams['savefig.dpi'] = 300\n",
        "\n",
        "pd.set_option('mode.chained_assignment', 'raise')\n",
        "NPROC = multiprocessing.cpu_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UpNAGqSXnie"
      },
      "source": [
        "# Data input definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwV8j0JhnM-h"
      },
      "outputs": [],
      "source": [
        "# This has fields \"image_id,GLAUCOMA_GRADABILITY,GLAUCOMA_SUSPECT_RISK,\n",
        "# VERTICAL_CD_VISIBILITY,VERTICAL_CUP_TO_DISC,VCDR_GRADERS,VCDR_CONFIDENCE,\n",
        "# VCDR_STDEV,VCDR_MAX_DIFF\"\n",
        "# The image_id field is the full path to the file, which needs to be parsed to extract the EID.\n",
        "VCDR_LABELS_FILE = '/path/to/labels/file.tsv'\n",
        "\n",
        "# Craig VCDR GWAS variants. Downloaded directly from the paper.\n",
        "# https://pubmed.ncbi.nlm.nih.gov/31959993/\n",
        "# Fields SNP,Chr,Position,EA,NEA,Freq,BETA,SE,P,Nearest_gene\n",
        "CRAIG_VCDR_SNPS = '/path/to/craig_et_al/hits.csv'\n",
        "\n",
        "# The set of proxy SNPs for Craig et al. hits in EPIC-Norfolk.\n",
        "CRAIG_VCDR_EPIC_SURROGATE_SNPS = '/path/to/craig_et_al/proxy_snps.tsv'\n",
        "\n",
        "# The subset of the Craig et al SNPs that are present in EPIC-Norfolk.\n",
        "CRAIG_VCDR_EPIC_ONLY_SNPS = '/path/to/craig_et_al/snps_in_epic.tsv'\n",
        "\n",
        "# ML-based GWAS variants (299 total hits).\n",
        "# This is a tab-separated file with fields\n",
        "# CHR\tBP\tREF\tALT\tRS\tAFFX\tEFF\tAAF\tNUM_INDV\tSRC\tINFO_SCORE\tP_HWE_COH\t\n",
        "# P_HWE_POP\tP\tBETA\tSE\tCLUSTER_LEFT\tCLUSTER_RIGHT\tCLUSTER_SIZE\tCYTOBAND\t\n",
        "# GENE_CONTEXT\tCLOSEST_GENES\tGLAUCOMA_HITS\tINTRAOCULAR_HITS\tCUPDISCRATIO_HITS\t\n",
        "# CUPTODISCRATIO_HITS\tOTHER_HITS\n",
        "MLDERIVED_VCDR_SNPS = '/path/to/mlbased_hits.tsv'\n",
        "\n",
        "# ML-based GWAS variants from Oct 2020 that are present on the EPIC-Norfolk\n",
        "# array. This is 282 hits generated by subsetting variants to those present on\n",
        "# the EPIC-Norfolk array and then re-calling hits (so the 282 are not a proper\n",
        "# subset of the 299 total discovered in UKB). This is an 18-field tab-separated\n",
        "# file:\n",
        "# 1: CHR\n",
        "# 2: BP\n",
        "# 3: SNP\n",
        "# 4: REF\n",
        "# 5: ALT\n",
        "# 6: EFF\n",
        "# 7: AAF\n",
        "# 8: NUM_INDV\n",
        "# 9: SRC\n",
        "# 10: INFO_SCORE\n",
        "# 11: P\n",
        "# 12: BETA\n",
        "# 13: SE\n",
        "# 14: P_HWE_POP\n",
        "# 15: EPIC_SNP\n",
        "# 16: CLUSTER_LEFT\n",
        "# 17: CLUSTER_RIGHT\n",
        "# 18: CLUSTER_SIZE\n",
        "MLDERIVED_VCDR_EPIC_SURROGATE_SNPS = '/path/to/mlbased_epic_hits.tsv'\n",
        "\n",
        "# Raw image model predictions.\n",
        "RAW_IMAGE_PREDICTIONS = '/path/to/model_predictions.tsv'\n",
        "\n",
        "# PLINK PRS predictions path.\n",
        "PLINK_PRS_PREDS = '/path/to/plink_predictions/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9ptA37xXrBe"
      },
      "source": [
        "## Code to load VCDR inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnsHq-W2Xqch"
      },
      "outputs": [],
      "source": [
        "def _get_eid(row):\n",
        "  \"\"\"Returns the integer EID from the CSV row.\"\"\"\n",
        "  key = 'image_id' if 'image_id' in row else ''\n",
        "  bn = os.path.basename(row[key])\n",
        "  return int(bn.split('_')[0])\n",
        "\n",
        "\n",
        "def _read_all_vcdrs(filename, eids):\n",
        "  \"\"\"Returns a dict from EID -\u003e list of (VCDR measurement, confidence, stdev) tuples.\"\"\"\n",
        "  missing_vcdr = 0\n",
        "  invalid_eids = 0\n",
        "  total = 0\n",
        "  measurements = collections.defaultdict(list)\n",
        "  with open(filename) as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "      total += 1\n",
        "      eid = _get_eid(row)\n",
        "      if eid not in eids:\n",
        "        # We are not allowed to use this EID.\n",
        "        invalid_eids += 1\n",
        "        continue\n",
        "      try:\n",
        "        vcdr = float(row['VERTICAL_CUP_TO_DISC'])\n",
        "        assert 0 \u003c= vcdr \u003c= 1\n",
        "        confidence = float(row.get('VCDR_CONFIDENCE', 0.5))\n",
        "        stdev = float(row['VCDR_STDEV'])\n",
        "      except (AssertionError, ValueError):\n",
        "        missing_vcdr += 1\n",
        "      else:\n",
        "        measurements[eid].append((vcdr, confidence, stdev))\n",
        "  num_eids = len(measurements)\n",
        "  kept_records = sum(len(v) for v in measurements.values())\n",
        "  assert total == (invalid_eids + missing_vcdr + kept_records)\n",
        "  print(\n",
        "      f'{total} total VCDR rows: {invalid_eids} invalid eids, {missing_vcdr} missing VCDR, {kept_records} kept.'\n",
        "  )\n",
        "  print(f'  {num_eids} unique EIDs.')\n",
        "  return measurements\n",
        "\n",
        "\n",
        "def _create_single_eid_level_vcdr(vc_tuples):\n",
        "  \"\"\"Returns the single EID-level VCDR to use, and a tuple for ordering by confidence.\n",
        "\n",
        "  Args:\n",
        "    vc_tuples: A list of (vcdr, confidence, stdev) triplets representing\n",
        "      attributes of a single image's VCDR grading by one or more individuals.\n",
        "\n",
        "  Returns:\n",
        "    A pair of results: the EID-level VCDR prediction and a tuple of\n",
        "    (adjudication status, sum of stdevs of image-level predictions, stdev of\n",
        "     images).\n",
        "  \"\"\"\n",
        "  # These are set so that sorting puts adjudicated images first.\n",
        "  ADJUDICATED = 0\n",
        "  NOT_ADJUDICATED = 1\n",
        "\n",
        "  if len(vc_tuples) == 1:\n",
        "    val, conf, std = vc_tuples[0]\n",
        "    if conf \u003c 0.25:\n",
        "      raise ValueError('Unexpected')\n",
        "    elif conf \u003c 0.75:\n",
        "      ordering = (NOT_ADJUDICATED, -1, 0)\n",
        "    else:\n",
        "      ordering = (ADJUDICATED, std, 0)\n",
        "    return val, ordering\n",
        "\n",
        "  # There are multiple graded images for the individual.\n",
        "  best_confidence = max(x[1] for x in vc_tuples)\n",
        "  # Keep only images that have the best confidence. For individuals with\n",
        "  # multiple graded images, that means that if they have both multiple graders\n",
        "  # on at least one image and images with just a single grader, the\n",
        "  # single-grader images are ignored.\n",
        "  conf_tuples = [x for x in vc_tuples if x[1] == best_confidence]\n",
        "  if best_confidence \u003c 0.25:\n",
        "    raise ValueError('Expected at least 0.5: {}'.format(vc_tuples))\n",
        "  elif best_confidence \u003c 0.75:\n",
        "    # This is multiple images with a single grade each. Just average them.\n",
        "    best_value = np.mean([val for val, _, _ in conf_tuples])\n",
        "    ordering = (\n",
        "        NOT_ADJUDICATED,\n",
        "        -len(conf_tuples),  # More images is better than fewer.\n",
        "        np.std([val for val, _, _ in conf_tuples]))\n",
        "  else:\n",
        "    # There are multiple graded images for this EID, all of which have multiple\n",
        "    # graders. Use inverse variance weighting to determine the EID-level VCDR.\n",
        "    numer = denom = 0\n",
        "    for val, _, std in conf_tuples:\n",
        "      invvar = 1e10 if std == 0 else 1. / (std * std)\n",
        "      numer += val * invvar\n",
        "      denom += invvar\n",
        "    best_value = numer / denom\n",
        "    ordering = (ADJUDICATED, sum(s for _, _, s in conf_tuples),\n",
        "                np.std([val for val, _, _ in conf_tuples]))\n",
        "  return best_value, ordering\n",
        "\n",
        "\n",
        "def _eid_vcdr(all_vcdrs):\n",
        "  \"\"\"Returns a triplet of VCDR results.\n",
        "\n",
        "  The first result is a dictionary mapping from eid --\u003e VCDR value to predict.\n",
        "  The second result is all the EIDs from the first result, ordered by confidence\n",
        "  in their results. I.e. first element in the output is the VCDR we are most\n",
        "  confident in, and the last element is the one we are least confident in.\n",
        "  The final result is a boolean array corresponding to the second result, where\n",
        "  True means that the image was adjudicated (read by \u003e1 grader with\n",
        "  not-too-different results.\n",
        "\n",
        "  Args:\n",
        "    all_vcdrs: Dict mapping from EID -\u003e list of (vcdr, confidence, stdev)\n",
        "      triplets, generated by `read_all_vcdrs` function.\n",
        "  \"\"\"\n",
        "  retval = {}\n",
        "  adjudication_ordering = []\n",
        "  for eid, vc_tuples in all_vcdrs.items():\n",
        "    vcdr, adjudication_tuple = _create_single_eid_level_vcdr(vc_tuples)\n",
        "    retval[eid] = vcdr\n",
        "    # Attach EID to the end of the ordering so that it does not affect sort\n",
        "    # order but we can extract the ordered set of EIDs.\n",
        "    adjudication_ordering.append(adjudication_tuple + (eid,))\n",
        "\n",
        "  ordered_results = sorted(adjudication_ordering)\n",
        "  ordered_eids = [x[-1] for x in ordered_results]\n",
        "  is_adjudicated = [x[0] == 0 for x in ordered_results]\n",
        "  return retval, ordered_eids, is_adjudicated\n",
        "\n",
        "\n",
        "class VcdrValues(object):\n",
        "\n",
        "  def __init__(self, filename, eids_to_retain):\n",
        "    eid_to_vcdr_list = _read_all_vcdrs(filename=filename, eids=eids_to_retain)\n",
        "    self._eid_to_vcdr_value, self._eid_ordering, self._is_adjudicated = _eid_vcdr(\n",
        "        eid_to_vcdr_list)\n",
        "    assert len(self._eid_to_vcdr_value) == len(self._eid_ordering) == len(\n",
        "        set(self._eid_ordering))\n",
        "    assert sorted(self._eid_to_vcdr_value.keys()) == sorted(self._eid_ordering)\n",
        "\n",
        "  def as_dataframe(self):\n",
        "    \"\"\"Returns a pandas DataFrame indexed by 'eid' with column 'vcdr' containing the value.\"\"\"\n",
        "    retval = pd.DataFrame([{\n",
        "        'eid': k,\n",
        "        'vcdr': v\n",
        "    } for k, v in self._eid_to_vcdr_value.items()])\n",
        "    return retval.set_index('eid')\n",
        "\n",
        "  def top_eids(self, n, valid_eids):\n",
        "    \"\"\"Returns a set of the `n` best ordered EIDs when restricted to those in `valid_eids`.\"\"\"\n",
        "    retval = set()\n",
        "    for i, eid in enumerate(self._eid_ordering, start=1):\n",
        "      if eid in valid_eids:\n",
        "        retval.add(eid)\n",
        "      if len(retval) == n:\n",
        "        print('Returning top {} EIDs after examining {}'.format(n, i))\n",
        "        return retval\n",
        "    raise ValueError('Unable to retrieve {} EIDs'.format(n))\n",
        "\n",
        "  @property\n",
        "  def eids(self):\n",
        "    return set(self._eid_ordering)\n",
        "\n",
        "  @property\n",
        "  def adjudicated_eids(self):\n",
        "    return {\n",
        "        eid\n",
        "        for eid, is_adjudicated in zip(self._eid_ordering, self._is_adjudicated)\n",
        "        if is_adjudicated\n",
        "    }\n",
        "\n",
        "\n",
        "# Do some testing of the _create_single_eid_level_vcdr function.\n",
        "def _test_create_single_eid_level_vcdr():\n",
        "\n",
        "  def check(inputs, expected_vcdr):\n",
        "    assert expected_vcdr == _create_single_eid_level_vcdr(inputs)[0]\n",
        "\n",
        "  # Single VCDR values return exactly the same.\n",
        "  check([(0.8, 0.5, 0.0)], 0.8)\n",
        "  check([(0.9, 1.0, 0.6)], 0.9)\n",
        "\n",
        "  # Multiple VCDR values for singly-graded images take the mean.\n",
        "  check([\n",
        "      (0.2, 0.5, 0.0),\n",
        "      (0.4, 0.5, 0.0),\n",
        "  ], (0.2 + 0.4) / 2)\n",
        "  check([(0.2, 0.5, 0.0), (0.4, 0.5, 0.0), (0.6, 0.5, 0.0)],\n",
        "        (0.2 + 0.4 + 0.6) / 3)\n",
        "\n",
        "  # Multiple VCDR values that include at least one multi-graded only use\n",
        "  # those multigraded.\n",
        "  check([(0.1, 0.5, 0.0), (0.1, 0.5, 0.0), (0.9, 1.0, 0.2)], 0.9)\n",
        "\n",
        "  # Multiple adjudicated images use inverse variance weighting of those.\n",
        "  check([(0.9, 1.0, 0.2), (0.8, 1.0, 0.5)], 0.8862068965517241)\n",
        "  check([(0.9, 1.0, 0.0), (0.5, 1.0, 0.5)], 0.89999999984)\n",
        "\n",
        "\n",
        "_test_create_single_eid_level_vcdr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wwBTaZqb15F"
      },
      "source": [
        "## Code for loading all genotype data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vQGhA9Un-ma"
      },
      "outputs": [],
      "source": [
        "Variant = collections.namedtuple('Variant',\n",
        "                                 'chr pos A1 A0 name freq beta pvalue')\n",
        "\n",
        "# Contains a numpy array of hard genotypes, numpy array of dosages,\n",
        "# string reference allele, and string alternate allele. The 0/1/2 coding of the\n",
        "# genotypes represents the number of alternate alleles present.\n",
        "VariantCall = collections.namedtuple('VariantCall', 'geno dosage ref alt')\n",
        "\n",
        "\n",
        "def _safename(s):\n",
        "  return s.replace(':', '_').replace('-', '_')\n",
        "\n",
        "\n",
        "def read_craig_snps(filename, thresh=5e-8):\n",
        "  \"\"\"Returns a list of Variant objects representing the CRAIG_VCDR_SNPS or CRAIG_META_SNPS file.\"\"\"\n",
        "  retval = []\n",
        "  with open(filename) as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "      betakey = 'BETA' if 'BETA' in row else 'BETA_(MTAG)'\n",
        "      pkey = 'P' if 'P' in row else 'P_(MTAG)'\n",
        "      v = Variant(\n",
        "          chr=int(row['Chr']),\n",
        "          pos=int(row['Position']),\n",
        "          A1=row['EA'],\n",
        "          A0=row['NEA'],\n",
        "          name=_safename(row['SNP']),\n",
        "          freq=float(row['Freq']),\n",
        "          beta=float(row[betakey]),\n",
        "          pvalue=float(row[pkey]))\n",
        "      if v.pvalue \u003c= thresh:\n",
        "        retval.append(v)\n",
        "  return retval\n",
        "\n",
        "\n",
        "def read_gwas_pipeline_results(filename, namecol='RS', thresh=5e-8):\n",
        "  \"\"\"Returns a list of Variant objects from the file.\"\"\"\n",
        "  retval = []\n",
        "  with open(filename) as f:\n",
        "    reader = csv.DictReader(f, delimiter='\\t')\n",
        "    for row in reader:\n",
        "      if row[namecol] and row[namecol] != '.':\n",
        "        name = row[namecol]\n",
        "      else:\n",
        "        name = '{}_{}_{}_{}'.format(row['CHR'], row['BP'], row['REF'],\n",
        "                                    row['ALT'])\n",
        "      assert row['EFF'] in [row['REF'], row['ALT']]\n",
        "      if row['EFF'] == row['ALT']:\n",
        "        a1 = row['ALT']\n",
        "        a0 = row['REF']\n",
        "        freq = float(row['AAF'])\n",
        "      else:\n",
        "        a1 = row['REF']\n",
        "        a0 = row['ALT']\n",
        "        freq = 1 - float(row['AAF'])\n",
        "      assert 0 \u003c= freq \u003c= 1\n",
        "      v = Variant(\n",
        "          chr=int(row['CHR']),\n",
        "          pos=int(row['BP']),\n",
        "          A1=a1,\n",
        "          A0=a0,\n",
        "          name=_safename(name),\n",
        "          freq=freq,\n",
        "          beta=float(row['BETA']),\n",
        "          pvalue=float(row['P']))\n",
        "      if v.pvalue \u003c= thresh:\n",
        "        retval.append(v)\n",
        "  return retval\n",
        "\n",
        "\n",
        "def _load_variant_calls(variants, eids):\n",
        "  \"\"\"Returns a dictionary mapping Variant --\u003e VariantCall.\"\"\"\n",
        "  # NOTE: This function must be implemented in order to run this colab. It\n",
        "  # depends on the data storage and infrastructure used for variants. See the\n",
        "  # definition of Variant and VariantCall objects above.\n",
        "  return {}\n",
        "\n",
        "\n",
        "class VariantValues(object):\n",
        "\n",
        "  def __init__(self, eids, variant_calls):\n",
        "    self._eids = eids\n",
        "    self._variant_calls = variant_calls\n",
        "\n",
        "  @classmethod\n",
        "  def from_variants(cls, variants, eids):\n",
        "    calls = _load_variant_calls(variants, eids)\n",
        "    return cls(eids=eids, variant_calls=calls)\n",
        "\n",
        "  def get_call(self, variant):\n",
        "    \"\"\"Returns the VariantCall object associated with this Variant.\"\"\"\n",
        "    return self._variant_calls[variant]\n",
        "\n",
        "  def variant_df(self, variants, dosage=False):\n",
        "    \"\"\"Returns a pd.DataFrame indexed by eid with all requested variants.\n",
        "\n",
        "    Variants are returned as columns with the name being v.name.\n",
        "\n",
        "    Args:\n",
        "      variants: list of Variant objects to extract.\n",
        "      dosage: bool. If True, the dosage is used. Otherwise, the geno call is\n",
        "        used.\n",
        "\n",
        "    Returns:\n",
        "      pd.DataFrame of variants.\n",
        "    \"\"\"\n",
        "    attr = 'dosage' if dosage else 'geno'\n",
        "    data = {v.name: getattr(self.get_call(v), attr) for v in variants}\n",
        "    assert len(data) == len(variants)\n",
        "    assert 'eid' not in data\n",
        "    data['eid'] = self._eids\n",
        "    return pd.DataFrame(data).set_index('eid')\n",
        "\n",
        "  def prs(self, variants, name='prs'):\n",
        "    \"\"\"Returns a pd.DataFrame indexed by eid with the PRS and its PLINK repr.\"\"\"\n",
        "    plink_strs = []\n",
        "    value = np.zeros_like(list(self._variant_calls.values())[0].dosage)\n",
        "    for v in variants:\n",
        "      vcall = self.get_call(v)\n",
        "      plink_str = f'{v.chr}:{v.pos}_{vcall.ref}_{vcall.alt}\\t{v.A1}\\t{v.beta}\\n'\n",
        "      plink_strs.append(plink_str)\n",
        "      assert ((vcall.ref == v.A0 and vcall.alt == v.A1) or\n",
        "              (vcall.ref == v.A1 and vcall.alt == v.A0))\n",
        "      if vcall.alt == v.A1:\n",
        "        value += v.beta * vcall.geno\n",
        "      else:\n",
        "        value += v.beta * (2 - vcall.geno)\n",
        "\n",
        "    df = pd.DataFrame({'eid': self._eids, name: value}).set_index('eid')\n",
        "    return df, ''.join(plink_strs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOhudvN0yWts"
      },
      "source": [
        "## Code to load covariate and ML-based data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7ZxsP7OycZJ"
      },
      "outputs": [],
      "source": [
        "# Load covariates.\n",
        "def load_covariates(eids_to_retain, subset_to_vcdr=True):\n",
        "  \"\"\"Returns a pd.DataFrame indexed by eid containing all covariates and ML-based VCDR.\"\"\"\n",
        "  cols = COVARS + [\n",
        "      'IID', 'vcdr_visit', 'has_touchscreen_plus_icd_poag',\n",
        "      'has_touchscreen_plus_icd_poag_nofundus'\n",
        "  ]\n",
        "  full_covar_df = pheno_utils.load_csv(\n",
        "      COVARIATES_FILE, index_col=None, delimiter='\\t', usecols=cols)\n",
        "  full_covar_df.rename(columns={'IID': 'eid'}, inplace=True)\n",
        "  num_records = len(full_covar_df)\n",
        "  eid_restricted_df = full_covar_df.loc[\n",
        "      full_covar_df.eid.isin(eids_to_retain), :]\n",
        "  num_restricted = len(eid_restricted_df)\n",
        "  if subset_to_vcdr:\n",
        "    retval = eid_restricted_df.loc[eid_restricted_df.vcdr_visit \u003e -9, :].copy()\n",
        "    print(f'From {num_records} total entries, reduced to {num_restricted} '\n",
        "          f'from input EIDs, and finally {len(retval)} with vcdr_visit')\n",
        "  else:\n",
        "    retval = eid_restricted_df.copy()\n",
        "    print(f'From {num_records} total entries, reduced to {num_restricted}')\n",
        "\n",
        "  # Transform the BOLT encoding of binary records [1, 2] to [0, 1]\n",
        "  for field in ['sex', 'genotyping_array']:\n",
        "    assert sorted(retval[field].unique()) == [1, 2]\n",
        "    retval[field] -= 1\n",
        "\n",
        "  retval.rename(\n",
        "      columns={\n",
        "          'has_touchscreen_plus_icd_poag': 'glaucoma',\n",
        "          'has_touchscreen_plus_icd_poag_nofundus': 'glaucoma_no_fundus'\n",
        "      },\n",
        "      inplace=True)\n",
        "  return retval.set_index('eid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlfSD5e8rKV7"
      },
      "source": [
        "## Load all the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_6EXZW8onU7"
      },
      "outputs": [],
      "source": [
        "valid_european_eids = ... # set of UKB EIDs consented for research and of genetically European ancestry.\n",
        "\n",
        "covar_df = load_covariates(valid_european_eids, subset_to_vcdr=True)\n",
        "\n",
        "# There are 165,457 inds with glaucoma status and all covariates, while only\n",
        "# 67,300 of them have fundus images. We use the 165,457 - 67,300 for evaluating\n",
        "# the relationship between glaucoma and PRS-predicted VCDR.\n",
        "covar_all_df = load_covariates(valid_european_eids, subset_to_vcdr=False)\n",
        "\n",
        "european_eids_with_covars = set(covar_df.index)\n",
        "european_eids_with_covars_all = set(covar_all_df.index)\n",
        "\n",
        "vcdr_container = VcdrValues(\n",
        "    filename=VCDR_LABELS_FILE, eids_to_retain=valid_european_eids)\n",
        "\n",
        "eids_to_load_genotypes = european_eids_with_covars_all.union(\n",
        "    vcdr_container.eids)\n",
        "\n",
        "\n",
        "craig_snps = read_craig_snps(CRAIG_VCDR_SNPS)\n",
        "craig_epic_surrogate_snps = read_craig_snps(CRAIG_VCDR_EPIC_SURROGATE_SNPS)\n",
        "craig_epic_only_snps = read_craig_snps(CRAIG_VCDR_EPIC_ONLY_SNPS)\n",
        "\n",
        "mlderived_snps = read_gwas_pipeline_results(filename=MLDERIVED_VCDR_SNPS,\n",
        "                                            namecol='RS',\n",
        "                                            thresh=5e-8)\n",
        "\n",
        "mlderived_epic_surrogate_snps = read_gwas_pipeline_results(\n",
        "    filename=MLDERIVED_VCDR_EPIC_SURROGATE_SNPS,\n",
        "    namecol='SNP',\n",
        "    thresh=5e-8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8g0w3bT1Ndc"
      },
      "outputs": [],
      "source": [
        "# Run the very slow variant loading in a separate cell so it can be skipped if\n",
        "# not needed.\n",
        "variant_container = VariantValues.from_variants(\n",
        "    craig_snps + craig_epic_surrogate_snps + craig_epic_only_snps +\n",
        "    mlderived_snps + mlderived_epic_surrogate_snps,\n",
        "    eids_to_load_genotypes\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_1_FhwoNjRg"
      },
      "source": [
        "## Save Genotypes in PLINK (.map + .ped) format\n",
        "We first save the genotypes as .map + .ped text PLINK files and then manually \n",
        "convert them to .bed + .bim + .fam files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpBeM0KGIHHA"
      },
      "outputs": [],
      "source": [
        "def write_plink_map_ped_files(path_prefix, df_genotypes, variants_name_map):\n",
        "  \"\"\"Writes \u003cdf_genotypes\u003e in PLINK's MAP and PED format.\"\"\"\n",
        "  variants = list(df_genotypes.columns)\n",
        "  eids = list(df_genotypes.index)\n",
        "\n",
        "  def _get_allele_map(ref, alt):\n",
        "    \"\"\"Returns genotype to allele pair map.\"\"\"\n",
        "    return {\n",
        "        np.nan: '0 0',\n",
        "        0: f'{ref} {ref}',\n",
        "        1: f'{ref} {alt}',\n",
        "        2: f'{alt} {alt}'\n",
        "    }\n",
        "\n",
        "  def _get_ped_call(genotype, allele_map):\n",
        "    \"\"\"Returns the PED allele code based on genotype.\"\"\"\n",
        "    # If genotype is `float`, we assume it has been mean-imputed\n",
        "    # so was missing in the first place.\n",
        "    if genotype.is_integer():\n",
        "      return allele_map[genotype]\n",
        "    else:\n",
        "      return allele_map[np.nan]\n",
        "\n",
        "  allele_maps = []\n",
        "  map_path = path_prefix + '.map'\n",
        "  with open(map_path, 'w') as fw:\n",
        "    for variant in variants:\n",
        "      prsname = variants_name_map[variant]\n",
        "      chrom, pos_ref_alt = prsname.split(':')\n",
        "      pos, ref, alt = pos_ref_alt.split('_')\n",
        "      allele_maps.append(_get_allele_map(ref, alt))\n",
        "      line = '\\t'.join([chrom, prsname, '0', pos])\n",
        "      fw.write(f'{line}\\n')\n",
        "\n",
        "  ped_path = path_prefix + '.ped'\n",
        "  with open(ped_path, 'w') as fw:\n",
        "    for eid in eids:\n",
        "      line = '\\t'.join(['0', str(eid), '0', '0', '0', '0'] + [\n",
        "          _get_ped_call(g, am)\n",
        "          for g, am in zip(df_genotypes.loc[eid], allele_maps)\n",
        "      ])\n",
        "      fw.write(f'{line}\\n')\n",
        "\n",
        "\n",
        "all_raw_vars = (craig_snps + craig_epic_surrogate_snps + craig_epic_only_snps +\n",
        "    mlderived_snps + mlderived_epic_surrogate_snps)\n",
        "all_variants = set(_get_canonical_variant_map(all_raw_vars).values())\n",
        "all_samples = variant_container.variant_df(all_variants)\n",
        "\n",
        "variants_name_map = dict()\n",
        "for variant in all_variants:\n",
        "  vcall = variant_container.get_call(variant)\n",
        "  prsname = '{}:{}_{}_{}'.format(variant.chr, variant.pos, vcall.ref, vcall.alt)\n",
        "  variants_name_map[variant.name] = prsname\n",
        "\n",
        "path_prefix = '/path/to/save/plink_data/'\n",
        "\n",
        "write_plink_map_ped_files(path_prefix, all_samples, variants_name_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLXUMj-ngC_A"
      },
      "source": [
        "## Build the full datasets for training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnmlUZeagCCl"
      },
      "outputs": [],
      "source": [
        "def load_dataset(v_df,\n",
        "                 target_df,\n",
        "                 eids=None,\n",
        "                 ensure_variation='raise'):\n",
        "  \"\"\"Returns a pd.DataFrame with `target` and all variants.\n",
        "\n",
        "  Args:\n",
        "    v_df: pd.DataFrame of variants to include.\n",
        "    target_df: pd.DataFrame containing a single field that is the target label.\n",
        "    eids: Iterable(int). eids to restrict to further.\n",
        "    ensure_variation: str in ('quiet', 'warn', 'raise'). Indicates what to do if\n",
        "      no variation exists in a column.\n",
        "\n",
        "  Returns:\n",
        "    pd.DataFrame containing requested data.\n",
        "  \"\"\"\n",
        "  full_df = v_df.join(target_df, how='inner')\n",
        "  if eids is not None:\n",
        "    no_na = full_df.loc[full_df.index.intersection(set(eids))].dropna(axis=0)\n",
        "  else:\n",
        "    no_na = full_df.dropna(axis=0)\n",
        "\n",
        "  retval = no_na.loc[(no_na == -9).sum(axis=1) == 0]\n",
        "\n",
        "  print(f'{len(v_df)} with variants --\u003e {len(full_df)} with v and target.')\n",
        "  print(f'{len(retval)} final.\\n')\n",
        "\n",
        "  if ensure_variation != 'quiet':\n",
        "    for col in retval.columns:\n",
        "      if len(retval[col].unique()) \u003c 2:\n",
        "        msg = f'Column {col} has no variation in retval.'\n",
        "        if ensure_variation == 'warn':\n",
        "          print(msg)\n",
        "        else:\n",
        "          raise ValueError(msg)\n",
        "\n",
        "  if retval.isna().sum().sum() \u003e 0:\n",
        "    raise ValueError('Unexpected NaN present in return value.')\n",
        "  if (retval == -9).sum().sum() \u003e 0:\n",
        "    raise ValueError('Unexpected -9 present in return value.')\n",
        "\n",
        "  return retval\n",
        "\n",
        "\n",
        "def create_design(split, variants):\n",
        "  \"\"\"Returns a design matrix with the given data split and variants.\"\"\"\n",
        "  v_df = variant_container.variant_df(variants)\n",
        "  if split == 'train':\n",
        "    target_df = covar_df[['vcdr_visit'\n",
        "                         ]].rename(columns={'vcdr_visit': 'target'})\n",
        "    eids = set(covar_df.index) - set(vcdr_container.eids)\n",
        "    ensure_variation = 'raise'\n",
        "  elif split == 'testadj':\n",
        "    target_df = vcdr_container.as_dataframe().rename(columns={'vcdr': 'target'})\n",
        "    target_df = target_df.loc[target_df.index.intersection(\n",
        "        vcdr_container.adjudicated_eids)]\n",
        "    eids = None\n",
        "    ensure_variation = 'raise'\n",
        "    covs_df = covar_df\n",
        "  else:\n",
        "    raise ValueError(f'Invalid split: {split}')\n",
        "\n",
        "  return load_dataset(\n",
        "      v_df=v_df,\n",
        "      target_df=target_df,\n",
        "      eids=eids,\n",
        "      ensure_variation=ensure_variation)\n",
        "\n",
        "\n",
        "def get_X_y(df, y_name='target'):\n",
        "  x_columns = df.columns.tolist()\n",
        "  x_columns.remove(y_name)\n",
        "  y = df[y_name].to_numpy()\n",
        "  X = df[x_columns].to_numpy()\n",
        "  return X, y\n",
        "\n",
        "\n",
        "def _bootstrap_ci(truths, preds, metric_fn, preds2=None):\n",
        "  # If two predictions are passed in then return the difference of the metrics.\n",
        "  if preds2 is not None:\n",
        "    re_truths, re_preds, re_preds2 = resample(truths, preds, preds2)\n",
        "    return metric_fn(re_truths, re_preds) - metric_fn(re_truths, re_preds2)\n",
        "  else:\n",
        "    return metric_fn(*resample(truths, preds))\n",
        "\n",
        "\n",
        "def bootstrap_ci(truths,\n",
        "                 preds,\n",
        "                 metric_fn,\n",
        "                 iters=2000,\n",
        "                 preds2=None,\n",
        "                 ci_interval=97.5):\n",
        "  future_objs = []\n",
        "  with futures.ThreadPoolExecutor(max_workers=NPROC) as pool:\n",
        "    for _ in range(iters):\n",
        "      future_objs.append(\n",
        "          pool.submit(_bootstrap_ci, truths, preds, metric_fn, preds2=preds2))\n",
        "  metrics = []\n",
        "  for future_obj in future_objs:\n",
        "    metrics.append(future_obj.result())\n",
        "  return np.percentile(metrics, [100 - ci_interval, ci_interval])  # 95% CI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Pfqvi5sic8X"
      },
      "outputs": [],
      "source": [
        "print('### Craig et al 76 SNPs.')\n",
        "craig_train_design = create_design('train', craig_snps)\n",
        "craig_test_design = create_design('testadj', craig_snps)\n",
        "\n",
        "print('\\n### Craig et al 76 EPIC-surrogate SNPs.')\n",
        "craig_epic_surrogate_train_design = create_design('train', craig_epic_surrogate_snps)\n",
        "craig_epic_surrogate_test_design = create_design('testadj', craig_epic_surrogate_snps)\n",
        "\n",
        "print('\\n### Craig et al 58 EPIC-present SNPs.')\n",
        "craig_epic_only_train_design = create_design('train', craig_epic_only_snps)\n",
        "craig_epic_only_test_design = create_design('testadj', craig_epic_only_snps)\n",
        "\n",
        "print('\\n### ML-derived 299 SNPs.')\n",
        "mlderived_train_design = create_design('train', mlderived_snps)\n",
        "mlderived_test_design = create_design('testadj', mlderived_snps)\n",
        "\n",
        "print('\\n### ML-derived 282 EPIC-surrogate SNPs.')\n",
        "mlderived_epic_surrogate_train_design = create_design('train', mlderived_epic_surrogate_snps)\n",
        "mlderived_epic_surrogate_test_design = create_design('testadj', mlderived_epic_surrogate_snps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMraxgRL68Gs"
      },
      "outputs": [],
      "source": [
        "# Sanity check the design matrices.\n",
        "def check_pair(df1, df2, same=['target']):\n",
        "  if len(df1) != len(df2):\n",
        "    raise ValueError(\n",
        "        f'Number of entries is different: {len(df1)} vs {len(df2)}')\n",
        "  if set(df1.index) != set(df2.index):\n",
        "    raise ValueError('Indexes are different.')\n",
        "  \n",
        "  shared_columns = sorted(set(df1.columns) \u0026 set(df2.columns))\n",
        "  assert 'target' in shared_columns\n",
        "  print(f'{len(shared_columns)} total shared columns.')\n",
        "\n",
        "  if (df1[shared_columns] != df2[shared_columns]).any().any():\n",
        "    raise ValueError(f'Expected identical results for {shared_columns}')\n",
        "\n",
        "\n",
        "check_pair(craig_train_design, mlderived_train_design)\n",
        "check_pair(craig_test_design, mlderived_test_design)\n",
        "\n",
        "check_pair(craig_epic_surrogate_train_design, mlderived_epic_surrogate_train_design)\n",
        "check_pair(craig_epic_surrogate_test_design, mlderived_epic_surrogate_test_design)\n",
        "\n",
        "check_pair(craig_epic_only_train_design, mlderived_train_design)\n",
        "check_pair(craig_epic_only_test_design, mlderived_test_design)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UbeD8Ef6Fmr"
      },
      "source": [
        "# Train on ML-based VCDR predictions, evaluate on human labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6EbnmXb3v3r"
      },
      "outputs": [],
      "source": [
        "Stats = collections.namedtuple('Stats', 'mae mse r r_low_95 r_high_95 pvalue r2')\n",
        "\n",
        "def train_and_test(train_df,\n",
        "                   test_df,\n",
        "                   title='',\n",
        "                   model='linear',\n",
        "                   bootstrap=False):\n",
        "  \"\"\"Trains and evaluates a model. Returns (model, truth, preds, stats) tuple.\"\"\"\n",
        "  assert list(train_df.columns) == list(test_df.columns)\n",
        "  train_X, train_y = get_X_y(train_df)\n",
        "  test_X, test_y = get_X_y(test_df)\n",
        "  assert not bool(set(train_df.index) \u0026 set(test_df.index))\n",
        "  if model == 'linear':\n",
        "    reg = linear_model.LinearRegression()\n",
        "  elif model == 'elastic':\n",
        "    # l1_ratio == 0 is Ridge regression; l1_ratio == 1 is LASSO.\n",
        "    reg = linear_model.ElasticNetCV(\n",
        "        cv=5, l1_ratio=[.1, .5, .7, .9, .95, .99, 1.], n_jobs=-1)\n",
        "  else:\n",
        "    raise ValueError('Unknown model: {}'.format(model))\n",
        "  reg.fit(train_X, train_y)\n",
        "  preds = reg.predict(test_X)\n",
        "  pearson_r, pvalue = stats.pearsonr(test_y, preds)\n",
        "  if bootstrap:\n",
        "    low_r, high_r = bootstrap_ci(\n",
        "        test_y, preds, lambda x, y: stats.pearsonr(x, y)[0], iters=3000)\n",
        "    r_str = 'R: {:.5f} ({:.5f}, {:.5f})'.format(pearson_r, low_r, high_r)\n",
        "  else:\n",
        "    r_str = 'R: {:.5f}'.format(pearson_r)\n",
        "    low_r = None\n",
        "    high_r = None\n",
        "  stats_container = Stats(mae=metrics.mean_absolute_error(test_y, preds),\n",
        "                         mse=metrics.mean_squared_error(test_y, preds),\n",
        "                         r=pearson_r,\n",
        "                         r_low_95=low_r,\n",
        "                         r_high_95=high_r,\n",
        "                         pvalue=pvalue,\n",
        "                         r2=pearson_r**2)\n",
        "  stats_strs = [\n",
        "      'MAE: {:.5f}'.format(stats_container.mae),\n",
        "      'MSE: {:.5f}'.format(stats_container.mse),\n",
        "      r_str,\n",
        "      'R^2: {:.5f}'.format(stats_container.r2),\n",
        "      'P-value: {:.3e}'.format(stats_container.pvalue),\n",
        "  ]\n",
        "\n",
        "  lr = stats.linregress(test_y, preds)\n",
        "  assert abs(pvalue - lr.pvalue) \u003c 1e-6, 'P-value estimates of {} vs {}'.format(\n",
        "      pvalue, lr.pvalue)\n",
        "  equation_str = 'y = {:.3f}x + {:.3f}'.format(lr.slope, lr.intercept)\n",
        "  plt.scatter(test_y, preds, alpha=0.1)\n",
        "  plt.xlabel('Labeled adjudicated VCDR')\n",
        "  plt.ylabel('Predicted VCDR')\n",
        "  plt.plot([0.1, 0.9],\n",
        "           [lr.intercept + lr.slope * 0.1, lr.intercept + lr.slope * 0.9])\n",
        "\n",
        "  s = '\\n'.join(['; '.join(stats_strs), equation_str])\n",
        "  t = title + f' ({model})\\n' + s\n",
        "  plt.title(t)\n",
        "  plt.show()\n",
        "  return (reg, test_y, preds, stats_container)\n",
        "\n",
        "\n",
        "def get_design_with_prs(initial_design_df, variants, prs_name):\n",
        "  prs, prs_plink_str = variant_container.prs(variants, name=prs_name)\n",
        "  retval = initial_design_df[['target']].join(prs)\n",
        "  assert len(retval) == len(initial_design_df)\n",
        "  return retval, prs_plink_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjmiBp6H6Qt7"
      },
      "outputs": [],
      "source": [
        "def eval_all():\n",
        "  retval = {}\n",
        "  for name, train_df, test_df, variants in [\n",
        "    ('Craig orig', craig_train_design, craig_test_design, craig_snps),\n",
        "    ('Craig EPIC-only', craig_epic_only_train_design, craig_epic_only_test_design, craig_epic_only_snps),\n",
        "    ('Craig EPIC-surrogate', craig_epic_surrogate_train_design, craig_epic_surrogate_test_design, craig_epic_surrogate_snps),\n",
        "    ('ML-derived orig', mlderived_train_design, mlderived_test_design, mlderived_snps),\n",
        "    ('ML-derived EPIC-surrogate', mlderived_epic_surrogate_train_design, mlderived_epic_surrogate_test_design, mlderived_epic_surrogate_snps),\n",
        "  ]:\n",
        "    title = f'{name} ({train_df.shape[1] - 1}) - eval adjudicated'\n",
        "    retval[f'{name} elastic'] = train_and_test(train_df=train_df,\n",
        "                                               test_df=test_df,\n",
        "                                               title=title,\n",
        "                                               model='elastic',\n",
        "                                               bootstrap=True)\n",
        "    \n",
        "    title = f'{name} ({train_df.shape[1] - 1}) - P+T eval adjudicated'\n",
        "    prs_train_df, plink_str = get_design_with_prs(train_df, variants, 'prs')\n",
        "    prs_test_df, plink_str2 = get_design_with_prs(test_df, variants, 'prs')\n",
        "    assert plink_str == plink_str2\n",
        "    retval[f'{name} P+T'] = train_and_test(train_df=prs_train_df,\n",
        "                                           test_df=prs_test_df,\n",
        "                                           title=title,\n",
        "                                           model='linear',\n",
        "                                           bootstrap=True) + (plink_str,)\n",
        "  return retval\n",
        "\n",
        "\n",
        "def _one_elastic_prs_str(model, train_df, variants):\n",
        "  cols = [c for c in train_df.columns if c != 'target']\n",
        "  assert len(model.coef_) == len(cols) == len(variants)\n",
        "\n",
        "  name_to_variant = {}\n",
        "  for name in cols:\n",
        "    vs = [v for v in variants if v.name == name]\n",
        "    assert len(vs) == 1\n",
        "    name_to_variant[name] = vs[0]\n",
        "\n",
        "  name_to_prs_name = {}\n",
        "  for name, variant in name_to_variant.items():\n",
        "    vcall = variant_container.get_call(variant)\n",
        "    prsname = '{}:{}_{}_{}\\t{}'.format(variant.chr, variant.pos, vcall.ref,\n",
        "                                       vcall.alt, vcall.alt)\n",
        "    name_to_prs_name[name] = prsname\n",
        "\n",
        "  retval = []\n",
        "  for name, beta in zip(cols, model.coef_):\n",
        "    retval.append(f'{name_to_prs_name[name]}\\t{beta}\\n')\n",
        "  return ''.join(retval)\n",
        "\n",
        "\n",
        "def write_all_prs_outputs(results_dict, outdir='/path/to/output/directory'):\n",
        "  \"\"\"Write all PRS outputs to the given output directory.\"\"\"\n",
        "  # P+T models.\n",
        "  for name, plink_str in [\n",
        "      # Used in Fig 3, since we can test the equivalent in EPIC-Norfolk.\n",
        "      ('craig_prs.epic_only_58.p_plus_t.tsv', results_dict['Craig EPIC-only P+T'][-1]),\n",
        "      ('mlbased_prs.epic_surrogates_282.p_plus_t.tsv', results_dict['ML-derived EPIC-surrogate P+T'][-1]),\n",
        "      # Used in suppl fig, since we can only evaluate in UKB.\n",
        "      ('craig_prs.original_76.p_plus_t.tsv', results_dict['Craig orig P+T'][-1]),\n",
        "      ('mlbased_prs.original_299.p_plus_t.tsv', results_dict['ML-derived orig P+T'][-1]),\n",
        "  ]:\n",
        "    with open(os.path.join(outdir, name), 'w') as f:\n",
        "      f.write(plink_str)\n",
        "\n",
        "  # Elastic net models.\n",
        "  for name, train_df, variants, model in [\n",
        "      # Used in Fig 3.\n",
        "      ('craig_prs.epic_surrogates_76.elastic.tsv', craig_epic_surrogate_train_design, craig_epic_surrogate_snps, results_dict['Craig EPIC-surrogate elastic'][0]),\n",
        "      ('mlbased_prs.epic_surrogates_282.elastic.tsv', mlderived_epic_surrogate_train_design, mlderived_epic_surrogate_snps, results_dict['ML-derived EPIC-surrogate elastic'][0]),\n",
        "      # Used in suppl fig, since we can only evaluate in UKB.\n",
        "      ('craig_prs.epic_only_58.elastic.tsv', craig_epic_only_train_design, craig_epic_only_snps, results_dict['Craig EPIC-only elastic'][0]),\n",
        "      ('craig_prs.original_76.elastic.tsv', craig_train_design, craig_snps, results_dict['Craig orig elastic'][0]),\n",
        "      ('mlbased_prs.original_299.elastic.tsv', mlderived_train_design, mlderived_snps, results_dict['ML-derived orig elastic'][0]),\n",
        "  ]:\n",
        "    with open(os.path.join(outdir, name), 'w') as f:\n",
        "      f.write(_one_elastic_prs_str(model, train_df, variants))\n",
        "  \n",
        "\n",
        "# Run all the model training and evaluations.\n",
        "all_results = eval_all()\n",
        "\n",
        "# Set this to True if the PRSes should be written.\n",
        "if True:\n",
        "  write_all_prs_outputs(all_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHkzHtItSYit"
      },
      "source": [
        "# Evaluate models based on existing bootstraps and pairwise bootstrapping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0sVSKJTqo7D"
      },
      "outputs": [],
      "source": [
        "def compare_stats(label, craig_stats, ml_stats):\n",
        "  print(f'Results for the {label} data:')\n",
        "  print(\n",
        "      f'* Mean absolute error: Craig {craig_stats.mae:.5f} vs our {ml_stats.mae:.5f}, absolute improvement {craig_stats.mae - ml_stats.mae:.5f}, error reduction of {(1 - ml_stats.mae / craig_stats.mae) * 100:.1f}%'\n",
        "  )\n",
        "  print(\n",
        "      f'* Mean squared error: Craig {craig_stats.mse:.5f} vs our {ml_stats.mse:.5f}, absolute improvement {craig_stats.mse - ml_stats.mse:.5f}, error reduction of {(1 - ml_stats.mse / craig_stats.mse) * 100:.1f}%'\n",
        "  )\n",
        "  print(\n",
        "      f'* R: Craig {craig_stats.r:.5f} vs our {ml_stats.r:.5f}, absolute improvement {ml_stats.r - craig_stats.r:.5f}, prediction improvement of {100 * (ml_stats.r - craig_stats.r) / craig_stats.r:.1f}%'\n",
        "  )\n",
        "  print(\n",
        "      f'* R^2: Craig {craig_stats.r2:.5f} vs our {ml_stats.r2:.5f}, absolute improvement {ml_stats.r2 - craig_stats.r2:.5f}, prediction improvement of {100 * (ml_stats.r2 - craig_stats.r2) / craig_stats.r2:.1f}%'\n",
        "  )\n",
        "\n",
        "\n",
        "def paired_bootstrap(results_dict, ds1: str, ds2: str) -\u003e None:\n",
        "  _, truth1, preds1 = results_dict[ds1][:3]\n",
        "  _, truth2, preds2 = results_dict[ds2][:3]\n",
        "  assert (truth1 == truth2).all()\n",
        "\n",
        "  def corr_fn(x, y):\n",
        "    return np.corrcoef(x, y)[0, 1]\n",
        "  \n",
        "  print(f'* Paired R 95% CI improvement of {ds1} over {ds2}: ',\n",
        "        bootstrap_ci(\n",
        "            truth1,\n",
        "            preds1,\n",
        "            metric_fn=corr_fn,\n",
        "            iters=3000,\n",
        "            preds2=preds2,\n",
        "            ci_interval=97.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlHEbUqr65om"
      },
      "outputs": [],
      "source": [
        "for label, craig_key, ml_key in [\n",
        "    # 58 Craig variants present in EPIC vs 282 ML EPIC surrogates.\n",
        "    ('EPIC-possible P+T', 'Craig EPIC-only P+T', 'ML-derived EPIC-surrogate P+T'),\n",
        "    # 76 Craig variants present in EPIC vs 299 ML-based.\n",
        "    ('Original P+T', 'Craig orig P+T', 'ML-derived orig P+T'),\n",
        "    # 76 Craig surrogates vs 282 ML EPIC surrogates.\n",
        "    ('EPIC-possible elastic', 'Craig EPIC-surrogate elastic', 'ML-derived EPIC-surrogate elastic'),\n",
        "    # 76 Craig variants present in EPIC vs 299 ML-based.\n",
        "    ('Original elastic', 'Craig orig elastic', 'ML-derived orig elastic'),\n",
        "]:\n",
        "  compare_stats(label=label,\n",
        "                craig_stats=all_results[craig_key][3],\n",
        "                ml_stats=all_results[ml_key][3])\n",
        "  paired_bootstrap(all_results, ml_key, craig_key)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHPLSwgPFWC5"
      },
      "source": [
        "#Analyze PLINK predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9cCOVpGFz5V"
      },
      "outputs": [],
      "source": [
        "def pearson_corr(targets, predictions):\n",
        "  \"\"\"Returns Pearson correlation between \u003ctargets\u003e and \u003cpredictions\u003e.\"\"\"\n",
        "  return stats.pearsonr(targets, predictions)[0]\n",
        "\n",
        "\n",
        "def spearman_corr(targets, predictions):\n",
        "  \"\"\"Returns Pearman correlation between \u003ctargets\u003e and \u003cpredictions\u003e.\"\"\"\n",
        "  return stats.spearmanr(targets, predictions)[0]\n",
        "\n",
        "\n",
        "_SEED = 23\n",
        "\n",
        "_METRICS = [\n",
        "    perf_metrics.Metric(\n",
        "        'num', lambda y_true, y_pred: len(y_true), binary_only=False),\n",
        "    perf_metrics.Metric('Pearson corr', pearson_corr, binary_only=False),\n",
        "    perf_metrics.Metric('Spearman corr', spearman_corr, binary_only=False),\n",
        "]\n",
        "\n",
        "\n",
        "def load_plink_predictions(source, model):\n",
        "  \"\"\"Loads PLINK's predictions for \u003cdataset\u003e.\"\"\"\n",
        "  lookup = {\n",
        "      ('craig_orig', 'p+t'): 'craig_prs.original_76.p_plus_t.profile',\n",
        "      ('craig_orig', 'elastic'): 'craig_prs.original_76.elastic.profile',\n",
        "      ('craig_epic_only', 'p+t'): 'craig_prs.epic_only_58.p_plus_t.profile',\n",
        "      ('craig_epic_only', 'elastic'): 'craig_prs.epic_only_58.elastic.profile',\n",
        "      ('craig_epic_surrogates', 'elastic'): 'craig_prs.epic_surrogates_76.elastic.profile',\n",
        "      ('genmed_orig', 'p+t'): 'mlbased_prs.original_299.p_plus_t.profile',\n",
        "      ('genmed_orig', 'elastic'): 'mlbased_prs.original_299.elastic.profile',\n",
        "      ('genmed_epic_surrogates', 'p+t'): 'mlbased_prs.epic_surrogates_282.p_plus_t.profile',\n",
        "      ('genmed_epic_surrogates', 'elastic'): 'mlbased_prs.epic_surrogates_282.elastic.profile',\n",
        "  }\n",
        "  try:\n",
        "    filename = lookup[(source, model)]\n",
        "  except KeyError:\n",
        "    raise ValueError(\n",
        "        f'Unknown source ({source}) and model ({model}) combination.')\n",
        "\n",
        "  preds_path = os.path.join(PLINK_PRS_PREDS, filename)\n",
        "\n",
        "  preds = pheno_utils.load_csv(\n",
        "      preds_path,\n",
        "      index_col=None,\n",
        "      delim_whitespace=True,\n",
        "      usecols=['IID', 'SCORE'])\n",
        "  preds.rename(columns={'IID': 'eid', 'SCORE': 'prediction'}, inplace=True)\n",
        "\n",
        "  return preds.set_index('eid')\n",
        "\n",
        "\n",
        "def analyze_one_plink_set(source, model, seed=_SEED):\n",
        "  \"\"\"Computes performance metrics for \u003csource\u003e and \u003cmodel\u003e.\"\"\"\n",
        "  preds_df = load_plink_predictions(source, model)\n",
        "  target_df = vcdr_container.as_dataframe()\n",
        "  target_df = target_df.loc[target_df.index.intersection(\n",
        "      vcdr_container.adjudicated_eids)]\n",
        "  merged_df = pd.merge(\n",
        "      preds_df, target_df, left_index=True, right_index=True, how='inner')\n",
        "\n",
        "  return perf_metrics.PerformanceMetrics(\n",
        "      name=f'{source} - {model}', metrics=_METRICS).compute(\n",
        "          merged_df['prediction'].to_numpy(copy=True),\n",
        "          merged_df['vcdr'].to_numpy(copy=True),\n",
        "          n_bootstrap=2000,\n",
        "          seed=seed)\n",
        "\n",
        "\n",
        "def get_permute_pvalue(df, col_1, col_2, ground_truth, n_permute=2000, seed=42):\n",
        "  \"\"\"Computes permutation P for \u003ccol_1\u003e preds being better than \u003ccol_2\u003e.\"\"\"\n",
        "\n",
        "  def _corr_diff(p1, p2, gt):\n",
        "    \"\"\"Computes difference in correlation.\"\"\"\n",
        "    corr_1 = np.corrcoef(p1, gt)[0, 1]\n",
        "    corr_2 = np.corrcoef(p2, gt)[0, 1]\n",
        "    return corr_1 - corr_2\n",
        "    \n",
        "  prng = np.random.RandomState(seed=seed)\n",
        "  n = df.shape[0]\n",
        "  p1 = df[col_1].to_numpy(copy=True)\n",
        "  p2 = df[col_2].to_numpy(copy=True)\n",
        "  gt = df[ground_truth].to_numpy(copy=True)\n",
        "  \n",
        "  diffs = np.empty(n_permute)\n",
        "  \n",
        "  # get the observed corr diff\n",
        "  diff_obs = _corr_diff(p1, p2, gt)\n",
        "  # we append observed corr diff to make sure P is never zero. \n",
        "  diffs[-1] = diff_obs\n",
        "  \n",
        "  # concatenate two preds\n",
        "  p = np.hstack([p1, p2])\n",
        "    \n",
        "  for i in range(n_permute):\n",
        "    # randomly select predictions for p1/2_permut[i] from p1[i] or p2[i]\n",
        "    # For each individual, randomly select either their `p1` or `p2` value \n",
        "    # to be used in the permuted p1 vector, and use the other value in the\n",
        "    # permuted p2 vector.\n",
        "    rand_indicator = prng.choice([0, n], size=n)\n",
        "    idx_1 = np.arange(n) + rand_indicator\n",
        "    idx_2 = np.arange(n) - rand_indicator + n\n",
        "    diffs[i] = _corr_diff(p[idx_1], p[idx_2], gt)\n",
        "\n",
        "  # one-sided permutation p-value\n",
        "  P = np.max([1/n_permute, np.mean(diffs \u003e diff_obs)])\n",
        "  print(f'one-sided p-value for {col_1} \u003e {col_2}')\n",
        "  print('p-value \u003c= {:.3e}\\n'.format(P))\n",
        "\n",
        "\n",
        "def get_corr_ci(df, col_1, col_2, gt, n_bootstrap=2000, seed=42):\n",
        "  \"\"\"Computes CI for the difference in correlations.\"\"\"\n",
        "  prng = np.random.RandomState(seed=seed)\n",
        "  n = df.shape[0]\n",
        "  metrics = np.empty((n_bootstrap, 3))\n",
        "\n",
        "  p1 = df[col_1].to_numpy(copy=True)\n",
        "  p2 = df[col_2].to_numpy(copy=True)\n",
        "  gt = df[gt].to_numpy(copy=True)\n",
        "\n",
        "  for i in range(n_bootstrap):\n",
        "    idx = prng.randint(0, high=n, size=n)\n",
        "    corr_1 = np.corrcoef(gt[idx], p1[idx])[0, 1]\n",
        "    corr_2 = np.corrcoef(gt[idx], p2[idx])[0, 1]\n",
        "    metrics[i, :] = [corr_1, corr_2, corr_1 - corr_2]\n",
        "\n",
        "  print(f'CI for {col_1} \u003e {col_2}')\n",
        "  labs = [col_1, col_2, 'diff']\n",
        "  for i in range(3):\n",
        "    m = np.mean(metrics[:, i])\n",
        "    s = np.std(metrics[:, i])\n",
        "    lo, hi = np.percentile(metrics[:, i], [2.5, 97.5])\n",
        "    print('{}\\tm: {:.3f} s: {:.3f} cl: {:.3f}-{:.3f}'.format(\n",
        "        labs[i], m, s, lo, hi))\n",
        "  print()\n",
        "\n",
        "\n",
        "def analyze_plink_pairs(comparison, n_bootstrap=2000, n_permute=10000, seed=_SEED):\n",
        "  \"\"\"Computes performance metrics for \u003ccomparison\u003e for 'craig' and 'genmed'.\"\"\"\n",
        "  target_df = vcdr_container.as_dataframe()\n",
        "  df = target_df.loc[target_df.index.intersection(\n",
        "      vcdr_container.adjudicated_eids)]\n",
        "\n",
        "  comparison_to_preds = {\n",
        "      'fig3 p+t': [('genmed_epic_surrogates', 'p+t'), ('craig_epic_only', 'p+t')],\n",
        "      'fig3 elastic': [('genmed_epic_surrogates', 'elastic'), ('craig_epic_surrogates', 'elastic')],\n",
        "      'orig p+t': [('genmed_orig', 'p+t'), ('craig_orig', 'p+t')],\n",
        "      'orig elastic': [('genmed_orig', 'elastic'), ('craig_orig', 'elastic')],\n",
        "  }\n",
        "\n",
        "  cols = []\n",
        "  for source, model in comparison_to_preds[comparison]:\n",
        "    cols.append(f'{source}_{model}')\n",
        "    preds_df = load_plink_predictions(source, model)\n",
        "    preds_df.rename(columns={'prediction': f'{source}_{model}'}, inplace=True)\n",
        "    df = pd.merge(df, preds_df, left_index=True, right_index=True, how='inner')\n",
        "\n",
        "  get_corr_ci(df, cols[0], cols[1], 'vcdr', n_bootstrap=n_bootstrap, seed=seed)\n",
        "  get_permute_pvalue(\n",
        "      df, cols[0], cols[1], 'vcdr', n_permute=n_permute, seed=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjMl5omp30_F"
      },
      "outputs": [],
      "source": [
        "# Individual metrics.\n",
        "def compute_all_individual_metrics():\n",
        "  retval = {}\n",
        "  for key in [\n",
        "      ('craig_orig', 'p+t'),\n",
        "      ('craig_orig', 'elastic'),\n",
        "      ('craig_epic_only', 'p+t'),\n",
        "      ('craig_epic_only', 'elastic'),\n",
        "      ('craig_epic_surrogates', 'elastic'),\n",
        "      ('genmed_orig', 'p+t'),\n",
        "      ('genmed_orig', 'elastic'),\n",
        "      ('genmed_epic_surrogates', 'p+t'),\n",
        "      ('genmed_epic_surrogates', 'elastic'),]:\n",
        "    source, model = key\n",
        "    retval[key] = analyze_one_plink_set(source, model)\n",
        "  \n",
        "  # Print out the metrics before returning them.\n",
        "  for (source, model), metrics_dict in sorted(retval.items()):\n",
        "    print(f'{source} {model}:')\n",
        "    for metric_name, result in sorted(metrics_dict.items()):\n",
        "      print(perf_metrics._build_metric_str(metric_name, result))  \n",
        "\n",
        "  return retval\n",
        "\n",
        "\n",
        "indiv_metrics = compute_all_individual_metrics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISNKBjSnCnkR"
      },
      "outputs": [],
      "source": [
        "# Pairwise comparisons.\n",
        "for comparison in ['fig3 p+t', 'fig3 elastic', 'orig p+t', 'orig elastic']:\n",
        "  analyze_plink_pairs(comparison, n_bootstrap=2000, n_permute=100000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/genomics/internal:genomics_colab",
        "kind": "private"
      },
      "name": "learning_prs",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1OwMFs3dBd6XQvLd6s9XBihHi924BKorb",
          "timestamp": 1615658671072
        },
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/colab/notebooks/vcdr/vcdr_prs_manuscript_results.ipynb",
          "timestamp": 1615568598798
        },
        {
          "file_id": "/piper/depot/google3/learning/genomics/medgen/colab/notebooks/vcdr/vcdr_prs_analyses_for_manuscript.ipynb",
          "timestamp": 1602117009057
        },
        {
          "file_id": "1GjvqmpjlOIqvevs4oCrcsh31P8n6qcrG",
          "timestamp": 1589512378817
        },
        {
          "file_id": "1bbYWqx-qH1A6-SMO2QQ4RjHnuRMD_tKn",
          "timestamp": 1588254437448
        },
        {
          "file_id": "1UNlZOsIWPQ3TsHwEbAj0TE3-ZbFj_Jcx",
          "timestamp": 1587415459617
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
